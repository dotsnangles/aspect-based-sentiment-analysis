{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1666249058207,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"MbTADoPibruA"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using state  server backend.\n"]}],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForMaskedLM, \n",")\n","\n","from collections import Counter\n","import re, math, random, json\n","from copy import deepcopy\n","from tqdm import tqdm\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","from module.preprocess import decorate_form, decorate_acd_pair, decorate_asc_pair, decorate_acd_pair_split, decorate_asc_pair_split\n","from module.utils import count_tags, make_token_classification_pair, remove_props, get_filter\n","from module.augmentation import back_trans, random_replace, random_insert, random_swap, random_split\n","\n","# import demoji\n","# from cleantext import clean\n","# from pykospacing import Spacing\n","# from hanspell import spell_checker"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def jsonload(fname, encoding=\"utf-8\"):\n","    with open(fname, encoding=encoding) as f:\n","        j = json.load(f)\n","\n","    return j\n","\n","\n","# json 개체를 파일이름으로 깔끔하게 저장\n","def jsondump(j, fname):\n","    with open(fname, \"w\", encoding=\"UTF8\") as f:\n","        json.dump(j, f, ensure_ascii=False)\n","\n","# jsonl 파일 읽어서 list에 저장\n","def jsonlload(fname, encoding=\"utf-8\"):\n","    json_list = []\n","    with open(fname, encoding=encoding) as f:\n","        for line in f.readlines():\n","            json_list.append(json.loads(line))\n","    return json_list"]},{"cell_type":"markdown","metadata":{},"source":["# Load Raw Data"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666249059795,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"NjTs0B-pbxm6"},"outputs":[],"source":["train_json = './dataset/nikluge-sa-2022-train.jsonl'\n","dev_json = './dataset/nikluge-sa-2022-dev.jsonl'\n","test_json = './dataset/nikluge-sa-2022-test.jsonl'\n","\n","train = jsonlload(train_json)\n","dev = jsonlload(dev_json)\n","test = jsonlload(test_json)\n","train = pd.DataFrame(train)\n","dev = pd.DataFrame(dev)\n","test = pd.DataFrame(test)\n","\n","# train = pd.read_json(train_json, lines=True)\n","# dev = pd.read_json(dev_json, lines=True)\n","# test = pd.read_json(test_json, lines=True)\n","\n","train = train.drop(2319)\n","dev = dev.drop(1692)"]},{"cell_type":"markdown","metadata":{},"source":["# Declare Stuff to use"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ov3SPo0UK_2k"},"outputs":[],"source":["### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","\n","]\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["total = pd.concat([train, dev]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["sentiments = []\n","for idx, row in total.iterrows():\n","    temp = []\n","    for annotation in row.annotation:\n","        sentiment = annotation[2]\n","        temp.append(sentiment)\n","    temp = list(set(temp))\n","    sentiments.append(temp)\n","total['sentiments'] = sentiments"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["eps = []\n","for idx, row in total.iterrows():\n","    temp = []\n","    for annotation in row.annotation:\n","        ep = annotation[0]\n","        temp.append(ep)\n","    temp = list(set(temp))\n","    eps.append(temp)\n","total['eps'] = eps"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["minor = ['브랜드#가격',\n","    '패키지/구성품#다양성',\n","    '본품#가격',\n","    '본품#인지도',\n","    '패키지/구성품#가격']"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def check_if_in_minor(eps):\n","    for ep in eps:\n","        if ep in minor:\n","            return True\n","    return False\n","\n","indices_in_minor = total[total.eps.apply(check_if_in_minor) == True].index"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["rows_in_minor = total.iloc[indices_in_minor].copy()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["total = total.drop(indices_in_minor)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["total['stratified'] = total.annotation.apply(lambda x: x[0][2])\n","train, dev, _, _ = train_test_split(total, total['stratified'], test_size=0.2, random_state=42,  stratify=total['stratified'])\n","train.reset_index(inplace=True, drop=True)\n","dev.reset_index(inplace=True, drop=True)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train = pd.concat([train, rows_in_minor]).reset_index(drop=True)\n","train['stratified'] = train.annotation.apply(lambda x: x[0][2])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["positive\t4460\n","neutral\t117\n","negative\t69\n"]}],"source":["to_count = []\n","for sentiments in train.sentiments:\n","    for sentiment in sentiments:\n","        to_count.append(sentiment)\n","sentiment_counter = Counter(to_count)\n","sentiment_counter = sorted(sentiment_counter.items(), key=lambda x: x[1], reverse=True)\n","\n","for k, v in sentiment_counter:\n","    print(f'{k}\\t{v}')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["checker_one = train.sentence_form.apply(lambda x: len(x.split(' ')))\n","condition_one = checker_one > 4\n","checker_two = train.annotation.apply(len)\n","condition_two = checker_two == 1\n","\n","rows2aug = train[(condition_one) & (condition_two)]\n","\n","# count_tags(rows2aug, entity_property_pair)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["sentiment2aug = ['negative', 'neutral']"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["dfs = {}\n","for sentiment in sentiment2aug:\n","    df = rows2aug[rows2aug.stratified == sentiment]\n","    df = df[['id', 'sentence_form', 'annotation']].values.tolist()\n","    dfs[sentiment] = df"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["dict_keys(['negative', 'neutral'])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["dfs.keys()"]},{"cell_type":"markdown","metadata":{"id":"jAr5_Zc6HHQV"},"source":["# Augmentation"]},{"cell_type":"markdown","metadata":{"id":"nI6TIyYLINET"},"source":["Back Translation / Random Insertion / Random Replacement / Random Swap / Random Deletion / Random Split"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["augmenters = [random_replace, random_insert]\n","target_num = 4460\n","gen_num = 3"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2/2 [03:07<00:00, 93.71s/it]\n"]}],"source":["for sentiment in tqdm(dfs.keys()):\n","    samples = dfs[sentiment]\n","    if len(samples) >= target_num:\n","        continue\n","    \n","    while True:\n","        rand_sample = random.randrange(len(samples))\n","        id = samples[rand_sample][0]\n","        sentence_form = samples[rand_sample][1]\n","        annotation = samples[rand_sample][2]\n","        \n","        rand_aug = random.randrange(len(augmenters))\n","        aug_results = augmenters[rand_aug](gen_num, sentence_form)\n","        \n","        for aug_result in aug_results:\n","            augged = [id, aug_result, annotation]\n","            if augged not in samples:\n","                samples.append(augged)\n","                \n","        if len(samples) > target_num:\n","            samples = samples[:target_num]\n","            dfs[sentiment] = samples\n","            break"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["major = train[train.stratified == 'positive'][['id', 'sentence_form', 'annotation']].values.tolist().copy()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["minors = list(dfs.values())\n","\n","for minor in minors:\n","    major.extend(minor)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["augmented_asc_train = pd.DataFrame(major, columns=['id', 'sentence_form', 'annotation'])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["13380"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["4460 * 3"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def reformat(df):\n","    ep =[]\n","    p = []\n","    for index, row in df.iterrows():\n","        utterance = row.sentence_form\n","        id = row.id\n","        \n","        form = utterance\n","        # form = decorate_form(utterance)\n","\n","        for pair in entity_property_pair:\n","            isPairInOpinion = False\n","            if pd.isna(utterance):\n","                break\n","            for annotation in row.annotation:\n","                entity_property = annotation[0]\n","                sentiment = annotation[2]\n","                if entity_property == pair:\n","                    acd_pair = entity_property\n","                    ep_append = [id, form, acd_pair, tf_name_to_id['True']]\n","                    ep.append(ep_append)\n","                    p.append([id, utterance, acd_pair, polarity_name_to_id[sentiment]])\n","                    isPairInOpinion = True\n","                    break\n","            if isPairInOpinion is False:\n","                acd_pair = pair\n","                ep_append = [id, form, acd_pair, tf_name_to_id['False']]\n","                ep.append(ep_append)\n","    return ep, p"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["(13375, 1156)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["len(augmented_asc_train), len(dev)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["(334375, 28900, 13710, 1218)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["ep_train, p_train = reformat(augmented_asc_train)\n","ep_dev, p_dev = reformat(dev)\n","\n","ep_train = pd.DataFrame(ep_train, columns=['id', 'form', 'pair', 'labels'])\n","ep_dev = pd.DataFrame(ep_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","p_train = pd.DataFrame(p_train, columns=['id', 'form', 'pair', 'labels'])\n","p_dev = pd.DataFrame(p_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","len(ep_train), len(ep_dev), len(p_train), len(p_dev)"]},{"cell_type":"markdown","metadata":{"id":"rjaoyM97e9PQ"},"source":["### Counting"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"GFroeNPQc-DZ","outputId":"bce5e0c2-0423-4db7-982a-23d5b68b8618"},"outputs":[{"name":"stdout","output_type":"stream","text":["binary_multi: 334375 28900 13710 1218\n","\n","after drop_duplicates\n","\n","binary_multi: 334375 28900 13710 1218\n"]},{"data":{"text/plain":["(None, None)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))\n","ep_train = ep_train.drop_duplicates()\n","ep_dev = ep_dev.drop_duplicates()\n","p_train = p_train.drop_duplicates()\n","p_dev = p_dev.drop_duplicates()\n","print('\\nafter drop_duplicates\\n')\n","print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))"]},{"cell_type":"markdown","metadata":{},"source":["### Validate Here"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# dfs = [ep_train, ep_dev, p_train, p_dev]\n","# for df in dfs:\n","#     for idx, row in df.iterrows():\n","#         print(row.id, '\\n',\n","#             row.form, '\\n',\n","#             row.pair, '\\n',\n","#             row.labels,  '\\n',)\n","#         if idx == 999:\n","#             break"]},{"cell_type":"markdown","metadata":{},"source":["### Save"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/uncleaned_v16\n"]}],"source":["DATA_V = 'uncleaned_v16'\n","save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["!mkdir -p {save_path}\n","\n","# train.to_csv(f'{save_path}/raw_train.csv', index=False, encoding='utf-8-sig')\n","# dev.to_csv(f'{save_path}/raw_dev.csv', index=False, encoding='utf-8-sig')\n","# test.to_csv(f'{save_path}/raw_test.csv', index=False, encoding='utf-8-sig')\n","\n","p_train.to_csv(f'{save_path}/pc_train_balanced.csv', index=False, encoding='utf-8-sig')\n","p_dev.to_csv(f'{save_path}/pc_dev.csv', index=False, encoding='utf-8-sig')"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
