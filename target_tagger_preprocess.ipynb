{"cells":[{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1666249058207,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"MbTADoPibruA"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForMaskedLM, \n",")\n","\n","# import nlpaug.augmenter.char as nac\n","# import nlpaug.augmenter.word as naw\n","# import nlpaug.augmenter.sentence as nas\n","# import nlpaug.flow as nafc\n","# from nlpaug.util import Action\n","\n","# from googletrans import Translator\n","# import translators as ts\n","\n","import re, math, random, json\n","from copy import deepcopy\n","from sklearn.model_selection import StratifiedKFold\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import Counter\n","\n","from module.preprocess import decorate_form, decorate_acd_pair, decorate_asc_pair, decorate_acd_pair_split, decorate_asc_pair_split\n","\n","import demoji\n","\n","# from cleantext import clean\n","# from pykospacing import Spacing\n","# from hanspell import spell_checker"]},{"cell_type":"markdown","metadata":{},"source":["# Load Raw Data"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1666249059795,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"NjTs0B-pbxm6"},"outputs":[],"source":["train_json = './dataset/nikluge-sa-2022-train.jsonl'\n","dev_json = './dataset/nikluge-sa-2022-dev.jsonl'\n","test_json = './dataset/nikluge-sa-2022-test.jsonl'\n","\n","train = pd.read_json(train_json, lines=True)\n","dev = pd.read_json(dev_json, lines=True)\n","test = pd.read_json(test_json, lines=True)\n","\n","train = train.drop(2319)\n","dev = dev.drop(1692)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentence_form</th>\n","      <th>annotation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>nikluge-sa-2022-train-00001</td>\n","      <td>둘쨋날은 미친듯이 밟아봤더니 기어가 헛돌면서 틱틱 소리가 나서 경악.</td>\n","      <td>[[본품#품질, [기어, 16, 18], negative]]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>nikluge-sa-2022-train-00002</td>\n","      <td>이거 뭐 삐꾸를 준 거 아냐 불안하고, 거금 투자한 게 왜 이래.. 싶어서 정이 확...</td>\n","      <td>[[본품#품질, [기어 텐션, 67, 72], negative]]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>nikluge-sa-2022-train-00003</td>\n","      <td>간사하게도 그 이후에는 라이딩이 아주 즐거워져서 만족스럽게 탔다.</td>\n","      <td>[[제품 전체#일반, [None, 0, 0], positive]]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nikluge-sa-2022-train-00004</td>\n","      <td>샥이 없는 모델이라 일반 도로에서 타면 노면의 진동 때문에 손목이 덜덜덜 떨리고 이...</td>\n","      <td>[[제품 전체#일반, [샥이 없는 모델, 0, 8], neutral]]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>nikluge-sa-2022-train-00005</td>\n","      <td>안장도 딱딱해서 엉덩이가 아팠는데 무시하고 타고 있다.</td>\n","      <td>[[본품#일반, [안장, 0, 2], negative]]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>nikluge-sa-2022-train-02997</td>\n","      <td>(슬픔)</td>\n","      <td>[[제품 전체#가격, [None, 0, 0], negative]]</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>nikluge-sa-2022-train-02998</td>\n","      <td>보드랍고 괜찮다!</td>\n","      <td>[[제품 전체#품질, [None, 0, 0], positive]]</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>nikluge-sa-2022-train-02999</td>\n","      <td>#일본 유니클로 질이 우리나라보다 좋은 것 같으면 기분 탓인가.......</td>\n","      <td>[[브랜드#일반, [유니클로, 4, 8], neutral]]</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>nikluge-sa-2022-train-03000</td>\n","      <td>마지막으로 귀여워서 집어온 모자.</td>\n","      <td>[[제품 전체#디자인, [모자, 15, 17], positive]]</td>\n","    </tr>\n","    <tr>\n","      <th>3000</th>\n","      <td>nikluge-sa-2022-train-03001</td>\n","      <td>일본유니클로 사랑해!!!!!!!</td>\n","      <td>[[브랜드#일반, [일본유니클로, 0, 6], positive]]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows × 3 columns</p>\n","</div>"],"text/plain":["                               id  \\\n","0     nikluge-sa-2022-train-00001   \n","1     nikluge-sa-2022-train-00002   \n","2     nikluge-sa-2022-train-00003   \n","3     nikluge-sa-2022-train-00004   \n","4     nikluge-sa-2022-train-00005   \n","...                           ...   \n","2996  nikluge-sa-2022-train-02997   \n","2997  nikluge-sa-2022-train-02998   \n","2998  nikluge-sa-2022-train-02999   \n","2999  nikluge-sa-2022-train-03000   \n","3000  nikluge-sa-2022-train-03001   \n","\n","                                          sentence_form  \\\n","0                둘쨋날은 미친듯이 밟아봤더니 기어가 헛돌면서 틱틱 소리가 나서 경악.   \n","1     이거 뭐 삐꾸를 준 거 아냐 불안하고, 거금 투자한 게 왜 이래.. 싶어서 정이 확...   \n","2                  간사하게도 그 이후에는 라이딩이 아주 즐거워져서 만족스럽게 탔다.   \n","3     샥이 없는 모델이라 일반 도로에서 타면 노면의 진동 때문에 손목이 덜덜덜 떨리고 이...   \n","4                        안장도 딱딱해서 엉덩이가 아팠는데 무시하고 타고 있다.   \n","...                                                 ...   \n","2996                                               (슬픔)   \n","2997                                          보드랍고 괜찮다!   \n","2998          #일본 유니클로 질이 우리나라보다 좋은 것 같으면 기분 탓인가.......   \n","2999                                 마지막으로 귀여워서 집어온 모자.   \n","3000                                  일본유니클로 사랑해!!!!!!!   \n","\n","                                   annotation  \n","0           [[본품#품질, [기어, 16, 18], negative]]  \n","1        [[본품#품질, [기어 텐션, 67, 72], negative]]  \n","2        [[제품 전체#일반, [None, 0, 0], positive]]  \n","3     [[제품 전체#일반, [샥이 없는 모델, 0, 8], neutral]]  \n","4             [[본품#일반, [안장, 0, 2], negative]]  \n","...                                       ...  \n","2996     [[제품 전체#가격, [None, 0, 0], negative]]  \n","2997     [[제품 전체#품질, [None, 0, 0], positive]]  \n","2998        [[브랜드#일반, [유니클로, 4, 8], neutral]]  \n","2999    [[제품 전체#디자인, [모자, 15, 17], positive]]  \n","3000     [[브랜드#일반, [일본유니클로, 0, 6], positive]]  \n","\n","[3000 rows x 3 columns]"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["train"]},{"cell_type":"markdown","metadata":{},"source":["# Declare Stuff to use"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"ov3SPo0UK_2k"},"outputs":[],"source":["### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","\n","]\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}"]},{"cell_type":"markdown","metadata":{},"source":["# Remove annotations without a target"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["for idx, row in train.iterrows():\n","    for idx in range(len(row.annotation)):\n","        if row.annotation[idx][1][0] == None:\n","            row.annotation[idx] = []\n","    row.annotation = [el for el in row.annotation if el != []]"]},{"cell_type":"markdown","metadata":{},"source":["# Drop rows without a single annotation"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["for idx, row in train.iterrows():\n","    for annotation in row.annotation:\n","        if annotation[1][0] == None:\n","            print(row)        "]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["train['checker'] = train.annotation.apply(bool)\n","train = train[train.checker == True].copy()"]},{"cell_type":"markdown","metadata":{},"source":["# Generate token classification pairs"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["def make_token_classification_pair(original_input, annotations):\n","    targets = []\n","    for annotation in annotations:\n","        if annotation[1][0] != None:\n","            target = annotation[1][1:]\n","            targets.append(target)\n","    targets.sort()\n","    input_len = len(original_input)\n","\n","    split_input = []\n","    split_label = []\n","    pointer = 0\n","    for target in targets:\n","        start = target[0]\n","        end = target[1]\n","        if start != 0:\n","            split_input.append(original_input[pointer:start])\n","            split_label.append(0)\n","        split_input.append(original_input[start:end])\n","        split_label.append(1)\n","        pointer = end\n","    if end != len(original_input):\n","        split_input.append(original_input[end:])\n","        split_label.append(0)\n","\n","    return split_input, split_label"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"data":{"text/plain":["('디자인과 조작감에서 차이가 날 뿐인데 LEXMA 블루투스 마우스는 디자인과 조작감 둘 다 합격점.',\n"," [['본품#품질', ['조작감', 5, 8], 'positive'],\n","  ['제품 전체#디자인', ['LEXMA 블루투스 마우스', 21, 35], 'positive']])"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["### test a sample\n","train['checker'] = train.annotation.apply(len)\n","original_input = train[train.checker > 1].iloc[2].sentence_form\n","annotations = train[train.checker > 1].iloc[2].annotation\n","original_input, annotations"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["split_inputs, split_labels = [], []\n","for original_input, annotations in zip(train.sentence_form, train.annotation):\n","    split_input, split_label = make_token_classification_pair(original_input, annotations)\n","    split_inputs.append(split_input)\n","    split_labels.append(split_label)"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['둘쨋날은 미친듯이 밟아봤더니 ', '기어', '가 헛돌면서 틱틱 소리가 나서 경악.']\n","[0, 1, 0]\n","\n","['이거 뭐 삐꾸를 준 거 아냐 불안하고, 거금 투자한 게 왜 이래.. 싶어서 정이 확 떨어졌는데 산 곳 가져가서 확인하니 ', '기어 텐션', ' 문제라고 고장 아니래.']\n","[0, 1, 0]\n","\n","['샥이 없는 모델', '이라 일반 도로에서 타면 노면의 진동 때문에 손목이 덜덜덜 떨리고 이가 부딪칠 지경인데 이마저도 며칠 타면서 익숙해지니 신경쓰이지 않게 됐다.']\n","[1, 0]\n","\n","['안장', '도 딱딱해서 엉덩이가 아팠는데 무시하고 타고 있다.']\n","[1, 0]\n","\n","['지금 내 실력과 저질 체력으로는 이 정도 ', '자전거', '도 되게 훌륭한 거라는..']\n","[0, 1, 0]\n","\n","['내장 기어 3단', '은 썩 좋은 물건이라 기어 변환도 부드럽고 겉에서는 기어가 보이지 않기 때문에 깔끔하다.']\n","[1, 0]\n","\n","['한번 교환했는데 새로 온 ', 'UD20', '은 불량화소가 있고 ㅜ ㅜ ㅜ']\n","[0, 1, 0]\n","\n","['전에 작동 안되었던 ', '자막 검색 후 등록 기능', '이 똑같이 작동 안 된다!!!']\n","[0, 1, 0]\n","\n","['왜 ', '[등록]키', '를 만들어놓고 제대로 단어장에 등록이 되지 않는 거냐!!']\n","[0, 1, 0]\n","\n","['다른 ', '부가 기능', '은 참 훌륭한데..']\n","[0, 1, 0]\n","\n","['동영상 재생하면서 자막 중 모르는 내용 있으면 터치해서 바로 검색하는 기능', ' 때문에 산 건데 이게 에러다..']\n","[1, 0]\n","\n","['아까 한 번 잠깐 되더니 지금 또 ', '등록 버튼', '이 먹통이다.']\n","[0, 1, 0]\n","\n","['전자사전 기능', '은 훌륭한데 이런 게 고장이 없어야지.. ㅜ ㅜ ㅜ ㅜ ㅜ']\n","[1, 0]\n","\n","['만화책 보는 건 오케이, ', '녹음', '도 잘 되고..']\n","[0, 1, 0]\n","\n","['스펙상으로는 116g인데 집에서 저울로 재어보니 ', '118g', ', 실제로 들어보니 돌덩이 같다.']\n","[0, 1, 0]\n","\n","['동영상 변환하기 싫어서 환장할 지경이라 ', '디빅', '만으로도 얘는 가치 있다.']\n","[0, 1, 0]\n","\n","['근데 ', '터치', '가 적응이 안 돼.']\n","[0, 1, 0]\n","\n","['물론 쥐시장 가', '면', ' 천원짜리도 많겠지만 가격대비 면이 좋네.']\n","[0, 1, 0]\n","\n","['배색', '도 핑크랑 그레이라 무난하면서도 칙칙하지 않다.']\n","[1, 0]\n","\n","['민트, 솔잎', ' 이런 게 들어서 그런가 굉장히 화~~~하다. -_-;']\n","[1, 0]\n","\n","['아무래도 발이다 보니 이러고 돌아다닐 수도 없고 친절하게 ', '비닐 봉지', '가 들어있다.']\n","[0, 1, 0]\n","\n","['게다가 입구가 펄럭거리면 불편하니 ', '테잎', '도 동봉되어 있어서 이렇게 발목을 조일 수 있다.']\n","[0, 1, 0]\n","\n","['사실 난 투명 ', '컵', '이 더 좋은데 다들 색깔이 연하게 들어가있다.']\n","[0, 1, 0]\n","\n","['역시 ', '코카콜라 컵', '이라 콜라가 더 잘 어울린다.']\n","[0, 1, 0]\n","\n","['사이즈', '가 평소 마시는 것보다 약간 커서 넉넉하게 담을 수 있는 건 좋은데 설거지하기에는 밑이 좀 깊어서 불편.']\n","[1, 0]\n","\n","['600원짜리 ', '컵', '인데 더 이상을 바랄 순 없을 듯.']\n","[0, 1, 0]\n","\n","['톰보우도 몇 백원은 준 거 같은데 ', '사쿠라폼', '은 우수한 성능에도 불구 단돈 600원.']\n","[0, 1, 0]\n","\n","['너무 이뻐서(얼굴은 보지도 않았음. 이게 병;)', '신발', '만 보면서 한참을 따라간 듯.']\n","[0, 1, 0]\n","\n","['정확하게는 ', '신발과 합체된 종아리 이하 모습', '에 반했다고 해야 맞을 듯.']\n","[0, 1, 0]\n","\n","['그래서 매장에 가봤더니 아니나 다를까 색감하며 디자인하며 이건 무슨 구석기 시대 ', '운동화', '냐 싶은게 신어보니 발은 항공모함만해 보여서 냅다 버리고 뒤도 안 돌아보고 왔단 얘기.']\n","[0, 1, 0]\n","\n","['특히 마음에 안 드는 건 ', '뒷축', '으로 클래식 시리즈는 덜 하지만 뉴발의 대개 모델들은 뒷축이 이상하게 툭 튀어나와서 좀 닳을 때까지는 눈에 너무 거슬릴 거 같다.']\n","[0, 1, 0]\n","\n","['근데 난 ', '빨강', '을 안 좋아한다.']\n","[0, 1, 0]\n","\n","['봉제선', '이 앞코 쪽에 딱 한군데 있고 맥스나 테니스 클래식 등보다 훨씬 편하다.']\n","[1, 0]\n","\n","['무게', '도 경량에 ', '에어', '가 젤타입이 아니어서 터질 우려도 없단다.']\n","[1, 0, 1, 0]\n","\n","['', '매장에서 꽤 괜찮은 놈을 세일해서 99000원에 파는 걸보고 홀딱 반했는데 한 번에 두 켤레를 살 수는 없었고 신어보니 무게감이 루나를 따라갈 수 없어서 일단 포기했다.']\n","[1, 0]\n","\n","['전자제품이라면 그것이 어떤 기능을 가졌든지 일단 좋아하지만, 그 중 극강은 역시 ', '노트북', '..']\n","[0, 1, 0]\n","\n","['처음에 마음에 든 건 아래 녹색이었는데, 이후 ', '골드', '가 출시된 것을 알고 마음이 바뀌었다.']\n","[0, 1, 0]\n","\n","['내가 이래서 ', '소니', '를 좋아해..']\n","[0, 1, 0]\n","\n","['나는 사실 핑크 별로 안 좋아하는데 다른 ', '색상', '이 다 이쁘지 않게 나왔다.']\n","[0, 1, 0]\n","\n","['-_-; ', '색 조합', '이 저게 뭐냐?']\n","[0, 1, 0]\n","\n","['흰색이면 그냥 흰색으로 밀고 나가면 되지 무슨 촌스런 ', '빨강', '이야.']\n","[0, 1, 0]\n","\n","['색', '을 저렇게 밖에 못 뽑는지 묻고 싶다.']\n","[1, 0]\n","\n","['모냥이 빠져도 난 실용주의자라 군말없이 AS해주는 ', '삼성이나 엘지', '가 좋긴 좋다.']\n","[0, 1, 0]\n","\n","['막상 도착한 ', '에코백', '은 작은 거 좋아하는 나에게도 몇 센티 쯤인가 너무 작게 느껴졌으나 디자인이 중요한 가방이라 그럭저럭 만족한다.']\n","[0, 1, 0]\n","\n","['조금 더 토톰한 ', '천', '에 5센티만 ', '폭', '이 컸어도 딱인데 아깝구나.']\n","[0, 1, 0, 1, 0]\n","\n","['밴드', '도 올리브그린과 블랙이 있었는데 알도 까만데 줄까지 까만 건 싫고 국방색은 너무 군인스럽나 싶지만 사실 아무래도 상관없다.']\n","[1, 0]\n","\n","['으하하.. 오자마자 ', '줄', '질을 하게 될 지 어떨지 몰라도 너에게는 어울리는 줄이 따로 있지 싶어.']\n","[0, 1, 0]\n","\n","['아무리 나라도 ', '카키색 줄', '을 계속 찰 수는 없잖아.']\n","[0, 1, 0]\n","\n","['근데 이거 좀 에러인게 ', '줄', '을 바꾸려면 잘라버려야 한다.']\n","[0, 1, 0]\n","\n","['마지막으로 겁나 큰 ', '초침소리', '라는데 내가 주무실 때 이 싸구려를 어디다 숨겨놔야 초침 소리를 안 들을지 연구해봐야겠다.']\n","[0, 1, 0]\n","\n","['아디다스의 상징인 삼선', '이 없어서 좋다.']\n","[1, 0]\n","\n","['방안에서 찍어서 ', '색감', '의 왜곡이 있지만 밖에서 보면 참 곱다. ㅋㅋ']\n","[0, 1, 0]\n","\n","['그래도 얇아서 덥지 않고 ', '색깔', '이 청량감이 있어서 스웨이드임에도 여름 운동화 같다.']\n","[0, 1, 0]\n","\n","['어쨌든 ', '8G 모델', '이다보니 동영상 등의 무리한 다운로드는 안할 듯 싶고 월별 기본제공되는 3G와 에그 와이브로를 병행해서 쓰면 그럭저럭 쓸만할 듯 싶다.']\n","[0, 1, 0]\n","\n","['LEXMA 블루투스 마우스', ' 쪽이 크기도 작고 디자인도 좋다.']\n","[1, 0]\n","\n","['LEXMA', '의 디자인이 월등히 낫다.']\n","[1, 0]\n","\n","['이런 점을 감안하면 블루투스 제품마다 모조리 ', '리시버', '가 들어있어야 하는 것도 말이 안되고 최근 기기는 블루투스 지원은 기본이니 불만사항이 될 순 없겠다.']\n","[0, 1, 0]\n","\n","['전체적으로 마우스의 크기가 작기 때문에 ', '온오프 스위치와 커넥트 버튼', '이 작다.']\n","[0, 1, 0]\n","\n","['LEXMA 블루투스 마우스', '는 크기가 작아 어딘가 갈 때 UMPC와 함께 들고 다니기에도 편리할 듯 싶다.']\n","[1, 0]\n","\n","['마우스 없이 PS3 조이패드로 인터넷을 하는 것은 힘들지만 ', '블루투스 마우스', '만 있으면 간편하게 PS3에서 인터넷을 즐길 수 있다.']\n","[0, 1, 0]\n","\n","['단, ', '휠 클릭', '은 뻑뻑해서 꽤 힘이 든다.']\n","[0, 1, 0]\n","\n","['마우스', '가 원래 거기서 거기이다보니 미세한 차이는 사람이 느끼기에 힘든 듯 싶다.']\n","[1, 0]\n","\n","['장점 : 디자인이 깔끔하다, 작아서 휴대성이 용이, ', '높낮이 조절', ' 가능, 다양한 블루투스 지원 기기에서 사용 가능.']\n","[0, 1, 0]\n","\n","['조작감', '이 좋아 편하게 이용할 수 있다.']\n","[1, 0]\n","\n","['휠 클릭', '이 뻑뻑해서 힘이 든다.']\n","[1, 0]\n","\n","['디자인과 ', '조작감', '에서 차이가 날 뿐인데 ', 'LEXMA 블루투스 마우스', '는 디자인과 조작감 둘 다 합격점.']\n","[0, 1, 0, 1, 0]\n","\n","['넷북 같은 휴대기기에 큰 마우스보단 이런 적당히 ', '작은 마우스', '를 갖고 다니는 것이 편리하겠지만 말이다.']\n","[0, 1, 0]\n","\n","['나는 ', '릴리안', '이 제일로 좋았고 다른제품에비해 훨씬 뒤가깔끔하거기분 좋아서 이사태에서 나는 릴리안을 반품안하고 오히려 쌀때 ㅋㅋ 더 사서썼다']\n","[0, 1, 0]\n","\n","['귀염귀염 ', '세일러느낌', '이에요']\n","[0, 1, 0]\n","\n","['전반적으로 ', '제이스타일 옷들', '은 핏이참 이쁜듯해요']\n","[0, 1, 0]\n","\n","['재질', '도 똑떨어지면서 색상도 너무예뻐요']\n","[1, 0]\n","\n","['제이스타일 옷들', '은 전반적으로 핏이참 예쁘게 떨어지는듯해요 ^^']\n","[1, 0]\n","\n","['#&name&이유식 들어가면서 만들어줘야겠다.. 생각했는데 역시나 넘나 간편한 #', '베이비쿡솔로', ' ..']\n","[0, 1, 0]\n","\n","['아이들이 있는 집 필수품`-` #', '하이맘밴드', ' ..']\n","[0, 1, 0]\n","\n","['색상', '이 보니 어느정도 투명해서 티도.. 많이 안나고 >_< ', '전용가위', '까지 센스 쩔..']\n","[1, 0, 1, 0]\n","\n","['밖에 나올때에도 유용한 .. #', '포리프 #고래거치대', ' ㅋㅋ..']\n","[0, 1, 0]\n","\n","['땠다.. 붙었다가 가능한 #', '젤패드', ' 라 굳 ..']\n","[0, 1, 0]\n","\n","['#', '향기', ' 까지 나는 거치대라 더 좋고마잉 ~']\n","[0, 1, 0]\n","\n","['처음에는 높은 ', '베개', ' 사용으로 낮은 거에 대한.. 느낌적인 부분으로 이상하게 느껴졌는데.. 3~4일 잘 견디니깐 이젠 익숙해지고 .. 확실히 아침이 조금 더 개운함이 있네요..']\n","[0, 1, 0]\n","\n","['태어나서부터 참 잘 사용중인.. #', '대디베이비', ' >_<']\n","[0, 1, 0]\n","\n","['>_< 피부 진정에 도움이 된다는 #', '바디미스트', ' 챙겨요..']\n","[0, 1, 0]\n","\n","['더군다나 여름철 야외 활동할 때 모기기피제로 많이 쓰는 ', '레몬그라스 향', '이 있어.. 야외활동 속 피부를 보호해주는 #일리윤 의 #바디미스트추천 신상제품']\n","[0, 1, 0]\n","\n","['캠핑이나 등산 요즘 많이들 다니는 여행시에 좋은.. #', '컴포트레스트아웃도어미스트', ' >_< ..']\n","[0, 1, 0]\n","\n","['거품형', '이라 편하기 까지 함 ㅋㅋ...']\n","[1, 0]\n","\n","['#', '한샘샘키즈프리미엄 실리콘 코팅', '이라.. 더 안심되고 열 PE라서 뛰어도 크게.. 아래집에 민폐가 되지 않는 거 같아요..']\n","[0, 1, 0]\n","\n","['이번에 #', '소르베베시그니처', ' 이뿌더라..']\n","[0, 1, 0]\n","\n","['#', '소르베베', ' 편안해서 요즘 인기 많던데.. ', '프리미엄시그니처', '는 디자인도 예쁨하네..']\n","[0, 1, 0, 1, 0]\n","\n","['아기띠', ' 한다고 지못미 스타일 되지 않게.. 멋스럽게 착용할 수 있는 #아기띠']\n","[1, 0]\n","\n","['제트블루 컬러가 우리한테 어울릴 것 같았는데.. 친구가 ', '코코아 브라운', ' 착용한거보니 괜찮더라구요.']\n","[0, 1, 0]\n","\n","['여러모로 #스타일링 까지 신경쓴 이번 ', '프리미엄', '..']\n","[0, 1, 0]\n","\n","['#국민방수요 이름을 가지고 있는.. #', '뮤라', ' `-`']\n","[0, 1, 0]\n","\n","['재질', '도 좋고.. 세탁기 빨래도.. 건조도 가능하니깐 넘나 좋음 >_< ..']\n","[1, 0]\n","\n","['그래도 우리 둘째는 #', '여름기저귀 #대디베이비', ' 팡팡 갈아주며. 뽀송뽀송하게 유지하고 있어요.']\n","[0, 1, 0]\n","\n","['#밤기저귀 #아기기저귀 손색없을.. 정도로 잘 사용하고 팬티라 활동이 좋으니깐.. 막 뛰어 놀아도 벗겨지지 않고 스스로 막 벗으려고.. 들어도 #', '팬티기저귀', ' 라서 좋은데..']\n","[0, 1, 0]\n","\n","['그래서 진통이나 소염 부기방지에 도움이 된다는 #', '베노플러스겔', ' 을 챙겨서 다니는 편이에요..']\n","[0, 1, 0]\n","\n","['이젠 #신생아아기띠 벗어나나 싶지만.. 요즘은 #', '올인원아기띠', ' 로 #아기띠 부터.. #힙시트 까지도 모두 한번에 해결이 되죠..']\n","[0, 1, 0]\n","\n","['가성비 좋고 실용성 좋은 #', '토드비', '', '토드비', ' 착용하는데.. ', '스타일', '도 ', '색상', '도 예쁘고 ', '재질', '도 부드러워서.. 만족만족..']\n","[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n","\n","['통기성', ' 좋고 가볍고 ', '샘방지', '도.. 잘되어있는 ', '3중파워흡수', ' ..']\n","[1, 0, 1, 0, 1, 0]\n","\n","['100% 미국산 #천연코튼', ' 함유로.. 부드럽고 자극적이지 않네여..']\n","[1, 0]\n","\n"]}],"source":["count = 0\n","for x, y in zip(split_inputs, split_labels):\n","    print(x)\n","    print(y)\n","    print()\n","    count += 1\n","    if count == 99:\n","        break"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"data":{"text/plain":["(['디자인과 ', '조작감', '에서 차이가 날 뿐인데 ', 'LEXMA 블루투스 마우스', '는 디자인과 조작감 둘 다 합격점.'],\n"," [0, 1, 0, 1, 0])"]},"execution_count":104,"metadata":{},"output_type":"execute_result"}],"source":["make_token_classification_pair(original_input, annotations)"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[5, 8], [21, 35]]\n"]}],"source":["targets = []\n","\n","for annotation in annotations:\n","    if annotation[1][0] != None:\n","        target = annotation[1][1:]\n","        targets.append(target)\n","targets.sort()\n","print(targets)"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["input_len = len(original_input)\n","split_input = []\n","label = []\n","pointer = 0\n","for target in targets:\n","    start = target[0]\n","    end = target[1]\n","    if start != 0:\n","        split_input.append(original_input[pointer:start])\n","        label.append(0)\n","    split_input.append(original_input[start:end])\n","    label.append(1)\n","    pointer = end\n","if end != len(original_input):\n","    split_input.append(original_input[end:])\n","    label.append(0)"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/plain":["('디자인과 조작감에서 차이가 날 뿐인데 LEXMA 블루투스 마우스는 디자인과 조작감 둘 다 합격점.',\n"," ['디자인과 ', '조작감', '에서 차이가 날 뿐인데 ', 'LEXMA 블루투스 마우스', '는 디자인과 조작감 둘 다 합격점.'],\n"," [0, 1, 0, 1, 0])"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["original_input, split_input, label"]},{"cell_type":"markdown","metadata":{},"source":["# Count"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tags found:  1811\n","tag set of df:  21\n","tag set of offered:  25\n","difference:  {'패키지/구성품#가격', '브랜드#디자인', '제품 전체#다양성', '본품#가격'}\n"]},{"data":{"text/plain":["[('본품#품질', 561),\n"," ('제품 전체#일반', 434),\n"," ('본품#일반', 239),\n"," ('제품 전체#품질', 136),\n"," ('제품 전체#디자인', 85),\n"," ('본품#편의성', 48),\n"," ('제품 전체#편의성', 47),\n"," ('브랜드#일반', 47),\n"," ('패키지/구성품#디자인', 44),\n"," ('제품 전체#인지도', 37),\n"," ('패키지/구성품#편의성', 33),\n"," ('패키지/구성품#일반', 23),\n"," ('본품#다양성', 17),\n"," ('제품 전체#가격', 15),\n"," ('본품#디자인', 14),\n"," ('브랜드#품질', 11),\n"," ('패키지/구성품#품질', 10),\n"," ('브랜드#인지도', 7),\n"," ('브랜드#가격', 1),\n"," ('패키지/구성품#다양성', 1),\n"," ('본품#인지도', 1)]"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.concat([train, dev])\n","df = pd.concat([train])\n","\n","count = 0\n","tags = []\n","ner_inputs = []\n","for idx, row in df.iterrows():\n","    if len(row.annotation) > 0:\n","        for annotation in row.annotation:\n","            form = row.sentence_form\n","            if annotation[1][0] != None and annotation[1][2] > 0:\n","                tags.append(annotation[0])\n","                ner_input = []\n","                start = annotation[1][1]\n","                end = annotation[1][2]\n","                if start != 0:\n","                    ner_input.append(form[:start])\n","                ner_input.append(form[start:end])\n","                if len(form) != end:\n","                    ner_input.append(form[end:])\n","                count += 1\n","            else:\n","                tags.append(annotation[0])\n","                ner_input = []\n","                ner_input.append(form)\n","                count += 1\n","            ner_inputs.append(ner_input)\n","\n","print('tags found: ', count)\n","print('tag set of df: ', len(set(tags)))\n","print('tag set of offered: ', len(set(entity_property_pair)))\n","print('difference: ', set(entity_property_pair)-set(tags))\n","\n","tag_counter = Counter(tags)\n","sorted(tag_counter.items(), key=lambda x: x[1], reverse=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Filter entity_property_pair and Drop rows accordingly"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FILTER_MODE = False\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성',\n","#           '제품 전체#편의성',\n","#           '제품 전체#인지도',\n","#           '패키지/구성품#디자인',\n","#           '브랜드#일반',\n","#           '제품 전체#가격']  # 2716\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성',\n","#           '제품 전체#편의성',\n","#           '제품 전체#인지도',\n","#           '패키지/구성품#디자인',\n","#           '브랜드#일반'] # 2676\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성',\n","#           '제품 전체#편의성',\n","#           '제품 전체#인지도',\n","#           '패키지/구성품#디자인']  # 2627\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성',\n","#           '제품 전체#편의성',\n","#           '제품 전체#인지도']  # 2575\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성',\n","#           '제품 전체#편의성'] # 2509\n","\n","# filter = ['본품#품질',\n","#           '제품 전체#일반',\n","#           '본품#일반',\n","#           '제품 전체#품질',\n","#           '제품 전체#디자인',\n","#           '본품#편의성'] # 2421\n","\n","filter = ['본품#품질',\n","          '제품 전체#일반',\n","          '본품#일반',\n","          '제품 전체#품질',\n","          '제품 전체#디자인'] # 2339\n","\n","\n","def remove_props(df):\n","    for idx, row in df.iterrows():\n","        empty = []\n","        stay = True\n","        for annotation in row.annotation:\n","            if annotation[0] not in filter:\n","            # if annotation[0] not in filter or annotation[2] != 'positive':\n","                stay = False\n","        if stay == False:\n","            row.annotation = empty\n","    df['check'] = df.annotation.apply(lambda x: bool(x))\n","    df = df.drop(df[df.check == False].index)\n","    return df\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if FILTER_MODE == True:\n","    train = remove_props(train)\n","    dev = remove_props(dev)\n","len(train), len(dev)"]},{"cell_type":"markdown","metadata":{"id":"hkFQP8GW4SXT"},"source":["# Preprocess"]},{"cell_type":"markdown","metadata":{},"source":["## Cleansing"]},{"cell_type":"markdown","metadata":{"id":"PII4v9rJLzaV"},"source":["### Before"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1666249062532,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"oBhyEPcfmFdB","outputId":"362f9678-bda2-4ded-f372-23c0e9fdd36d"},"outputs":[],"source":["# for el in train.sample(n=5).sentence_form:\n","#     print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5570,"status":"ok","timestamp":1666249070279,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"zxaftwE_uq9w"},"outputs":[],"source":["# train.sentence_form = train.sentence_form.apply(preprocess)\n","# dev.sentence_form = dev.sentence_form.apply(preprocess)\n","# test.sentence_form = test.sentence_form.apply(preprocess)\n","# total = pd.concat([train, dev])"]},{"cell_type":"markdown","metadata":{"id":"B28qDpz-L47B"},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":278,"status":"ok","timestamp":1666249157277,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"TmQV4tDyycbX"},"outputs":[],"source":["# case = total.sentence_form.str.contains('r[^A-Za-z0-9가-힣\\s]+', case=False, flags=0, na=None, regex=True)\n","# for e in total[case].sentence_form:\n","#     print(e)"]},{"cell_type":"markdown","metadata":{"id":"ymHR_z-7L3LW"},"source":["### After"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666249070568,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"I94k-mG7s_q5","outputId":"9e82bf97-1530-4783-9fb3-80c82299a3c3"},"outputs":[],"source":["# for i, row in total[['id', 'sentence_form']].sample(n=5).iterrows():\n","#     print(row.id, '\\t', row.sentence_form)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# total['check'] = total.sentence_form.str.find('OO')\n","# for row in total[total.check > -1].sentence_form:\n","#     print(row)\n","#     break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# total"]},{"cell_type":"markdown","metadata":{"id":"25AnAYGke6BQ"},"source":["## Reformat"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666184223688,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"cRZR6lTRED9s","outputId":"08f43287-453a-4377-fe1b-e7d8b3fe6fd8"},"outputs":[],"source":["len(entity_property_pair)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["decorate_form, decorate_acd_pair, decorate_asc_pair, decorate_acd_pair_split, decorate_asc_pair_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9K9UG5aybovX"},"outputs":[],"source":["def reformat(df):\n","    ep =[]\n","    p = []\n","    for index, row in df.iterrows():\n","        utterance = row.sentence_form\n","        id = row.id\n","        \n","        form = utterance\n","        # form = decorate_form(utterance)\n","\n","        for pair in entity_property_pair:\n","            isPairInOpinion = False\n","            if pd.isna(utterance):\n","                break\n","            for annotation in row.annotation:\n","                entity_property = annotation[0]\n","                sentiment = annotation[2]\n","                if entity_property == pair:\n","                    \n","                    acd_pair = entity_property\n","                    # acd_pair = decorate_acd_pair(entity_property)\n","                    # acd_pair = decorate_acd_pair_split(entity_property)\n","                    \n","                    ep_append = [id, form, acd_pair, tf_name_to_id['True']]\n","                    ep.append(ep_append)\n","                    p.append([id, utterance, entity_property, sentiment])\n","                    isPairInOpinion = True\n","                    break\n","            if isPairInOpinion is False:\n","                \n","                acd_pair = pair\n","                # acd_pair = decorate_acd_pair(pair)\n","                # acd_pair = decorate_acd_pair_split(pair)\n","                \n","                ep_append = [id, form, acd_pair, tf_name_to_id['False']]\n","                ep.append(ep_append)\n","    return ep, p"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def reformat_p_binary(df):\n","    p_binary = []\n","    for i, row in df.iterrows():\n","        row.id, row.form, row.pair, row.sentiment\n","        \n","        form = row.form\n","        # form = decorate_form(row.form)\n","        \n","        for sentiment in polarity_id_to_name:\n","            if sentiment == row.sentiment:\n","\n","                asc_pair = '#'.join([row.pair, row.sentiment])\n","                # asc_pair = decorate_asc_pair(row.pair, row.sentiment)\n","                # asc_pair = decorate_asc_pair_split(row.pair, row.sentiment)\n","\n","                p_binary_append = [row.id, form, asc_pair, tf_name_to_id['True']]\n","                p_binary.append(p_binary_append)\n","            else:\n","\n","                asc_pair = '#'.join([row.pair, sentiment])\n","                # asc_pair = decorate_asc_pair(row.pair, sentiment)\n","                # asc_pair = decorate_asc_pair_split(row.pair, sentiment)\n","\n","                p_binary_append = [row.id, form, asc_pair, tf_name_to_id['False']]\n","                p_binary.append(p_binary_append)\n","    return p_binary"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(train), len(dev)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unJ9pUXwYTTm"},"outputs":[],"source":["ep_train, p_train = reformat(train)\n","ep_dev, p_dev = reformat(dev)\n","\n","ep_train = pd.DataFrame(ep_train, columns=['id', 'form', 'pair', 'labels'])\n","ep_dev = pd.DataFrame(ep_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","p_train = pd.DataFrame(p_train, columns=['id', 'form', 'pair', 'sentiment'])\n","p_dev = pd.DataFrame(p_dev, columns=['id', 'form', 'pair', 'sentiment'])\n","\n","len(ep_train), len(ep_dev), len(p_train), len(p_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["p_binary_train = reformat_p_binary(p_train)\n","p_binary_train = pd.DataFrame(p_binary_train, columns=['id', 'form', 'pair', 'labels'])\n","\n","p_binary_dev = reformat_p_binary(p_dev)\n","p_binary_dev = pd.DataFrame(p_binary_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ep_train.sort_values(['id', 'labels'], inplace=True)\n","# ep_dev.sort_values(['id', 'labels'], inplace=True)\n","# p_binary_train.sort_values(['id', 'labels'], inplace=True, ascending=[True, True])\n","# p_binary_dev.sort_values(['id', 'labels'], inplace=True, ascending=[True, True])"]},{"cell_type":"markdown","metadata":{"id":"rjaoyM97e9PQ"},"source":["### Counting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"GFroeNPQc-DZ","outputId":"bce5e0c2-0423-4db7-982a-23d5b68b8618"},"outputs":[],"source":["print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))\n","print('binary_binary: ', end=''), print(len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev))\n","ep_train = ep_train.drop_duplicates()\n","ep_dev = ep_dev.drop_duplicates()\n","p_train = p_train.drop_duplicates()\n","p_dev = p_dev.drop_duplicates()\n","p_binary_train = p_binary_train.drop_duplicates()\n","p_binary_dev = p_binary_dev.drop_duplicates()\n","print('\\nafter drop_duplicates\\n')\n","print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))\n","print('binary_binary: ', end=''), print(len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev))"]},{"cell_type":"markdown","metadata":{},"source":["### Validate Here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = ep_train\n","for idx, row in df.iterrows():\n","    print(row.id, '\\n',\n","          row.form, '\\n',\n","          row.pair, '\\n',\n","          row.labels,  '\\n',)\n","    if idx == 49:\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["### Save"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DATA_V = 'uncleaned_v6'\n","save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mkdir -p {save_path}\n","\n","train.to_csv(f'{save_path}/raw_train.csv', index=False)\n","dev.to_csv(f'{save_path}/raw_dev.csv', index=False)\n","test.to_csv(f'{save_path}/raw_test.csv', index=False)\n","\n","ep_train.to_csv(f'{save_path}/ce_train.csv', index=False)\n","ep_dev.to_csv(f'{save_path}/ce_dev.csv', index=False)\n","\n","p_binary_train.to_csv(f'{save_path}/pc_binary_train.csv', index=False)\n","p_binary_dev.to_csv(f'{save_path}/pc_binary_dev.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Additional Length Test If Needed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ep_train, ep_dev, p_binary_train, p_binary_dev"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_checkpoint = 'snunlp/KR-ELECTRA-discriminator'\n","\n","train_path = f'./dataset/{DATA_V}/raw_train.csv'\n","dev_path = f'./dataset/{DATA_V}/raw_dev.csv'\n","test_path = f'./dataset/{DATA_V}/raw_test.csv'\n","train = pd.read_csv(train_path)\n","dev = pd.read_csv(dev_path)\n","test = pd.read_csv(test_path)\n","\n","### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","]\n","special_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","emojis = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form], ignore_index=True, verify_integrity=True).to_frame()\n","emojis = list(set(demoji.findall(' '.join(emojis.sentence_form.to_list())).keys()))\n","ep_labels = pd.Series(entity_property_pair, name='sentence_form', copy=True)\n","\n","tokens2add = special_tokens + emojis\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","print(len(tokenizer))\n","tokenizer_train_data = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form], ignore_index=True, verify_integrity=True).to_frame().drop_duplicates()\n","tokenizer_train_data = tokenizer_train_data.sentence_form.to_list()\n","new_tokenizer = tokenizer.train_new_from_iterator(tokenizer_train_data, vocab_size=1)\n","new_tokens = set(list(new_tokenizer.vocab.keys()) + tokens2add) - set(tokenizer.vocab.keys())\n","tokenizer.add_tokens(list(new_tokens))\n","print(len(new_tokenizer))\n","print(len(tokenizer))\n","# model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ep_train, ep_dev, p_binary_train, p_binary_dev\n","len_counter = []\n","for df in [ep_train, ep_dev, p_binary_train, p_binary_dev]:\n","    for idx, row in df.iterrows():\n","        len_counter.append(len(tokenizer(row[\"form\"], row[\"pair\"], truncation=True).input_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max(len_counter)"]},{"cell_type":"markdown","metadata":{},"source":["### done here."]},{"cell_type":"markdown","metadata":{},"source":["## Save Files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save_path = './dataset/cleaned_v1'\n","\n","# train.to_csv(f'{save_path}/raw_train.csv', index=False)\n","# dev.to_csv(f'{save_path}/raw_dev.csv', index=False)\n","# test.to_csv(f'{save_path}/raw_test.csv', index=False)\n","\n","# ep_train.to_csv(f'{save_path}/ce_train.csv', index=False)\n","# ep_dev.to_csv(f'{save_path}/ce_dev.csv', index=False)\n","# p_train.to_csv(f'{save_path}/pc_train.csv', index=False)\n","# p_dev.to_csv(f'{save_path}/pc_dev.csv', index=False)\n","# p_binary_train.to_csv(f'{save_path}/pc_binary_train.csv', index=False)\n","# p_binary_dev.to_csv(f'{save_path}/pc_binary_dev.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"jAr5_Zc6HHQV"},"source":["# ASC Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJxucvEoipu2"},"outputs":[],"source":["model_checkpoint = '/content/drive/MyDrive/aspect_based_sentiment_analysis/base_model/klue_roberta_base/v2/klue_roberta_base_mlm/checkpoint-19860'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOg2ROQQi2OQ"},"outputs":[],"source":["sTokens = tokenizer.all_special_tokens\n","\n","def delTokens(sent):\n","    sent = sent.split(' ')\n","    temp = []\n","    for e in sent:\n","        if e not in sTokens:\n","            temp.append(e)\n","    return ' '.join(temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abyMklzeI81o"},"outputs":[],"source":["positive, negative, neutral = p_train[p_train.sentiment == 'positive'], p_train[p_train.sentiment == 'negative'], p_train[p_train.sentiment == 'neutral']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1666184227323,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"Vl33p6WhHmOj","outputId":"ff54ba6a-ccd2-4fb2-f716-03a4469cc43d"},"outputs":[],"source":["len(positive), len(negative), len(neutral)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666184227323,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"Tt1lAdOUHDyq","outputId":"8c17fd2d-5a8b-4f7a-ac7b-8a69604a8281"},"outputs":[],"source":["(58 * 3) * 4 * 3, (95 * 3) * 4 * 2 # bt ri rr"]},{"cell_type":"markdown","metadata":{"id":"nI6TIyYLINET"},"source":["Back Translation / Random Insertion / Random Replacement / Random Swap / Random Deletion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeypyouVr6Vk"},"outputs":[],"source":["def backTrans(text):\n","    aug1 = ts.papago(text, sleep_seconds=5, from_language='ko', to_language='en')\n","    aug1 = ts.papago(aug1, sleep_seconds=5, from_language='en', to_language='ko')\n","\n","    aug2 = ts.papago(text, sleep_seconds=5, from_language='ko', to_language='ja')\n","    aug2 = ts.papago(aug2, sleep_seconds=5, from_language='ja', to_language='ko')\n","\n","    return [aug1, aug2]\n","\n","def randomInsert(num, sample, device):\n","    aug = naw.ContextualWordEmbsAug(\n","        model_path=model_checkpoint, action=\"insert\", model_type='bert', top_k=5, aug_p=0.3, aug_min=1, aug_max=1, device=device)\n","\n","    aug_result = aug.augment(sample, n=num, num_thread=12)\n","    aug_result = list(map(delTokens, aug_result))\n","    aug_result = list(set(aug_result))\n","    return aug_result\n","\n","def randomReplace(num, sample, device):\n","    aug = naw.ContextualWordEmbsAug(\n","        model_path=model_checkpoint, action=\"insert\", model_type='bert', top_k=5, aug_p=0.3, aug_min=1, aug_max=1, device=device)\n","\n","    aug_result = aug.augment(sample, n=num, num_thread=12)\n","    aug_result = list(map(delTokens, aug_result))\n","    aug_result = list(set(aug_result))\n","    return aug_result\n","\n","def randomSwap(num, sample):\n","    aug = naw.RandomWordAug(action='swap', aug_min=1, aug_max=1, aug_p=0.3)    \n","    aug_result = aug.augment(sample, n=num, num_thread=2)\n","    aug_result = list(set(aug_result))\n","    return aug_result\n","\n","def randomSplit(num, sample):\n","    aug = naw.SplitAug(aug_min=1, aug_max=1, aug_p=0.3, min_char=3)\n","    aug_result = aug.augment(sample, n=num, num_thread=2)\n","    aug_result = list(set(aug_result))\n","    return aug_result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666184227324,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"S61gxehDqAsf","outputId":"a5a79918-c784-41e5-a0f2-7f0006086908"},"outputs":[],"source":["(58 * 3) * 5 * 4, (95 * 3) * 4 * 3 # bt ri rr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QVPawzK3Uqt"},"outputs":[],"source":["def backtransRoutine(data2augment, output_path):\n","    print('back translation started.')\n","    temp = []\n","    for row in data2augment:\n","        augs = backTrans(row[1])\n","        for aug in augs:\n","            if aug != '' and aug != row[1]:\n","                new = [row[0], aug, row[2], row[3]]\n","                if new not in data2augment:\n","                    temp.append(new)\n","    data2augment.extend(temp)\n","    print(len(f'back translation finished.\\ncurrent count: {len(data2augment)}'))\n","\n","    data_aug = pd.DataFrame(data2augment, columns=['id', 'sentence_form', 'entity_property', 'sentiment'])\n","    data_aug.to_csv(f'{output_path}', index=False)\n","\n","    return data_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ab6cjfGYqpJG"},"outputs":[],"source":["import os\n","\n","def edaRoutine(data2augment, ri, rr, output_path):\n","    print(f'current count: {len(data2augment)}')\n","    print('random insertion started.')\n","    temp = []\n","    for row in data2augment:\n","        augs = randomInsert(ri, row[1], 'cuda')\n","        for aug in augs:\n","            if aug != '' and aug != row[1]:\n","                new = [row[0], aug, row[2], row[3]]\n","                if new not in data2augment:\n","                    temp.append(new)\n","    data2augment.extend(temp)\n","    print(f'random insertion finished.\\ncurrent count: {len(data2augment)}')\n","\n","    print('random replacement started.')\n","    temp = []\n","    for row in data2augment:\n","        augs = randomReplace(rr, row[1], 'cuda')\n","        for aug in augs:\n","            if aug != '' and aug != row[1]:\n","                new = [row[0], aug, row[2], row[3]]\n","                if new not in data2augment:\n","                    temp.append(new)\n","    data2augment.extend(temp)\n","    print(f'random replacement finished.\\ncurrent count: {len(data2augment)}')\n","\n","    print('random swap and split started.')\n","    while len(data2augment) < len(positive):\n","        temp = []\n","        k = random.randrange(len(negative))\n","        id, text, entity, sentiment = data2augment[k]\n","\n","        selector = random.randint(0,1)\n","        if selector == 0:\n","            augs = randomSwap(1, text)\n","            for aug in augs:\n","                if aug != '' and aug != text:\n","                    new = [id, aug, entity, sentiment]\n","                    if new not in data2augment:\n","                        temp.append(new)\n","            data2augment.extend(temp)\n","        else:\n","            augs = randomSplit(1, text)\n","            for aug in augs:\n","                if aug != '' and aug != text:\n","                    new = [id, aug, entity, sentiment]\n","                    if new not in data2augment:\n","                        temp.append(new)\n","            data2augment.extend(temp)\n","        if len(data2augment)%25 == 0:\n","            print(f'random swap and split in progress.\\ncurrent count: {len(data2augment)}')\n","\n","    print(f'whole augmentation routine finished.\\ntotal count: {len(data2augment)}')\n","\n","    data_aug = pd.DataFrame(data2augment, columns=['id', 'sentence_form', 'entity_property', 'sentiment'])\n","    data_aug.to_csv(f'{output_path}', index=False)\n","\n","    return data_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmx-J4bu1JuU"},"outputs":[],"source":["### negative\n","# # back translation\n","\n","# data2augment = negative.values.tolist()\n","\n","output_folder = '/content/drive/MyDrive/aspect_based_sentiment_analysis/data/v11'\n","output_file = 'negative_bt.csv'\n","output_path = os.path.join(output_folder, output_file)\n","\n","# negative_bt = backtransRoutine(data2augment, output_path)\n","negative_bt = pd.read_csv(output_path)\n","negative_bt = negative_bt.values.tolist()\n","# RI / RR\n","\n","ri = 4 # times - 1\n","rr = 3 # times - 1\n","\n","output_folder = '/content/drive/MyDrive/aspect_based_sentiment_analysis/data/v11'\n","output_file = 'negative_aug.csv'\n","output_path = os.path.join(output_folder, output_file)\n","\n","# negative_aug = edaRoutine(negative_bt, ri, rr, output_path)\n","negative_aug = pd.read_csv(output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qu5fuqt5Q6AY"},"outputs":[],"source":["negative_aug\n","negative_aug = negative_aug.drop_duplicates()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GUBfkU5QIZD"},"outputs":[],"source":["# negative_aug.sample(n=15, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eP_iTJrASqcr"},"outputs":[],"source":["# negative_aug.sort_values('id').head(50).sentence_form"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XROBqEb71MmR"},"outputs":[],"source":["### neutral\n","# back translation\n","\n","# data2augment = neutral.values.tolist()\n","\n","output_folder = '/content/drive/MyDrive/aspect_based_sentiment_analysis/data/v11'\n","output_file = 'neutral_bt.csv'\n","output_path = os.path.join(output_folder, output_file)\n","\n","# neutral_bt = backtransRoutine(data2augment, output_path)\n","neutral_bt = pd.read_csv(output_path)\n","neutral_bt = neutral_bt.values.tolist()\n","\n","# RI / RR\n","\n","ri = 3 # times - 1\n","rr = 2 # times - 1\n","\n","output_folder = '/content/drive/MyDrive/aspect_based_sentiment_analysis/data/v11'\n","output_file = 'neutral_aug.csv'\n","output_path = os.path.join(output_folder, output_file)\n","\n","# neutral_aug = edaRoutine(neutral_bt, ri, rr, output_path)\n","neutral_aug = pd.read_csv(output_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MS1g9SKERC1T"},"outputs":[],"source":["neutral_aug\n","neutral_aug = neutral_aug.drop_duplicates()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gC38BqB7RFMr"},"outputs":[],"source":["# neutral_aug.sample(n=15, frac=None, replace=False, weights=None, random_state=None, axis=None, ignore_index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8v5pqYIlRheZ"},"outputs":[],"source":["# neutral_aug.sort_values('id').head(50).sentence_form"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Birg9KWWHGY2"},"outputs":[],"source":["p_train_aug = pd.concat([positive, negative_aug, neutral_aug])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"010dmjkolD3N"},"outputs":[],"source":["def reformat_p_binary(df):\n","    p_binary = []\n","    for i, row in df.iterrows():\n","        row.id, row.sentence_form, row.entity_property, row.sentiment\n","        for sentiment in polarity_id_to_name:\n","            if sentiment == row.sentiment:\n","                p_binary.append([row.id, row.sentence_form, '#'.join([row.entity_property, row.sentiment]), tf_name_to_id['True']])\n","            else: \n","                p_binary.append([row.id, row.sentence_form, '#'.join([row.entity_property, sentiment]), tf_name_to_id['False']])\n","    return p_binary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffHy0u-5kH9J"},"outputs":[],"source":["p_binary_train_aug = reformat_p_binary(p_train_aug)\n","p_binary_train_aug = pd.DataFrame(p_binary_train_aug, columns=['id', 'sentence_form', 'entity_property', 'labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666184235131,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"TcjTW80FTkU5","outputId":"9487802d-6ab8-431c-e551-a01c0eee48ba"},"outputs":[],"source":["p_binary_train_aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ue-_eGNSkJpk"},"outputs":[],"source":["p_binary_dev = reformat_p_binary(p_dev)\n","p_binary_dev = pd.DataFrame(p_binary_dev, columns=['id', 'sentence_form', 'entity_property', 'labels'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"F7JUwP81T7t7","outputId":"99179898-45db-4e4a-c226-8992dd4d7112"},"outputs":[],"source":["p_binary_dev"]},{"cell_type":"markdown","metadata":{"id":"rjaoyM97e9PQ"},"source":["# Counting"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"GFroeNPQc-DZ","outputId":"bce5e0c2-0423-4db7-982a-23d5b68b8618"},"outputs":[],"source":["len(ep_train), len(ep_dev), len(p_train), len(p_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"-UNi4guSpiOH","outputId":"59306b7c-8d3a-412d-dd30-b4ab2536de09"},"outputs":[],"source":["len(ep_train), len(ep_dev), len(p_binary_train_aug), len(p_binary_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666184237229,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"NB39FuJa_vNH","outputId":"0d143fe1-f1c8-4a3b-bcb4-fbc95fa05433"},"outputs":[],"source":["ep_train = ep_train.drop_duplicates()\n","p_binary_train_aug = p_binary_train_aug.drop_duplicates()\n","ep_dev = ep_dev.drop_duplicates()\n","p_binary_dev = p_binary_dev.drop_duplicates()\n","len(ep_train), len(ep_dev), len(p_binary_train_aug), len(p_binary_dev)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9RmADlISEwu"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PxiYbGKaFfpE"},"source":["# Export"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1666184351766,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"7AJTuriR2Wsd","outputId":"db6fdeaa-7d72-4bfd-d9fb-13114631b1b1"},"outputs":[],"source":["%cd /content/drive/MyDrive/aspect_based_sentiment_analysis/data/v11\n","\n","# train.to_csv('raw_train.csv', index=False)\n","# dev.to_csv('raw_dev.csv', index=False)\n","# test.to_csv('raw_test.csv', index=False)\n","\n","ep_train.to_csv('ce_train.csv', index=False)\n","p_binary_train_aug.to_csv('pc_binary_train_aug.csv', index=False)\n","ep_dev.to_csv('ce_dev.csv', index=False)\n","p_binary_dev.to_csv('pc_binary_dev.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QP_NZbG8fEDN"},"outputs":[],"source":["# emojis = pd.concat([ep_train.sentence_form, p_train.sentence_form, ep_dev.sentence_form, p_dev.sentence_form], ignore_index=True, verify_integrity=True).to_frame()\n","# emojis = list(set(demoji.findall(' '.join(emojis.sentence_form.to_list())).keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":833},"executionInfo":{"elapsed":964,"status":"ok","timestamp":1666184397981,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"UyUS26wMZRCu","outputId":"7d5ce0bc-49ac-48dd-9373-21f42f766349"},"outputs":[],"source":["df = pd.read_csv('ce_train.csv')\n","df[df.id == 'nikluge-sa-2022-train-00065']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1666184401423,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"izy5bCjIDTus","outputId":"03dcb49e-d238-4cd4-db55-73771d78026c"},"outputs":[],"source":["df = pd.read_csv('ce_dev.csv')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1666184405643,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"4oEfZBxBK6bG","outputId":"151fe3a5-269b-4968-ca15-a755fa237ae9"},"outputs":[],"source":["df = pd.read_csv('pc_binary_train_aug.csv')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666184410093,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"SEDxWfFhDWDs","outputId":"0726487f-297a-4de9-8738-d24ba8680fe1"},"outputs":[],"source":["df = pd.read_csv('pc_binary_dev.csv')\n","df"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
