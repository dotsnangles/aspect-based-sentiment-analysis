{"cells":[{"cell_type":"markdown","metadata":{"id":"9pZhmy9xKmZX"},"source":["# Modules and Global Variables"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":879,"status":"ok","timestamp":1666094093089,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"_v8VXBZdKuUD"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification, \n","    ElectraForTokenClassification, ElectraForSequenceClassification, ElectraTokenizerFast\n",")\n","\n","import torch, copy, json, re, os\n","from cleantext import clean\n","from tqdm import tqdm\n","from module.preprocess import preprocess\n","from module.preprocess import decorate_form, decorate_acd_pair, decorate_acd_pair_split, decorate_asc_pair, decorate_asc_pair_split\n","from module.score import evaluation_f1"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1666094096632,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"Xj_s1ZLiv9jQ"},"outputs":[],"source":["def jsonload(fname, encoding=\"utf-8\"):\n","    with open(fname, encoding=encoding) as f:\n","        j = json.load(f)\n","    return j\n","\n","def jsondump(j, fname):\n","    with open(fname, \"w\", encoding=\"UTF8\") as f:\n","        json.dump(j, f, ensure_ascii=False)\n","\n","def jsonlload(fname, encoding=\"utf-8\"):\n","    json_list = []\n","    with open(fname, encoding=encoding) as f:\n","        for line in f.readlines():\n","            json_list.append(json.loads(line))\n","    return json_list"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.12.1\n","torch.cuda.is_available(): True\n","NGPU: 4\n"]}],"source":["print(f'torch.__version__: {torch.__version__}')\n","print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n","NGPU = torch.cuda.device_count()\n","print(f'NGPU: {NGPU}')"]},{"cell_type":"markdown","metadata":{},"source":["# Paths and Modes"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1666094093090,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"T1iAj-3Vmqt0"},"outputs":[],"source":["EVAL_MODE = False\n","CATEGORY_FILTER = False\n","SENTIMENT_FILTER = False\n","\n","RESULT_SAVE_NAME = 'monologg_koelectra_base_v3_discriminator_uncleaned_v11_tagger_acd_asc.json'\n","\n","TAGGER_CHECKPOINT = 'training_results/monologg_koelectra_base_v3_discriminator_uncleaned_v11/target_tagger/monologg_koelectra_base_v3_discriminator_uncleaned_v11/checkpoint-370'\n","ACD_CHECKPOINT = 'training_results/monologg_koelectra_base_v3_discriminator_uncleaned_v11/acd/monologg_koelectra_base_v3_discriminator_uncleaned_v11/checkpoint-9750'\n","ASC_CHECKPOINT = 'training_results/monologg_koelectra_base_v3_discriminator_uncleaned_v11/asc/monologg_koelectra_base_v3_discriminator_uncleaned_v11/checkpoint-1190'\n","\n","TEST_DATA_PATH = 'dataset/nikluge-sa-2022-test.jsonl'\n","EVAL_DATA_PATH = 'dataset/nikluge-sa-2022-dev.jsonl'"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>>> >>>>> >>>>> dataset/nikluge-sa-2022-test.jsonl <<<<< <<<<< <<<<<\n","\n","{'id': 'nikluge-sa-2022-test-00001', 'sentence_form': '하나 사려고 알아보는 중인데 맘에드는거 발견', 'annotation': []}\n","{'id': 'nikluge-sa-2022-test-00002', 'sentence_form': '동양인 피부톤과 잘 어울리고 우아한 분위기를 풍긴다네?', 'annotation': []}\n","{'id': 'nikluge-sa-2022-test-00003', 'sentence_form': '근데 이건 마르살라보다 더 지나친 색 같은데..', 'annotation': []}\n","{'id': 'nikluge-sa-2022-test-00004', 'sentence_form': '나스 색조가 다 그렇지만서도 어데이셔스 라인은 진짜 색 기막히게 뽑는것 같다', 'annotation': []}\n","{'id': 'nikluge-sa-2022-test-00005', 'sentence_form': '색상만 보면 이걸 어떻게 발라.. 싶겠지만 의외로 너무너무 괜찮다', 'annotation': []}\n"]}],"source":["if EVAL_MODE == True:\n","    TEST_DATA_PATH = EVAL_DATA_PATH\n","print('>>>>> >>>>> >>>>> ', TEST_DATA_PATH, ' <<<<< <<<<< <<<<<', '\\n', sep='')\n","\n","test_data = jsonlload(TEST_DATA_PATH)\n","\n","if EVAL_MODE == True:\n","    for row in test_data:\n","        for annotation in row['annotation']:\n","            annotation.pop(1)\n","            \n","    true_data = copy.deepcopy(test_data)\n","    \n","    for row in test_data:\n","        row['annotation'] = []\n","\n","    for idx, row in enumerate(true_data):\n","        print(row)\n","        if idx == 4:\n","            break\n","    print()\n","for idx, row in enumerate(test_data):\n","    print(row)\n","    if idx == 4:\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# Inference Configs"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666094093090,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"7t7eYrTJkyCV","outputId":"f3d1a885-212a-43b2-c079-79ee276beae8"},"outputs":[{"data":{"text/plain":["25"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["if CATEGORY_FILTER == True:\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인',\n","    #           '본품#편의성',\n","    #           '제품 전체#편의성',\n","    #           '제품 전체#인지도',\n","    #           '패키지/구성품#디자인',\n","    #           '브랜드#일반',\n","    #           '제품 전체#가격']  # 2716\n","\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인',\n","    #           '본품#편의성',\n","    #           '제품 전체#편의성',\n","    #           '제품 전체#인지도',\n","    #           '패키지/구성품#디자인',\n","    #           '브랜드#일반'] # 2676\n","\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인',\n","    #           '본품#편의성',\n","    #           '제품 전체#편의성',\n","    #           '제품 전체#인지도',\n","    #           '패키지/구성품#디자인']  # 2627\n","\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인',\n","    #           '본품#편의성',\n","    #           '제품 전체#편의성',\n","    #           '제품 전체#인지도']  # 2575\n","\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인',\n","    #           '본품#편의성',\n","    #           '제품 전체#편의성'] # 2509\n","\n","    entity_property_pair = ['본품#품질',\n","            '제품 전체#일반',\n","            '본품#일반',\n","            '제품 전체#품질',\n","            '제품 전체#디자인',\n","            '본품#편의성'] # 2421\n","\n","    # entity_property_pair = ['본품#품질',\n","    #           '제품 전체#일반',\n","    #           '본품#일반',\n","    #           '제품 전체#품질',\n","    #           '제품 전체#디자인'] # 2339\n","else:\n","    ### new\n","    entity_property_pair = [\n","        '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","        '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","        '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","        '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","    ]\n","\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n","\n","target_tagger_labels = ['Other', 'TRG_B', 'TRG_I']\n","tag2id = {k: i for i, k in enumerate(target_tagger_labels)}\n","id2tag = {i: k for i, k in enumerate(target_tagger_labels)}\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","len(entity_property_pair)"]},{"cell_type":"markdown","metadata":{"id":"XSAzFxnH1ozQ"},"source":["# Load Model and Tokenizer"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3554,"status":"ok","timestamp":1666094096632,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"BlFBKYKDPNuN"},"outputs":[],"source":["tagger_model = ElectraForTokenClassification.from_pretrained(TAGGER_CHECKPOINT)\n","tagger_tokenizer = ElectraTokenizerFast.from_pretrained(TAGGER_CHECKPOINT)\n","\n","acd_model = ElectraForSequenceClassification.from_pretrained(ACD_CHECKPOINT)\n","acd_tokenizer = ElectraTokenizerFast.from_pretrained(ACD_CHECKPOINT)\n","\n","asc_model = ElectraForSequenceClassification.from_pretrained(ASC_CHECKPOINT)\n","asc_tokenizer = ElectraTokenizerFast.from_pretrained(ASC_CHECKPOINT)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(<function module.preprocess.decorate_form(form)>,\n"," <function module.preprocess.decorate_acd_pair(entity)>,\n"," <function module.preprocess.decorate_acd_pair_split(entity)>,\n"," <function module.preprocess.decorate_asc_pair(entity, sentiment)>,\n"," <function module.preprocess.decorate_asc_pair_split(entity, sentiment)>)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["decorate_form, decorate_acd_pair, decorate_acd_pair_split, decorate_asc_pair, decorate_asc_pair_split"]},{"cell_type":"markdown","metadata":{},"source":["# Inference Logic"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1666094096633,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"AW4V6ZVKdMRP"},"outputs":[],"source":["def predict_from_korean_form(tagger_tokenizer, acd_tokenizer, asc_tokenizer, tagger_model, acd_model, asc_model, data):\n","    tagger_model.to(device)\n","    tagger_model.eval()\n","    acd_model.to(device)\n","    acd_model.eval()\n","    asc_model.to(device)\n","    asc_model.eval()\n","\n","    for sentence in tqdm(data):\n","        # form = sentence['sentence_form']\n","        form = 'Target ' + sentence['sentence_form']\n","        form = re.sub('#', '', form)\n","        form = re.sub('\\xa0', ' ', form)\n","        \n","        sentence['annotation'] = []\n","        if type(form) != str:\n","            print(\"form type is wrong: \", form)\n","            continue\n","\n","        tokens = tagger_tokenizer.tokenize(form)\n","\n","        input_triplet = tagger_tokenizer(form, return_tensors='pt')\n","        input_triplet = {k:v.to(device) for k, v in input_triplet.items()}\n","\n","        output = tagger_model(**input_triplet).logits\n","        pred = output.argmax(-1)[-1].tolist()[1:-1]\n","\n","        starts = list({k:v for k, v in enumerate(pred) if v == 1}.keys())\n","        \n","        targets = []\n","        for start in starts:\n","            target = [tokens[start]]\n","            for tok, lab in zip(tokens[start+1:], pred[start+1:]):\n","                if lab != 2:\n","                    break\n","                else:\n","                    target.append(tok)\n","            targets.append(tagger_tokenizer.convert_tokens_to_string(target))\n","        \n","        if targets != []:\n","            for target in targets:\n","        \n","                for pair in entity_property_pair:\n","                    acd_pair = '#'.join([target, pair])\n","                    acd_encoded = acd_tokenizer(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","                    acd_encoded = {k:v.to(device) for k,v in acd_encoded.items()}\n","                    with torch.no_grad():\n","                        acd_outputs = acd_model(**acd_encoded)\n","                    \n","                    ce_predictions = acd_outputs['logits'].argmax(-1)\n","                    ce_result = tf_id_to_name[ce_predictions[0]]\n","\n","                    if ce_result == 'True':\n","                        sentiments = ['positive', 'negative', 'neutral']\n","                        asc_pairs = []\n","                        for sentiment in sentiments:\n","                            asc_pair = '#'.join([target, pair, sentiment])\n","                            asc_pairs.append(asc_pair)\n","\n","                        positive = asc_tokenizer(form, asc_pairs[0], truncation=True, return_tensors=\"pt\")\n","                        positive = {k:v.to(device) for k,v in positive.items()}\n","                        negative = asc_tokenizer(form, asc_pairs[1], truncation=True, return_tensors=\"pt\")\n","                        negative = {k:v.to(device) for k,v in negative.items()}\n","                        neutral = asc_tokenizer(form, asc_pairs[2], truncation=True, return_tensors=\"pt\")\n","                        neutral = {k:v.to(device) for k,v in neutral.items()}\n","\n","                        with torch.no_grad():\n","                            positive_outputs = asc_model(**positive)\n","                            negative_outputs = asc_model(**negative)\n","                            neutral_outputs = asc_model(**neutral)\n","\n","                        pc_predictions = torch.tensor([positive_outputs['logits'][0][0], negative_outputs['logits'][0][0], neutral_outputs['logits'][0][0]]).argmax(-1)\n","                        pc_result = polarity_id_to_name[pc_predictions]\n","\n","                        if SENTIMENT_FILTER == True:\n","                            if pc_result == 'positive':\n","                                if pair == '패키지/구성품#가격':\n","                                    print(f'{pair} found.')\n","                                    pair = '패키지/ 구성품#가격'\n","                                    print(f'corrected as {pair}')\n","\n","                                sentence['annotation'].append([pair, pc_result])\n","                                # print(pair, pc_result)\n","                        else:\n","                            if pair == '패키지/구성품#가격':\n","                                print(f'{pair} found.')\n","                                pair = '패키지/ 구성품#가격'\n","                                print(f'corrected as {pair}')\n","\n","                            sentence['annotation'].append([pair, pc_result])\n","                            # print(pair, pc_result)\n","\n","    return data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":577968,"status":"ok","timestamp":1666094674586,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"-rSyg8MUwcJq","outputId":"381ba7ec-0bae-4878-86f1-37eeca323995"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/2127 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#일반#positive\n","Target#제품 전체#일반#negative\n","Target#제품 전체#일반#neutral\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 1/2127 [00:01<1:05:28,  1.85s/it]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 2/2127 [00:02<40:47,  1.15s/it]  "]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#일반#positive\n","Target#제품 전체#일반#negative\n","Target#제품 전체#일반#neutral\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 3/2127 [00:02<28:26,  1.24it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","어데이셔스 라인은#본품#가격\n","어데이셔스 라인은#본품#다양성\n","어데이셔스 라인은#본품#디자인\n","어데이셔스 라인은#본품#인지도\n","어데이셔스 라인은#본품#일반\n","어데이셔스 라인은#본품#편의성\n","어데이셔스 라인은#본품#품질\n","어데이셔스 라인은#브랜드#가격\n","어데이셔스 라인은#브랜드#디자인\n","어데이셔스 라인은#브랜드#인지도\n","어데이셔스 라인은#브랜드#일반\n","어데이셔스 라인은#브랜드#품질\n","어데이셔스 라인은#제품 전체#가격\n","어데이셔스 라인은#제품 전체#다양성\n","어데이셔스 라인은#제품 전체#디자인\n","어데이셔스 라인은#제품 전체#인지도\n","어데이셔스 라인은#제품 전체#일반\n","어데이셔스 라인은#제품 전체#편의성\n","어데이셔스 라인은#제품 전체#품질\n","어데이셔스 라인은#패키지/구성품#가격\n","어데이셔스 라인은#패키지/구성품#다양성\n","어데이셔스 라인은#패키지/구성품#디자인\n","어데이셔스 라인은#패키지/구성품#일반\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 4/2127 [00:03<22:51,  1.55it/s]"]},{"name":"stdout","output_type":"stream","text":["어데이셔스 라인은#패키지/구성품#편의성\n","어데이셔스 라인은#패키지/구성품#품질\n","색상만#본품#가격\n","색상만#본품#다양성\n","색상만#본품#디자인\n","색상만#본품#인지도\n","색상만#본품#일반\n","색상만#본품#일반#positive\n","색상만#본품#일반#negative\n","색상만#본품#일반#neutral\n","색상만#본품#편의성\n","색상만#본품#품질\n","색상만#브랜드#가격\n","색상만#브랜드#디자인\n","색상만#브랜드#인지도\n","색상만#브랜드#일반\n","색상만#브랜드#품질\n","색상만#제품 전체#가격\n","색상만#제품 전체#다양성\n","색상만#제품 전체#디자인\n","색상만#제품 전체#인지도\n","색상만#제품 전체#일반\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 5/2127 [00:03<21:36,  1.64it/s]"]},{"name":"stdout","output_type":"stream","text":["색상만#제품 전체#편의성\n","색상만#제품 전체#품질\n","색상만#패키지/구성품#가격\n","색상만#패키지/구성품#다양성\n","색상만#패키지/구성품#디자인\n","색상만#패키지/구성품#일반\n","색상만#패키지/구성품#편의성\n","색상만#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 6/2127 [00:04<19:39,  1.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#디자인#positive\n","Target#제품 전체#디자인#negative\n","Target#제품 전체#디자인#neutral\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#제품 전체#품질#positive\n","Target#제품 전체#품질#negative\n","Target#제품 전체#품질#neutral\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 7/2127 [00:04<19:02,  1.85it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","컬러만#본품#가격\n","컬러만#본품#다양성\n","컬러만#본품#디자인\n","컬러만#본품#인지도\n","컬러만#본품#일반\n","컬러만#본품#일반#positive\n","컬러만#본품#일반#negative\n","컬러만#본품#일반#neutral\n","컬러만#본품#편의성\n","컬러만#본품#품질\n","컬러만#브랜드#가격\n","컬러만#브랜드#디자인\n","컬러만#브랜드#인지도\n","컬러만#브랜드#일반\n","컬러만#브랜드#품질\n","컬러만#제품 전체#가격\n","컬러만#제품 전체#다양성\n","컬러만#제품 전체#디자인\n","컬러만#제품 전체#인지도\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 8/2127 [00:05<19:09,  1.84it/s]"]},{"name":"stdout","output_type":"stream","text":["컬러만#제품 전체#일반\n","컬러만#제품 전체#편의성\n","컬러만#제품 전체#품질\n","컬러만#패키지/구성품#가격\n","컬러만#패키지/구성품#다양성\n","컬러만#패키지/구성품#디자인\n","컬러만#패키지/구성품#일반\n","컬러만#패키지/구성품#편의성\n","컬러만#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 9/2127 [00:05<18:51,  1.87it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#품질\n","T#본품#가격\n","T#본품#다양성\n","T#본품#디자인\n","T#본품#인지도\n","T#본품#일반\n","T#본품#편의성\n","T#본품#품질\n","T#브랜드#가격\n","T#브랜드#디자인\n","T#브랜드#인지도\n","T#브랜드#일반\n","T#브랜드#품질\n","T#제품 전체#가격\n","T#제품 전체#다양성\n","T#제품 전체#디자인\n","T#제품 전체#인지도\n","T#제품 전체#일반\n","T#제품 전체#편의성\n","T#제품 전체#품질\n","T#패키지/구성품#가격\n","T#패키지/구성품#다양성\n","T#패키지/구성품#디자인\n","T#패키지/구성품#일반\n","T#패키지/구성품#편의성\n","T#패키지/구성품#품질\n","대용량이라#본품#가격\n","대용량이라#본품#다양성\n","대용량이라#본품#디자인\n","대용량이라#본품#인지도\n","대용량이라#본품#일반\n","대용량이라#본품#일반#positive\n","대용량이라#본품#일반#negative\n","대용량이라#본품#일반#neutral\n","대용량이라#본품#편의성\n","대용량이라#본품#품질\n","대용량이라#브랜드#가격\n","대용량이라#브랜드#디자인\n","대용량이라#브랜드#인지도\n","대용량이라#브랜드#일반\n","대용량이라#브랜드#품질\n","대용량이라#제품 전체#가격\n","대용량이라#제품 전체#다양성\n","대용량이라#제품 전체#디자인\n","대용량이라#제품 전체#인지도\n","대용량이라#제품 전체#일반\n","대용량이라#제품 전체#편의성\n","대용량이라#제품 전체#품질\n","대용량이라#패키지/구성품#가격\n","대용량이라#패키지/구성품#다양성\n","대용량이라#패키지/구성품#디자인\n","대용량이라#패키지/구성품#일반\n","대용량이라#패키지/구성품#편의성\n","대용량이라#패키지/구성품#품질\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 10/2127 [00:06<22:15,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#일반#positive\n","Target#제품 전체#일반#negative\n","Target#제품 전체#일반#neutral\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 11/2127 [00:07<20:58,  1.68it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#일반#positive\n","Target#제품 전체#일반#negative\n","Target#제품 전체#일반#neutral\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 12/2127 [00:07<18:35,  1.90it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#품질\n","하또무기 스킨도#본품#가격\n","하또무기 스킨도#본품#다양성\n","하또무기 스킨도#본품#디자인\n","하또무기 스킨도#본품#인지도\n","하또무기 스킨도#본품#일반\n","하또무기 스킨도#본품#편의성\n","하또무기 스킨도#본품#품질\n","하또무기 스킨도#본품#품질#positive\n","하또무기 스킨도#본품#품질#negative\n","하또무기 스킨도#본품#품질#neutral\n","하또무기 스킨도#브랜드#가격\n","하또무기 스킨도#브랜드#디자인\n","하또무기 스킨도#브랜드#인지도\n","하또무기 스킨도#브랜드#일반\n","하또무기 스킨도#브랜드#품질\n","하또무기 스킨도#제품 전체#가격\n","하또무기 스킨도#제품 전체#다양성\n","하또무기 스킨도#제품 전체#디자인\n","하또무기 스킨도#제품 전체#인지도\n","하또무기 스킨도#제품 전체#일반\n","하또무기 스킨도#제품 전체#편의성\n","하또무기 스킨도#제품 전체#품질\n","하또무기 스킨도#패키지/구성품#가격\n","하또무기 스킨도#패키지/구성품#다양성\n","하또무기 스킨도#패키지/구성품#디자인\n","하또무기 스킨도#패키지/구성품#일반\n","하또무기 스킨도#패키지/구성품#편의성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 13/2127 [00:08<17:28,  2.02it/s]"]},{"name":"stdout","output_type":"stream","text":["하또무기 스킨도#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","젤타입 에센스니까#본품#가격\n","젤타입 에센스니까#본품#다양성\n","젤타입 에센스니까#본품#디자인\n","젤타입 에센스니까#본품#인지도\n","젤타입 에센스니까#본품#일반\n","젤타입 에센스니까#본품#일반#positive\n","젤타입 에센스니까#본품#일반#negative\n","젤타입 에센스니까#본품#일반#neutral\n","젤타입 에센스니까#본품#편의성\n","젤타입 에센스니까#본품#품질\n","젤타입 에센스니까#브랜드#가격\n","젤타입 에센스니까#브랜드#디자인\n","젤타입 에센스니까#브랜드#인지도\n","젤타입 에센스니까#브랜드#일반\n","젤타입 에센스니까#브랜드#품질\n","젤타입 에센스니까#제품 전체#가격\n","젤타입 에센스니까#제품 전체#다양성\n","젤타입 에센스니까#제품 전체#디자인\n","젤타입 에센스니까#제품 전체#인지도\n","젤타입 에센스니까#제품 전체#일반\n","젤타입 에센스니까#제품 전체#편의성\n","젤타입 에센스니까#제품 전체#품질\n","젤타입 에센스니까#패키지/구성품#가격\n","젤타입 에센스니까#패키지/구성품#다양성\n","젤타입 에센스니까#패키지/구성품#디자인\n","젤타입 에센스니까#패키지/구성품#일반\n","젤타입 에센스니까#패키지/구성품#편의성\n","젤타입 에센스니까#패키지/구성품#품질\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 14/2127 [00:09<23:27,  1.50it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 15/2127 [00:09<21:44,  1.62it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","수분 젤 크림 제형이에요.#본품#가격\n","수분 젤 크림 제형이에요.#본품#다양성\n","수분 젤 크림 제형이에요.#본품#디자인\n","수분 젤 크림 제형이에요.#본품#인지도\n","수분 젤 크림 제형이에요.#본품#일반\n","수분 젤 크림 제형이에요.#본품#일반#positive\n","수분 젤 크림 제형이에요.#본품#일반#negative\n","수분 젤 크림 제형이에요.#본품#일반#neutral\n","수분 젤 크림 제형이에요.#본품#편의성\n","수분 젤 크림 제형이에요.#본품#품질\n","수분 젤 크림 제형이에요.#브랜드#가격\n","수분 젤 크림 제형이에요.#브랜드#디자인\n","수분 젤 크림 제형이에요.#브랜드#인지도\n","수분 젤 크림 제형이에요.#브랜드#일반\n","수분 젤 크림 제형이에요.#브랜드#품질\n","수분 젤 크림 제형이에요.#제품 전체#가격\n","수분 젤 크림 제형이에요.#제품 전체#다양성\n","수분 젤 크림 제형이에요.#제품 전체#디자인\n","수분 젤 크림 제형이에요.#제품 전체#인지도\n","수분 젤 크림 제형이에요.#제품 전체#일반\n","수분 젤 크림 제형이에요.#제품 전체#편의성\n","수분 젤 크림 제형이에요.#제품 전체#품질\n","수분 젤 크림 제형이에요.#패키지/구성품#가격\n","수분 젤 크림 제형이에요.#패키지/구성품#다양성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 16/2127 [00:10<19:51,  1.77it/s]"]},{"name":"stdout","output_type":"stream","text":["수분 젤 크림 제형이에요.#패키지/구성품#디자인\n","수분 젤 크림 제형이에요.#패키지/구성품#일반\n","수분 젤 크림 제형이에요.#패키지/구성품#편의성\n","수분 젤 크림 제형이에요.#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 17/2127 [00:10<19:58,  1.76it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 18/2127 [00:11<19:06,  1.84it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 19/2127 [00:11<18:25,  1.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","에센스#본품#가격\n","에센스#본품#다양성\n","에센스#본품#디자인\n","에센스#본품#인지도\n","에센스#본품#일반\n","에센스#본품#편의성\n","에센스#본품#품질\n","에센스#본품#품질#positive\n","에센스#본품#품질#negative\n","에센스#본품#품질#neutral\n","에센스#브랜드#가격\n","에센스#브랜드#디자인\n","에센스#브랜드#인지도\n","에센스#브랜드#일반\n","에센스#브랜드#품질\n","에센스#제품 전체#가격\n","에센스#제품 전체#다양성\n","에센스#제품 전체#디자인\n","에센스#제품 전체#인지도\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 20/2127 [00:12<22:31,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["에센스#제품 전체#일반\n","에센스#제품 전체#편의성\n","에센스#제품 전체#품질\n","에센스#패키지/구성품#가격\n","에센스#패키지/구성품#다양성\n","에센스#패키지/구성품#디자인\n","에센스#패키지/구성품#일반\n","에센스#패키지/구성품#편의성\n","에센스#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#가격#positive\n","Target#제품 전체#가격#negative\n","Target#제품 전체#가격#neutral\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 21/2127 [00:12<20:58,  1.67it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 22/2127 [00:13<19:18,  1.82it/s]"]},{"name":"stdout","output_type":"stream","text":["포니이펙트의 겨울쿠션#본품#가격\n","포니이펙트의 겨울쿠션#본품#다양성\n","포니이펙트의 겨울쿠션#본품#디자인\n","포니이펙트의 겨울쿠션#본품#인지도\n","포니이펙트의 겨울쿠션#본품#일반\n","포니이펙트의 겨울쿠션#본품#편의성\n","포니이펙트의 겨울쿠션#본품#품질\n","포니이펙트의 겨울쿠션#브랜드#가격\n","포니이펙트의 겨울쿠션#브랜드#디자인\n","포니이펙트의 겨울쿠션#브랜드#인지도\n","포니이펙트의 겨울쿠션#브랜드#일반\n","포니이펙트의 겨울쿠션#브랜드#품질\n","포니이펙트의 겨울쿠션#제품 전체#가격\n","포니이펙트의 겨울쿠션#제품 전체#다양성\n","포니이펙트의 겨울쿠션#제품 전체#디자인\n","포니이펙트의 겨울쿠션#제품 전체#인지도\n","포니이펙트의 겨울쿠션#제품 전체#일반\n","포니이펙트의 겨울쿠션#제품 전체#일반#positive\n","포니이펙트의 겨울쿠션#제품 전체#일반#negative\n","포니이펙트의 겨울쿠션#제품 전체#일반#neutral\n","포니이펙트의 겨울쿠션#제품 전체#편의성\n","포니이펙트의 겨울쿠션#제품 전체#품질\n","포니이펙트의 겨울쿠션#패키지/구성품#가격\n","포니이펙트의 겨울쿠션#패키지/구성품#다양성\n","포니이펙트의 겨울쿠션#패키지/구성품#디자인\n","포니이펙트의 겨울쿠션#패키지/구성품#일반\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 23/2127 [00:13<18:32,  1.89it/s]"]},{"name":"stdout","output_type":"stream","text":["포니이펙트의 겨울쿠션#패키지/구성품#편의성\n","포니이펙트의 겨울쿠션#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#디자인#positive\n","Target#패키지/구성품#디자인#negative\n","Target#패키지/구성품#디자인#neutral\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n","Target#패키지/구성품#품질\n","##용기가#본품#가격\n","##용기가#본품#다양성\n","##용기가#본품#디자인\n","##용기가#본품#인지도\n","##용기가#본품#일반\n","##용기가#본품#편의성\n","##용기가#본품#품질\n","##용기가#브랜드#가격\n","##용기가#브랜드#디자인\n","##용기가#브랜드#인지도\n","##용기가#브랜드#일반\n","##용기가#브랜드#품질\n","##용기가#제품 전체#가격\n","##용기가#제품 전체#다양성\n","##용기가#제품 전체#디자인\n","##용기가#제품 전체#인지도\n","##용기가#제품 전체#일반\n","##용기가#제품 전체#편의성\n","##용기가#제품 전체#품질\n","##용기가#패키지/구성품#가격\n","##용기가#패키지/구성품#다양성\n","##용기가#패키지/구성품#디자인\n","##용기가#패키지/구성품#디자인#positive\n","##용기가#패키지/구성품#디자인#negative\n","##용기가#패키지/구성품#디자인#neutral\n","##용기가#패키지/구성품#일반\n","##용기가#패키지/구성품#일반#positive\n","##용기가#패키지/구성품#일반#negative\n","##용기가#패키지/구성품#일반#neutral\n","##용기가#패키지/구성품#편의성\n","##용기가#패키지/구성품#품질\n","퍼프 느낌이#본품#가격\n","퍼프 느낌이#본품#다양성\n","퍼프 느낌이#본품#디자인\n","퍼프 느낌이#본품#인지도\n","퍼프 느낌이#본품#일반\n","퍼프 느낌이#본품#편의성\n","퍼프 느낌이#본품#품질\n","퍼프 느낌이#브랜드#가격\n","퍼프 느낌이#브랜드#디자인\n","퍼프 느낌이#브랜드#인지도\n","퍼프 느낌이#브랜드#일반\n","퍼프 느낌이#브랜드#품질\n","퍼프 느낌이#제품 전체#가격\n","퍼프 느낌이#제품 전체#다양성\n","퍼프 느낌이#제품 전체#디자인\n","퍼프 느낌이#제품 전체#인지도\n","퍼프 느낌이#제품 전체#일반\n","퍼프 느낌이#제품 전체#편의성\n","퍼프 느낌이#제품 전체#품질\n","퍼프 느낌이#패키지/구성품#가격\n","퍼프 느낌이#패키지/구성품#다양성\n","퍼프 느낌이#패키지/구성품#디자인\n","퍼프 느낌이#패키지/구성품#디자인#positive\n","퍼프 느낌이#패키지/구성품#디자인#negative\n","퍼프 느낌이#패키지/구성품#디자인#neutral\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 24/2127 [00:15<29:37,  1.18it/s]"]},{"name":"stdout","output_type":"stream","text":["퍼프 느낌이#패키지/구성품#일반\n","퍼프 느낌이#패키지/구성품#일반#positive\n","퍼프 느낌이#패키지/구성품#일반#negative\n","퍼프 느낌이#패키지/구성품#일반#neutral\n","퍼프 느낌이#패키지/구성품#편의성\n","퍼프 느낌이#패키지/구성품#품질\n","스무스 도우 퍼프가#본품#가격\n","스무스 도우 퍼프가#본품#다양성\n","스무스 도우 퍼프가#본품#디자인\n","스무스 도우 퍼프가#본품#인지도\n","스무스 도우 퍼프가#본품#일반\n","스무스 도우 퍼프가#본품#편의성\n","스무스 도우 퍼프가#본품#품질\n","스무스 도우 퍼프가#브랜드#가격\n","스무스 도우 퍼프가#브랜드#디자인\n","스무스 도우 퍼프가#브랜드#인지도\n","스무스 도우 퍼프가#브랜드#일반\n","스무스 도우 퍼프가#브랜드#품질\n","스무스 도우 퍼프가#제품 전체#가격\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 25/2127 [00:15<25:16,  1.39it/s]"]},{"name":"stdout","output_type":"stream","text":["스무스 도우 퍼프가#제품 전체#다양성\n","스무스 도우 퍼프가#제품 전체#디자인\n","스무스 도우 퍼프가#제품 전체#인지도\n","스무스 도우 퍼프가#제품 전체#일반\n","스무스 도우 퍼프가#제품 전체#편의성\n","스무스 도우 퍼프가#제품 전체#품질\n","스무스 도우 퍼프가#패키지/구성품#가격\n","스무스 도우 퍼프가#패키지/구성품#다양성\n","스무스 도우 퍼프가#패키지/구성품#디자인\n","스무스 도우 퍼프가#패키지/구성품#일반\n","스무스 도우 퍼프가#패키지/구성품#편의성\n","스무스 도우 퍼프가#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n","Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#본품#품질#positive\n","Target#본품#품질#negative\n","Target#본품#품질#neutral\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n","Target#제품 전체#다양성\n","Target#제품 전체#디자인\n","Target#제품 전체#인지도\n","Target#제품 전체#일반\n","Target#제품 전체#편의성\n","Target#제품 전체#품질\n","Target#패키지/구성품#가격\n","Target#패키지/구성품#다양성\n","Target#패키지/구성품#디자인\n","Target#패키지/구성품#일반\n","Target#패키지/구성품#편의성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 26/2127 [00:16<23:00,  1.52it/s]"]},{"name":"stdout","output_type":"stream","text":["Target#패키지/구성품#품질\n","핑크골드 컬러로#본품#가격\n","핑크골드 컬러로#본품#다양성\n","핑크골드 컬러로#본품#디자인\n","핑크골드 컬러로#본품#인지도\n","핑크골드 컬러로#본품#일반\n","핑크골드 컬러로#본품#편의성\n","핑크골드 컬러로#본품#품질\n","핑크골드 컬러로#브랜드#가격\n","핑크골드 컬러로#브랜드#디자인\n","핑크골드 컬러로#브랜드#인지도\n","핑크골드 컬러로#브랜드#일반\n","핑크골드 컬러로#브랜드#품질\n","핑크골드 컬러로#제품 전체#가격\n","핑크골드 컬러로#제품 전체#다양성\n","핑크골드 컬러로#제품 전체#디자인\n","핑크골드 컬러로#제품 전체#인지도\n","핑크골드 컬러로#제품 전체#일반\n","핑크골드 컬러로#제품 전체#편의성\n","핑크골드 컬러로#제품 전체#품질\n","핑크골드 컬러로#패키지/구성품#가격\n","핑크골드 컬러로#패키지/구성품#다양성\n","핑크골드 컬러로#패키지/구성품#디자인\n","핑크골드 컬러로#패키지/구성품#디자인#positive\n","핑크골드 컬러로#패키지/구성품#디자인#negative\n","핑크골드 컬러로#패키지/구성품#디자인#neutral\n"]},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 27/2127 [00:16<20:55,  1.67it/s]"]},{"name":"stdout","output_type":"stream","text":["핑크골드 컬러로#패키지/구성품#일반\n","핑크골드 컬러로#패키지/구성품#편의성\n","핑크골드 컬러로#패키지/구성품#품질\n","케이스#본품#가격\n","케이스#본품#다양성\n","케이스#본품#디자인\n","케이스#본품#인지도\n","케이스#본품#일반\n","케이스#본품#편의성\n","케이스#본품#품질\n","케이스#브랜드#가격\n","케이스#브랜드#디자인\n","케이스#브랜드#인지도\n","케이스#브랜드#일반\n","케이스#브랜드#품질\n","케이스#제품 전체#가격\n","케이스#제품 전체#다양성\n","케이스#제품 전체#디자인\n","케이스#제품 전체#인지도\n","케이스#제품 전체#일반\n","케이스#제품 전체#편의성\n","케이스#제품 전체#품질\n","케이스#패키지/구성품#가격\n"]},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 28/2127 [00:17<20:04,  1.74it/s]"]},{"name":"stdout","output_type":"stream","text":["케이스#패키지/구성품#다양성\n","케이스#패키지/구성품#디자인\n","케이스#패키지/구성품#디자인#positive\n","케이스#패키지/구성품#디자인#negative\n","케이스#패키지/구성품#디자인#neutral\n","케이스#패키지/구성품#일반\n","케이스#패키지/구성품#편의성\n","케이스#패키지/구성품#품질\n","Target#본품#가격\n","Target#본품#다양성\n"]},{"name":"stderr","output_type":"stream","text":["  1%|▏         | 28/2127 [00:17<21:58,  1.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Target#본품#디자인\n","Target#본품#인지도\n","Target#본품#일반\n","Target#본품#편의성\n","Target#본품#품질\n","Target#브랜드#가격\n","Target#브랜드#디자인\n","Target#브랜드#인지도\n","Target#브랜드#일반\n","Target#브랜드#품질\n","Target#제품 전체#가격\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pred_data \u001b[39m=\u001b[39m predict_from_korean_form(tagger_tokenizer, acd_tokenizer, asc_tokenizer, tagger_model, acd_model, asc_model, copy\u001b[39m.\u001b[39;49mdeepcopy(test_data))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m EVAL_MODE \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m\n","\u001b[1;32m/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb Cell 15\u001b[0m in \u001b[0;36mpredict_from_korean_form\u001b[0;34m(tagger_tokenizer, acd_tokenizer, asc_tokenizer, tagger_model, acd_model, asc_model, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(acd_pair)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     acd_outputs \u001b[39m=\u001b[39m acd_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49macd_encoded)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m ce_predictions \u001b[39m=\u001b[39m acd_outputs[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39margmax(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B125.6.38.196/home/ubuntu/jongmin/Jeonghyeon/codes/absa/target_tagging_acd_asc_inference.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m ce_result \u001b[39m=\u001b[39m tf_id_to_name[ce_predictions[\u001b[39m0\u001b[39m]]\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py:999\u001b[0m, in \u001b[0;36mElectraForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    997\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 999\u001b[0m discriminator_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melectra(\n\u001b[1;32m   1000\u001b[0m     input_ids,\n\u001b[1;32m   1001\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1002\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1003\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1004\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1005\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1006\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1007\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1008\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1009\u001b[0m )\n\u001b[1;32m   1011\u001b[0m sequence_output \u001b[39m=\u001b[39m discriminator_hidden_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1012\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py:913\u001b[0m, in \u001b[0;36mElectraModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39membeddings_project\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    911\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_project(hidden_states)\n\u001b[0;32m--> 913\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    914\u001b[0m     hidden_states,\n\u001b[1;32m    915\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    916\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    917\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    918\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    919\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    920\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    921\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    922\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    923\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    924\u001b[0m )\n\u001b[1;32m    926\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py:581\u001b[0m, in \u001b[0;36mElectraEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    572\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    573\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    574\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    579\u001b[0m     )\n\u001b[1;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    582\u001b[0m         hidden_states,\n\u001b[1;32m    583\u001b[0m         attention_mask,\n\u001b[1;32m    584\u001b[0m         layer_head_mask,\n\u001b[1;32m    585\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    586\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    587\u001b[0m         past_key_value,\n\u001b[1;32m    588\u001b[0m         output_attentions,\n\u001b[1;32m    589\u001b[0m     )\n\u001b[1;32m    591\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    592\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py:508\u001b[0m, in \u001b[0;36mElectraLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    506\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 508\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    510\u001b[0m )\n\u001b[1;32m    511\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    513\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/transformers/models/electra/modeling_electra.py:520\u001b[0m, in \u001b[0;36mElectraLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 520\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    521\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    522\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n","File \u001b[0;32m~/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/modules/module.py:1124\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1125\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1126\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["pred_data = predict_from_korean_form(tagger_tokenizer, acd_tokenizer, asc_tokenizer, tagger_model, acd_model, asc_model, copy.deepcopy(test_data))\n","if EVAL_MODE == False:\n","    save_path = './'\n","    file_name = RESULT_SAVE_NAME\n","\n","    jsondump(pred_data, os.path.join(save_path, file_name))\n","    pred_data = jsonload(os.path.join(save_path, file_name))\n","    \n","len(test_data), len(pred_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for idx, row in enumerate(pred_data):\n","    print(row)\n","    if idx == 4:\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# Scoring"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if EVAL_MODE == True:\n","    print('ACD_CHECKPOINT: ', ACD_CHECKPOINT)\n","    print('ASC_CHECKPOINT: ', ASC_CHECKPOINT)\n","    print('INFERENCE DATA: ', TEST_DATA_PATH)\n","\n","    print('EVAL_MODE :', EVAL_MODE)\n","    print('CATEGORY_FILTER: ', CATEGORY_FILTER)\n","    if CATEGORY_FILTER == True:\n","        print('CATEGORY_FILTER LENGTH: ', len(entity_property_pair))\n","        print('FILTER: ', entity_property_pair)\n","    print('SENTIMENT_FILTER: ', SENTIMENT_FILTER)\n","\n","    result = evaluation_f1(true_data, pred_data)\n","    print(list(result.items())[0])\n","    print(list(result.items())[1])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1lKTzwHyfXqUlglH4FYVH3lca6fPTxdYY","timestamp":1665143444868},{"file_id":"1SYzd80ssw5Xa_9cqyxAgVHC8lconiyjO","timestamp":1664892294191},{"file_id":"1ol6PhPqw6eJZDA7lphJRBh83aKzP4lLr","timestamp":1664726608470},{"file_id":"1SFw-WNKMa9Ds61AP8W7feAFKz7BAHJ8P","timestamp":1664724312859},{"file_id":"1FZZECpNm4M1SB3O2esRpEC02q2TeHjn7","timestamp":1664720478054}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
