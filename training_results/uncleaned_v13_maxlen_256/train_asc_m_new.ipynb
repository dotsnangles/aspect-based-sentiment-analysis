{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0083c94b",
   "metadata": {
    "id": "p8Lb8VDc8Rak",
    "papermill": {
     "duration": 0.034773,
     "end_time": "2022-11-06T09:14:31.484456",
     "exception": false,
     "start_time": "2022-11-06T09:14:31.449683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ccf15",
   "metadata": {
    "id": "9pZhmy9xKmZX",
    "papermill": {
     "duration": 0.017759,
     "end_time": "2022-11-06T09:14:31.604372",
     "exception": false,
     "start_time": "2022-11-06T09:14:31.586613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modules and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b04692b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:31.639826Z",
     "iopub.status.busy": "2022-11-06T09:14:31.638596Z",
     "iopub.status.idle": "2022-11-06T09:14:35.377663Z",
     "shell.execute_reply": "2022-11-06T09:14:35.376426Z"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1666258918849,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "_v8VXBZdKuUD",
    "papermill": {
     "duration": 3.759605,
     "end_time": "2022-11-06T09:14:35.380268",
     "exception": false,
     "start_time": "2022-11-06T09:14:31.620663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61efcf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:35.410357Z",
     "iopub.status.busy": "2022-11-06T09:14:35.408296Z",
     "iopub.status.idle": "2022-11-06T09:14:35.454067Z",
     "shell.execute_reply": "2022-11-06T09:14:35.452488Z"
    },
    "papermill": {
     "duration": 0.063342,
     "end_time": "2022-11-06T09:14:35.457008",
     "exception": false,
     "start_time": "2022-11-06T09:14:35.393666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.7.1\n",
      "torch.cuda.is_available(): True\n",
      "NGPU: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'torch.__version__: {torch.__version__}')\n",
    "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
    "NGPU = torch.cuda.device_count()\n",
    "print(f'NGPU: {NGPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fe3d44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:35.508052Z",
     "iopub.status.busy": "2022-11-06T09:14:35.507048Z",
     "iopub.status.idle": "2022-11-06T09:14:35.517375Z",
     "shell.execute_reply": "2022-11-06T09:14:35.516369Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666258918850,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "7t7eYrTJkyCV",
    "outputId": "4a36004a-6875-4404-dc79-01c48573a154",
    "papermill": {
     "duration": 0.036695,
     "end_time": "2022-11-06T09:14:35.518994",
     "exception": false,
     "start_time": "2022-11-06T09:14:35.482299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0, 'negative': 1, 'neutral': 2}\n",
      "{0: 'positive', 1: 'negative', 2: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "### labels\n",
    "\n",
    "ce_labels = ['True', 'False']\n",
    "pc_labels = ['positive', 'negative', 'neutral']\n",
    "pc_binary_labels = ['True', 'False']\n",
    "\n",
    "labels = pc_labels\n",
    "\n",
    "label2id = {k: i for i, k in enumerate(labels)}\n",
    "id2label = {i: k for i, k in enumerate(labels)}\n",
    "num_labels = len(labels)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51295d9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:35.549401Z",
     "iopub.status.busy": "2022-11-06T09:14:35.548411Z",
     "iopub.status.idle": "2022-11-06T09:14:36.234010Z",
     "shell.execute_reply": "2022-11-06T09:14:36.232489Z"
    },
    "executionInfo": {
     "elapsed": 2145,
     "status": "ok",
     "timestamp": 1666258920989,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "Rohq6E8Lp1x1",
    "outputId": "88391cfb-80b0-436a-f862-034b00cef374",
    "papermill": {
     "duration": 0.703972,
     "end_time": "2022-11-06T09:14:36.236801",
     "exception": false,
     "start_time": "2022-11-06T09:14:35.532829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### paths and names\n",
    "\n",
    "PROJECT_NAME = 'aspect_sentiment_classification_multi'\n",
    "RUN_ID = 'uncleaned_v13_maxlen_256'\n",
    "\n",
    "DATA_V = 'uncleaned_v13'\n",
    "DATA_T = 'pc' # ce or pc\n",
    "AUGMENTATION = False\n",
    "AUG_NAME = 'balanced'\n",
    "\n",
    "model_checkpoint = 'klue_roberta_base_mlm_fine_tuned'\n",
    "\n",
    "notebook_name = 'trainer_for_asc_m_new.ipynb'\n",
    "\n",
    "### fixed\n",
    "\n",
    "model_name = re.sub(r'[/-]', r'_', model_checkpoint).lower()\n",
    "run_name = f'{model_name}_{RUN_ID}'\n",
    "\n",
    "ROOT_PATH = './'\n",
    "SAVE_PATH = os.path.join(ROOT_PATH, 'training_results', RUN_ID, 'asc')\n",
    "NOTEBOOK_PATH = os.path.join(ROOT_PATH, notebook_name)\n",
    "\n",
    "augornot = f'_{AUG_NAME}' if AUGMENTATION is True else ''\n",
    "TRAIN_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_train{augornot}.csv')\n",
    "EVAL_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_dev.csv')\n",
    "\n",
    "!mkdir -p {SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd29669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:36.266724Z",
     "iopub.status.busy": "2022-11-06T09:14:36.265541Z",
     "iopub.status.idle": "2022-11-06T09:14:36.277810Z",
     "shell.execute_reply": "2022-11-06T09:14:36.276420Z"
    },
    "papermill": {
     "duration": 0.029335,
     "end_time": "2022-11-06T09:14:36.279741",
     "exception": false,
     "start_time": "2022-11-06T09:14:36.250406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint: klue_roberta_base_mlm_fine_tuned\n",
      "DATA_V: uncleaned_v13\n",
      "./training_results/uncleaned_v13_maxlen_256/asc exists.\n",
      "./trainer_for_asc_m_new.ipynb does not exist.\n",
      "./dataset/uncleaned_v13/pc_train.csv exists.\n",
      "./dataset/uncleaned_v13/pc_dev.csv exists.\n"
     ]
    }
   ],
   "source": [
    "print(f'model_checkpoint: {model_checkpoint}')\n",
    "print(f'DATA_V: {DATA_V}')\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    print(f'{SAVE_PATH} exists.')\n",
    "else:\n",
    "    print(f'{SAVE_PATH} does not exist.')\n",
    "if os.path.exists(NOTEBOOK_PATH):\n",
    "    print(f'{NOTEBOOK_PATH} exists.')\n",
    "else:\n",
    "    print(f'{NOTEBOOK_PATH} does not exist.')\n",
    "if os.path.exists(TRAIN_DATA_PATH):\n",
    "    print(f'{TRAIN_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{TRAIN_DATA_PATH} does not exist.')\n",
    "if os.path.exists(EVAL_DATA_PATH):\n",
    "    print(f'{EVAL_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{EVAL_DATA_PATH} does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bdb4b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:36.307585Z",
     "iopub.status.busy": "2022-11-06T09:14:36.306421Z",
     "iopub.status.idle": "2022-11-06T09:14:36.317460Z",
     "shell.execute_reply": "2022-11-06T09:14:36.316390Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666258920989,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "HnBF0kLyk4Z4",
    "papermill": {
     "duration": 0.030962,
     "end_time": "2022-11-06T09:14:36.323307",
     "exception": false,
     "start_time": "2022-11-06T09:14:36.292345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      "learning_rate: 1.2e-05\n",
      "num_train_epochs: 10\n"
     ]
    }
   ],
   "source": [
    "### rest of training args\n",
    "\n",
    "report_to=\"wandb\"\n",
    "\n",
    "fp16 = False\n",
    "\n",
    "num_train_epochs = 10\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "optim = 'adamw_hf' # 'adamw_torch'\n",
    "\n",
    "learning_rate = 3e-6 / 8 * batch_size * NGPU # 5e-5\n",
    "weight_decay = 0.01 # 0\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0\n",
    "\n",
    "save_total_limit = 2\n",
    "\n",
    "load_best_model_at_end = True\n",
    "metric_for_best_model ='f1_macro'\n",
    "\n",
    "save_strategy = \"epoch\"\n",
    "evaluation_strategy = \"epoch\"\n",
    "\n",
    "logging_strategy = \"steps\"\n",
    "logging_first_step = True \n",
    "logging_steps = 100\n",
    "\n",
    "print(f'batch_size: {batch_size}')\n",
    "print(f'learning_rate: {learning_rate}')\n",
    "print(f'num_train_epochs: {num_train_epochs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d481a24",
   "metadata": {
    "id": "yXVsV8jQpreV",
    "papermill": {
     "duration": 0.014448,
     "end_time": "2022-11-06T09:14:36.361724",
     "exception": false,
     "start_time": "2022-11-06T09:14:36.347276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# WandB Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2ad24d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:36.392609Z",
     "iopub.status.busy": "2022-11-06T09:14:36.391444Z",
     "iopub.status.idle": "2022-11-06T09:14:38.034333Z",
     "shell.execute_reply": "2022-11-06T09:14:38.032509Z"
    },
    "executionInfo": {
     "elapsed": 4727,
     "status": "ok",
     "timestamp": 1666258925707,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "P0IR11QyPy26",
    "outputId": "1d7538ee-93e1-419d-ee09-4011e6742d6f",
    "papermill": {
     "duration": 1.661112,
     "end_time": "2022-11-06T09:14:38.037034",
     "exception": false,
     "start_time": "2022-11-06T09:14:36.375922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./trainer_for_asc_m_new.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=aspect_sentiment_classification_multi\n",
      "env: WANDB_NOTEBOOK_NAME=./trainer_for_asc_m_new.ipynb\n",
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_WATCH=all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env WANDB_PROJECT={PROJECT_NAME}\n",
    "%env WANDB_NOTEBOOK_NAME={NOTEBOOK_PATH}\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_WATCH=all\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703cf48",
   "metadata": {
    "id": "XSAzFxnH1ozQ",
    "papermill": {
     "duration": 0.014651,
     "end_time": "2022-11-06T09:14:38.066392",
     "exception": false,
     "start_time": "2022-11-06T09:14:38.051741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model, Tokenizer, and Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1275ea7a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "bf7dac5b27584f288107f28e482be51d",
      "9355394179624ce3be82e1b294b1a2b5",
      "e3db079ea80048359f6097228cdc8086",
      "0c4bff269e8f4d9693aec278a0a8d52a",
      "c30f1c569f584efdb38e04fd4d5f838a",
      "e01a20c18d8249cea389638d8c005b8d",
      "6acc835b544d451894d35e3736e0d804",
      "c5ed91471a484c8da8249e731a16f343",
      "bc621d540c4f48c88ef6758cc902f652",
      "9890392cc707490d88aa6fe155917a09",
      "f62340167e2d447096a2965b4fc60826",
      "83be86e7a1bc4cb5ad983f549588cec5",
      "0642dca8ab984c91a4539585afef8390",
      "92f849d5359340cc89bce483f9d15bfe",
      "a6d4a8cf193d4d4486b72f41e7ec7fa5",
      "bab12b33f3b0477c9a9c9fb02aa288db",
      "ad20f3a0ca6c42c6afc1f506046ebf3b",
      "fe51a8730e28454d897439830382db46",
      "684011384bc34d2692f71dfe935b4723",
      "44649a89dc5d4156892db45e1fdee5c1",
      "5b3593cbcc844e928f086f80d9108ba1",
      "a7c890f084ac432b9facfa6a397f6295",
      "d93d55f032ac46068d03caeb1330b7bc",
      "a143eeb39a3a4f34be3eea3253d8b3f2",
      "c2924cb5fd6642d5aa134b63aaa01dca",
      "e615f2d044e143d387a202fcaab64972",
      "4d894cca56034a818c9132a012504061",
      "a8e8e78b21d6416f858f4f7352059bc0",
      "7c3552d804164201a11b0d9a7a6d9b10",
      "efd3eea3194c47d28ce4981dceb04f54",
      "658511cf252648a0ae4dd509bbe12fe6",
      "5cb0cdb0332f49caa2c9e728078da80a",
      "1d07530c6d494b4bb5d9579e0da3c820",
      "c9b0e46751fb474ab454ba3eddd8dbd6",
      "e188d96fbcc54a35838b1356cf7a8797",
      "90465c6d97ef4e83b86160ce1e66ca8b",
      "bb83f39eb9b74852b14cc8317cacf616",
      "86c9f350fe5f491e966c968f09428b2f",
      "ba30ea7b361c4105966ff21c1d8a8695",
      "f514807a72e64160b487098810593b20",
      "110c5f6649ab4b3382cce9d0bfcca25b",
      "2e99b266d32549aa80f6234d807ff8bb",
      "45efd1e29eb445d0bbdb4d0e90dec407",
      "dff996c84db24f52bef3d54528588226"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:38.099776Z",
     "iopub.status.busy": "2022-11-06T09:14:38.098329Z",
     "iopub.status.idle": "2022-11-06T09:14:40.065505Z",
     "shell.execute_reply": "2022-11-06T09:14:40.064425Z"
    },
    "executionInfo": {
     "elapsed": 25161,
     "status": "ok",
     "timestamp": 1666258950864,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "v7hpRDtF7ChY",
    "outputId": "32ce331a-b87f-47f7-a3e7-b1af49c11478",
    "papermill": {
     "duration": 1.986676,
     "end_time": "2022-11-06T09:14:40.067582",
     "exception": false,
     "start_time": "2022-11-06T09:14:38.080906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue_roberta_base_mlm_fine_tuned were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue_roberta_base_mlm_fine_tuned and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, label2id=label2id, id2label=id2label, num_labels=num_labels\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length', max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e25aed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:40.098131Z",
     "iopub.status.busy": "2022-11-06T09:14:40.097398Z",
     "iopub.status.idle": "2022-11-06T09:14:40.105326Z",
     "shell.execute_reply": "2022-11-06T09:14:40.104366Z"
    },
    "papermill": {
     "duration": 0.024941,
     "end_time": "2022-11-06T09:14:40.106903",
     "exception": false,
     "start_time": "2022-11-06T09:14:40.081962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = f'./dataset/{DATA_V}/raw_train.csv'\n",
    "# dev_path = f'./dataset/{DATA_V}/raw_dev.csv'\n",
    "# test_path = f'./dataset/{DATA_V}/raw_test.csv'\n",
    "# train = pd.read_csv(train_path)\n",
    "# dev = pd.read_csv(dev_path)\n",
    "# test = pd.read_csv(test_path)\n",
    "\n",
    "# print(len(tokenizer))\n",
    "# tokenizer_train_data = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form]).to_frame().drop_duplicates()\n",
    "# tokenizer_train_data = tokenizer_train_data.sentence_form.to_list()\n",
    "# new_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# new_tokenizer = tokenizer.train_new_from_iterator(tokenizer_train_data, vocab_size=1)\n",
    "# new_tokens = set(list(new_tokenizer.vocab.keys())) - set(tokenizer.vocab.keys())\n",
    "# tokenizer.add_tokens(list(new_tokens))\n",
    "# print(len(new_tokenizer))\n",
    "# print(len(tokenizer))\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f2c2cf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:40.135940Z",
     "iopub.status.busy": "2022-11-06T09:14:40.135361Z",
     "iopub.status.idle": "2022-11-06T09:14:40.141267Z",
     "shell.execute_reply": "2022-11-06T09:14:40.140372Z"
    },
    "papermill": {
     "duration": 0.022272,
     "end_time": "2022-11-06T09:14:40.142766",
     "exception": false,
     "start_time": "2022-11-06T09:14:40.120494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(new_tokens))\n",
    "# print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c47dc5e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:40.171691Z",
     "iopub.status.busy": "2022-11-06T09:14:40.171098Z",
     "iopub.status.idle": "2022-11-06T09:14:40.181199Z",
     "shell.execute_reply": "2022-11-06T09:14:40.180363Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258957461,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "fPhUW964vTzH",
    "outputId": "eebfdfdb-9e05-4509-fac0-450ca0a24c31",
    "papermill": {
     "duration": 0.026714,
     "end_time": "2022-11-06T09:14:40.182798",
     "exception": false,
     "start_time": "2022-11-06T09:14:40.156084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'positive': 0, 'negative': 1, 'neutral': 2},\n",
       " {0: 'positive', 1: 'negative', 2: 'neutral'},\n",
       " 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id, model.config.id2label, model.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e12c49",
   "metadata": {
    "id": "V-EVcOAQ18dS",
    "papermill": {
     "duration": 0.013259,
     "end_time": "2022-11-06T09:14:40.209659",
     "exception": false,
     "start_time": "2022-11-06T09:14:40.196400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4181b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9a01945a9afe49a18a98c35b4cb99c8a",
      "f4a78200b20640f4928944c489daf7a7",
      "0032f06143bf468e90701a0ee56c9df1",
      "2a92b6399a3b4cfea7afcbe89ea6c1c8",
      "275c1bc29ce0431c919d30b0c4de4beb",
      "767206f5d9e04d099a2706442df3e2ca",
      "81ea513d9bbb4dffb926f175947642e9",
      "dc3f367d749440b1acd2f8cefe848c4e",
      "4cc2f55692264694a43389cc5385db8a",
      "b094395b8da34ff8a9c33fcded16377f",
      "1de70d714b014ec4bc1fa226ba66b64f",
      "76629b189eb648d3bc7ba0711e57bc66",
      "8d44dca2d0a24fb38dabcf4bd388323f",
      "89c0ae7377644daa8688ec9ede9f035a",
      "ae3f51735615420bbc92ad5dfb590263",
      "9714e67513334f8e868607422f7da2b9",
      "9237d2a901984102a5deb1c2528f1e10",
      "e9ef7c82807847eb8ff43b3f0303b7d5",
      "41e5cd9c231a46b5bfd8262b2b745cc6",
      "6dcdbf9f62004f9fb3141b1ca5dfddf0",
      "82ebe2dd5a624c418fdfe9dbc021d18d",
      "6ef978f43b214c58abfdf1155f475684"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:40.238678Z",
     "iopub.status.busy": "2022-11-06T09:14:40.237642Z",
     "iopub.status.idle": "2022-11-06T09:14:43.573839Z",
     "shell.execute_reply": "2022-11-06T09:14:43.572442Z"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1666258958492,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "qtEXOy22Gz8l",
    "outputId": "ec55c208-3acd-457e-f052-32644f1ffe7a",
    "papermill": {
     "duration": 3.354956,
     "end_time": "2022-11-06T09:14:43.577994",
     "exception": false,
     "start_time": "2022-11-06T09:14:40.223038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42ff974e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:43.627586Z",
     "iopub.status.busy": "2022-11-06T09:14:43.626929Z",
     "iopub.status.idle": "2022-11-06T09:14:43.637268Z",
     "shell.execute_reply": "2022-11-06T09:14:43.636363Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666258958492,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "1d61JHiLEadB",
    "papermill": {
     "duration": 0.03661,
     "end_time": "2022-11-06T09:14:43.639519",
     "exception": false,
     "start_time": "2022-11-06T09:14:43.602909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(references=labels, predictions=predictions)['accuracy']\n",
    "    f1_positive, f1_negative, f1_neutral = tuple(f1_metric.compute(references=labels, predictions=predictions, average=None, labels=[0,1,2])['f1'])\n",
    "    f1_macro = f1_metric.compute(references=labels, predictions=predictions, average='macro')['f1']\n",
    "    f1_micro = f1_metric.compute(references=labels, predictions=predictions, average='micro')['f1']\n",
    "    \n",
    "    return {'accuracy': accuracy, \n",
    "            'f1_positive': f1_positive, 'f1_negative': f1_negative, 'f1_neutral': f1_neutral, \n",
    "            'f1_macro': f1_macro, 'f1_micro': f1_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62286b9",
   "metadata": {
    "id": "EBp5WFGR2JRb",
    "papermill": {
     "duration": 0.0154,
     "end_time": "2022-11-06T09:14:43.670642",
     "exception": false,
     "start_time": "2022-11-06T09:14:43.655242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608eeba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:43.703841Z",
     "iopub.status.busy": "2022-11-06T09:14:43.702600Z",
     "iopub.status.idle": "2022-11-06T09:14:43.709200Z",
     "shell.execute_reply": "2022-11-06T09:14:43.708368Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666258958493,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "ryHwmgr7B3Ze",
    "papermill": {
     "duration": 0.025947,
     "end_time": "2022-11-06T09:14:43.711700",
     "exception": false,
     "start_time": "2022-11-06T09:14:43.685753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"form\"], examples[\"pair\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51ca70c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e91015e3fd4e4c48930293c31958c06b",
      "03a85f47681c41cdab9d75beee0fb78a",
      "04fe7e54680749478e8daec82decd3ee",
      "f76847602c9e4f8ba5141ccf966a8918",
      "c3f6df857dac4350a4c43b98e5b61e43",
      "5c02b9951c1946279cb36c6c8a4a50f4",
      "fbe16032b1b54aab84d7f1c3caf83201",
      "7d10259a18d54648a6c670a6722e82b5",
      "505a1235079e40cda60009ba1bcf31fe",
      "d4b8a3d633a346e1ad913a3f39ff7332",
      "df47dce258854a2cbfde89bd1b4333a3",
      "6d5bfc1c2ad541e38ef71c3b70faa6aa",
      "b46847cc57cb4d1686abedd7729f2276",
      "eefa541e2bce44f48d5d57921a5105a9",
      "6a576fba1fb14f2fab2cae599e01c9cb",
      "4652216b070746baa42a73d1dd6cec47",
      "d31b16ab5eeb4d3c8d842ec0a739524b",
      "0ad2f8531b5d4ab28f8cd8f9003f7f56",
      "7c9acc1b41de46debb3a27a4af31f6c1",
      "c7cce1948cf14099b8b760cf64db0733",
      "d70edc08493c42bba3d66945ad4da9ac",
      "f472a293ade641c9bff11ee3905e34ee"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:43.744823Z",
     "iopub.status.busy": "2022-11-06T09:14:43.743714Z",
     "iopub.status.idle": "2022-11-06T09:14:44.385545Z",
     "shell.execute_reply": "2022-11-06T09:14:44.384383Z"
    },
    "executionInfo": {
     "elapsed": 15291,
     "status": "ok",
     "timestamp": 1666258973779,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "lM9mxmKb2Nah",
    "outputId": "c048ff0a-1067-4143-88fb-a765c79f3cbc",
    "papermill": {
     "duration": 0.660914,
     "end_time": "2022-11-06T09:14:44.387843",
     "exception": false,
     "start_time": "2022-11-06T09:14:43.726929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cb330fe1cb4e5d9b3e260e2f62d565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec6b271429048bd9c848c88883ddacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(TRAIN_DATA_PATH)\n",
    "eval_dataset = pd.read_csv(EVAL_DATA_PATH)\n",
    "train_dataset = datasets.Dataset.from_pandas(train_dataset).shuffle(seed=42)\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_dataset).shuffle(seed=42)\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f1d2992",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:44.423083Z",
     "iopub.status.busy": "2022-11-06T09:14:44.421678Z",
     "iopub.status.idle": "2022-11-06T09:14:44.433530Z",
     "shell.execute_reply": "2022-11-06T09:14:44.432385Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666258973781,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "YUaaH_gi7UFe",
    "outputId": "a481e242-25ea-461f-b54e-3c6372ae7421",
    "papermill": {
     "duration": 0.031884,
     "end_time": "2022-11-06T09:14:44.435734",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.403850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3196, 3002)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ae5d25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:44.469632Z",
     "iopub.status.busy": "2022-11-06T09:14:44.468457Z",
     "iopub.status.idle": "2022-11-06T09:14:44.593615Z",
     "shell.execute_reply": "2022-11-06T09:14:44.592395Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "AW4V6ZVKdMRP",
    "outputId": "9a4ad945-bfaa-49d1-93db-3a62b359a6a2",
    "papermill": {
     "duration": 0.145407,
     "end_time": "2022-11-06T09:14:44.596594",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.451187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 풍성함이 느껴지니 너무 좋음ㅠ [SEP] 본품 # 품질 [SEP] 0\n",
      "[CLS] 넉넉한 에센스 용량으로 얼굴 뿐만 아니라 몸 전체에도 사용할 수 있어서 저는 마스크팩 할 때마다 온몸 수분충전도 같이하고있어요 ㅋㅋㅋㅋㅋㅋ [SEP] 본품 # 일반 [SEP] 0\n"
     ]
    }
   ],
   "source": [
    "k = random.randrange(len(train_dataset))\n",
    "print(tokenizer.decode(train_dataset['input_ids'][k]), train_dataset['labels'][k])\n",
    "k = random.randrange(len(eval_dataset))\n",
    "print(tokenizer.decode(eval_dataset['input_ids'][k]), eval_dataset['labels'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587512f",
   "metadata": {
    "id": "admrPVvW1_Q_",
    "papermill": {
     "duration": 0.014615,
     "end_time": "2022-11-06T09:14:44.625885",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.611270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c78dcc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:44.657903Z",
     "iopub.status.busy": "2022-11-06T09:14:44.656507Z",
     "iopub.status.idle": "2022-11-06T09:14:44.681635Z",
     "shell.execute_reply": "2022-11-06T09:14:44.680393Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "B0b4moolsNWK",
    "papermill": {
     "duration": 0.043503,
     "end_time": "2022-11-06T09:14:44.683891",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.640388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=run_name,\n",
    "    run_name=run_name,\n",
    "    report_to=report_to,\n",
    "\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "\n",
    "    optim=optim,\n",
    "\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    adam_epsilon=adam_epsilon,\n",
    "\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "\n",
    "    save_total_limit=save_total_limit,\n",
    "\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    \n",
    "    save_strategy=save_strategy,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_first_step=logging_first_step, \n",
    "    logging_steps=logging_steps,\n",
    "    \n",
    "    fp16=fp16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c3562d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:44.717100Z",
     "iopub.status.busy": "2022-11-06T09:14:44.715599Z",
     "iopub.status.idle": "2022-11-06T09:14:44.725751Z",
     "shell.execute_reply": "2022-11-06T09:14:44.724421Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "w1aRCCDR9kVb",
    "papermill": {
     "duration": 0.02881,
     "end_time": "2022-11-06T09:14:44.727693",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.698883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64cedf68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:44.759621Z",
     "iopub.status.busy": "2022-11-06T09:14:44.758638Z",
     "iopub.status.idle": "2022-11-06T09:14:49.797728Z",
     "shell.execute_reply": "2022-11-06T09:14:49.796416Z"
    },
    "executionInfo": {
     "elapsed": 4423,
     "status": "ok",
     "timestamp": 1666258978191,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "pwe87xkaMEK6",
    "papermill": {
     "duration": 5.058172,
     "end_time": "2022-11-06T09:14:49.800738",
     "exception": false,
     "start_time": "2022-11-06T09:14:44.742566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b3dbc",
   "metadata": {
    "id": "9KNsbWs72BoC",
    "papermill": {
     "duration": 0.015834,
     "end_time": "2022-11-06T09:14:49.835747",
     "exception": false,
     "start_time": "2022-11-06T09:14:49.819913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db589fd9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T09:14:49.868330Z",
     "iopub.status.busy": "2022-11-06T09:14:49.867062Z",
     "iopub.status.idle": "2022-11-06T09:34:20.677619Z",
     "shell.execute_reply": "2022-11-06T09:34:20.676380Z"
    },
    "id": "tyN8PA8tMFsU",
    "outputId": "43105a1e-799b-4e6f-f03b-713148df5ce7",
    "papermill": {
     "duration": 1170.84594,
     "end_time": "2022-11-06T09:34:20.696806",
     "exception": false,
     "start_time": "2022-11-06T09:14:49.850866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Number of trainable parameters = 111022083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/jongmin/Jeonghyeon/codes/absa/wandb/run-20221106_181449-212zef3q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/212zef3q\" target=\"_blank\">klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256</a></strong> to <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 18:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.110820</td>\n",
       "      <td>0.968688</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475556</td>\n",
       "      <td>0.968688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.114418</td>\n",
       "      <td>0.964357</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464912</td>\n",
       "      <td>0.964357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.104814</td>\n",
       "      <td>0.975683</td>\n",
       "      <td>0.989153</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.500371</td>\n",
       "      <td>0.975683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.098494</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>0.989631</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.589684</td>\n",
       "      <td>0.977348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.106029</td>\n",
       "      <td>0.977682</td>\n",
       "      <td>0.989789</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.630303</td>\n",
       "      <td>0.977682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.108232</td>\n",
       "      <td>0.977348</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.627524</td>\n",
       "      <td>0.977348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.114645</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.989768</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.640574</td>\n",
       "      <td>0.976682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.121194</td>\n",
       "      <td>0.975683</td>\n",
       "      <td>0.989768</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0.610431</td>\n",
       "      <td>0.975683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.125582</td>\n",
       "      <td>0.975683</td>\n",
       "      <td>0.989585</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.329897</td>\n",
       "      <td>0.639827</td>\n",
       "      <td>0.975683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.973351</td>\n",
       "      <td>0.988376</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.632023</td>\n",
       "      <td>0.973351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-100] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-200] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-600] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-800] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: form, pair, id. If form, pair, id are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-1000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-1000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-900] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256/checkpoint-700 (score: 0.6405744291411138).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/tmpq_44n7aj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpq_44n7aj/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /tmp/tmpq_44n7aj/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /tmp/tmpq_44n7aj/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /tmp/tmpq_44n7aj/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▃▁▇███▇▇▇▆</td></tr><tr><td>eval/f1_macro</td><td>▁▁▂▆█▇█▇██</td></tr><tr><td>eval/f1_micro</td><td>▃▁▇███▇▇▇▆</td></tr><tr><td>eval/f1_negative</td><td>▂▁▁▇█▇▇▄▆▆</td></tr><tr><td>eval/f1_neutral</td><td>▁▁▃▄▆▇▇███</td></tr><tr><td>eval/f1_positive</td><td>▄▁▇██████▆</td></tr><tr><td>eval/loss</td><td>▄▅▂▁▃▃▅▆▇█</td></tr><tr><td>eval/runtime</td><td>▃▁▄▁▃▄█▅▄▁</td></tr><tr><td>eval/samples_per_second</td><td>▆█▅█▆▅▁▄▅█</td></tr><tr><td>eval/steps_per_second</td><td>▆█▅█▆▅▁▄▅█</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▂▃▃▄▄▄▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▂▃▃▄▄▄▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▇▆▅▅▄▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97335</td></tr><tr><td>eval/f1_macro</td><td>0.63202</td></tr><tr><td>eval/f1_micro</td><td>0.97335</td></tr><tr><td>eval/f1_negative</td><td>0.6</td></tr><tr><td>eval/f1_neutral</td><td>0.30769</td></tr><tr><td>eval/f1_positive</td><td>0.98838</td></tr><tr><td>eval/loss</td><td>0.13003</td></tr><tr><td>eval/runtime</td><td>27.9684</td></tr><tr><td>eval/samples_per_second</td><td>107.335</td></tr><tr><td>eval/steps_per_second</td><td>3.361</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>1000</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0084</td></tr><tr><td>train/total_flos</td><td>4204552415293440.0</td></tr><tr><td>train/train_loss</td><td>0.08099</td></tr><tr><td>train/train_runtime</td><td>1140.9685</td></tr><tr><td>train/train_samples_per_second</td><td>28.011</td></tr><tr><td>train/train_steps_per_second</td><td>0.876</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">klue_roberta_base_mlm_fine_tuned_uncleaned_v13_maxlen_256</strong>: <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/212zef3q\" target=\"_blank\">https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/212zef3q</a><br/>Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221106_181449-212zef3q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa27284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T09:34:20.746966Z",
     "iopub.status.busy": "2022-11-06T09:34:20.745783Z",
     "iopub.status.idle": "2022-11-06T09:34:22.541896Z",
     "shell.execute_reply": "2022-11-06T09:34:22.540407Z"
    },
    "id": "njKzTZtir0SC",
    "papermill": {
     "duration": 1.824039,
     "end_time": "2022-11-06T09:34:22.544549",
     "exception": false,
     "start_time": "2022-11-06T09:34:20.720510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "keep = [\n",
    "    'added_tokens.json',\n",
    "    'config.json',\n",
    "    'pytorch_model.bin',\n",
    "    'special_tokens_map.json',\n",
    "    'tokenizer.json',\n",
    "    'tokenizer_config.json',\n",
    "    'vocab.txt'\n",
    "]\n",
    "\n",
    "ckpts = os.listdir(run_name)\n",
    "for ckpt in ckpts:\n",
    "    ckpt = os.path.join(run_name, ckpt)\n",
    "    for item in os.listdir(ckpt):\n",
    "        if item not in keep:\n",
    "            os.remove(os.path.join(ckpt, item))\n",
    "\n",
    "!mv wandb {run_name} {SAVE_PATH}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('jeonghyeon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1197.37388,
   "end_time": "2022-11-06T09:34:27.134819",
   "environment_variables": {},
   "exception": null,
   "input_path": "./train_asc_m_new.ipynb",
   "output_path": "./papermill/train_asc_m_new.ipynb",
   "parameters": {},
   "start_time": "2022-11-06T09:14:29.760939",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0310334238e2412499e75826ea8d4d33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "11b9cd50f14c426788b8e446f4aecd07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1aafa5ec13c9488aa4f66f9a98b6b431": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1e826760fb69419e9029d81d8e55bb81": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "20b4a7e640e74823b4d58374c95c14cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20e94ad1bfcb4364b3055a559201d385": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2399efa8f5e34ccb81ece23431c917d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2918e3e79c1b4baf8196add96df02521": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "305e9b7f4f3849a2b2beb18b08db0b35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "306c64524030496182f7d0530c075fa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e34fc0251ae439eae0ff6c8b39acb26",
       "placeholder": "​",
       "style": "IPY_MODEL_fd46648bc0f148c194b17ed6098b8e3a",
       "tabbable": null,
       "tooltip": null,
       "value": " 75%"
      }
     },
     "3342389ac97544e0ab3c99af189810fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_11b9cd50f14c426788b8e446f4aecd07",
       "placeholder": "​",
       "style": "IPY_MODEL_cbc2642dea704a569e73ad827a9b54f5",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/4 [00:00&lt;00:00, 13.48ba/s]"
      }
     },
     "420daba082a9491e8ceea786fd37dc66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_305e9b7f4f3849a2b2beb18b08db0b35",
       "placeholder": "​",
       "style": "IPY_MODEL_bdf13452bd334186b3175b298c086b7a",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "4ec6b271429048bd9c848c88883ddacd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_306c64524030496182f7d0530c075fa5",
        "IPY_MODEL_791d42dccea74651b0cc5ea3057f7373",
        "IPY_MODEL_7acf21ef9a7d456f8b1cd326d966d45d"
       ],
       "layout": "IPY_MODEL_2399efa8f5e34ccb81ece23431c917d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4eda6d267c744e2c9b95958089d06774": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e2713f52e77440a8c3a72ff9daaed2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e34fc0251ae439eae0ff6c8b39acb26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78398f2305364da9b8a598bf4facf7ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8cf2bb261a047049f6019e02e79d42e",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b9ccae7544d2443cbecb713d45f12908",
       "tabbable": null,
       "tooltip": null,
       "value": 3.0
      }
     },
     "791d42dccea74651b0cc5ea3057f7373": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4eda6d267c744e2c9b95958089d06774",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_20e94ad1bfcb4364b3055a559201d385",
       "tabbable": null,
       "tooltip": null,
       "value": 3.0
      }
     },
     "7acf21ef9a7d456f8b1cd326d966d45d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81353c8bf3c64b30935fcc1d5d74c5de",
       "placeholder": "​",
       "style": "IPY_MODEL_1e826760fb69419e9029d81d8e55bb81",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/4 [00:00&lt;00:00, 13.44ba/s]"
      }
     },
     "81353c8bf3c64b30935fcc1d5d74c5de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83371e73e5374d4094614fe3c6bb0e44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d4cd911d3f7e47a2ac24c9e630c570b5",
       "placeholder": "​",
       "style": "IPY_MODEL_0310334238e2412499e75826ea8d4d33",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "85fb7c5742214371a77d0c65f455710d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e2713f52e77440a8c3a72ff9daaed2b",
       "placeholder": "​",
       "style": "IPY_MODEL_bead0a8be7a348a0952a4275d7789d39",
       "tabbable": null,
       "tooltip": null,
       "value": " 75%"
      }
     },
     "893170215a4f4aca8e7a942b18bf672d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2918e3e79c1b4baf8196add96df02521",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_94e92aba5313484588b7fa5305c51734",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "94e92aba5313484588b7fa5305c51734": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9e3c5fb8c73a45788728d6b65561c1dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_20b4a7e640e74823b4d58374c95c14cc",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1aafa5ec13c9488aa4f66f9a98b6b431",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "a9cb330fe1cb4e5d9b3e260e2f62d565": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_85fb7c5742214371a77d0c65f455710d",
        "IPY_MODEL_78398f2305364da9b8a598bf4facf7ae",
        "IPY_MODEL_3342389ac97544e0ab3c99af189810fb"
       ],
       "layout": "IPY_MODEL_ee4def9cf1d348078cb1bcbc5c2564d6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b9ccae7544d2443cbecb713d45f12908": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bdf13452bd334186b3175b298c086b7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "bead0a8be7a348a0952a4275d7789d39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cbc2642dea704a569e73ad827a9b54f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cdf45ccd4d5346bc85fbf4f84153476c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4cd911d3f7e47a2ac24c9e630c570b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d56449dc3bb443439be1094d56b016d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_83371e73e5374d4094614fe3c6bb0e44",
        "IPY_MODEL_893170215a4f4aca8e7a942b18bf672d"
       ],
       "layout": "IPY_MODEL_deb0ec72ed8b4ad09b803b04788be4cc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d61209c190c94afb90ce9028055e4db3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_420daba082a9491e8ceea786fd37dc66",
        "IPY_MODEL_9e3c5fb8c73a45788728d6b65561c1dd"
       ],
       "layout": "IPY_MODEL_cdf45ccd4d5346bc85fbf4f84153476c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "deb0ec72ed8b4ad09b803b04788be4cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8cf2bb261a047049f6019e02e79d42e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee4def9cf1d348078cb1bcbc5c2564d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd46648bc0f148c194b17ed6098b8e3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}