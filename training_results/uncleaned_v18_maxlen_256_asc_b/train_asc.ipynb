{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33896ee",
   "metadata": {
    "id": "p8Lb8VDc8Rak",
    "papermill": {
     "duration": 0.040397,
     "end_time": "2022-11-06T10:09:52.186119",
     "exception": false,
     "start_time": "2022-11-06T10:09:52.145722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2707989b",
   "metadata": {
    "id": "9pZhmy9xKmZX",
    "papermill": {
     "duration": 0.087889,
     "end_time": "2022-11-06T10:09:52.301913",
     "exception": false,
     "start_time": "2022-11-06T10:09:52.214024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modules and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50260d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:52.330585Z",
     "iopub.status.busy": "2022-11-06T10:09:52.329518Z",
     "iopub.status.idle": "2022-11-06T10:09:56.838359Z",
     "shell.execute_reply": "2022-11-06T10:09:56.836547Z"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1666258918849,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "_v8VXBZdKuUD",
    "papermill": {
     "duration": 4.528079,
     "end_time": "2022-11-06T10:09:56.843316",
     "exception": false,
     "start_time": "2022-11-06T10:09:52.315237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da12e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:56.875522Z",
     "iopub.status.busy": "2022-11-06T10:09:56.873611Z",
     "iopub.status.idle": "2022-11-06T10:09:57.113407Z",
     "shell.execute_reply": "2022-11-06T10:09:57.112368Z"
    },
    "papermill": {
     "duration": 0.258208,
     "end_time": "2022-11-06T10:09:57.115590",
     "exception": false,
     "start_time": "2022-11-06T10:09:56.857382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.7.1\n",
      "torch.cuda.is_available(): True\n",
      "NGPU: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'torch.__version__: {torch.__version__}')\n",
    "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
    "NGPU = torch.cuda.device_count()\n",
    "print(f'NGPU: {NGPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bafa633",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:57.145385Z",
     "iopub.status.busy": "2022-11-06T10:09:57.144498Z",
     "iopub.status.idle": "2022-11-06T10:09:57.153573Z",
     "shell.execute_reply": "2022-11-06T10:09:57.152387Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666258918850,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "7t7eYrTJkyCV",
    "outputId": "4a36004a-6875-4404-dc79-01c48573a154",
    "papermill": {
     "duration": 0.026506,
     "end_time": "2022-11-06T10:09:57.155776",
     "exception": false,
     "start_time": "2022-11-06T10:09:57.129270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True': 0, 'False': 1}\n",
      "{0: 'True', 1: 'False'}\n"
     ]
    }
   ],
   "source": [
    "### labels\n",
    "\n",
    "ce_labels = ['True', 'False']\n",
    "pc_labels = ['positive', 'negative', 'neutral']\n",
    "pc_binary_labels = ['True', 'False']\n",
    "\n",
    "labels = pc_binary_labels\n",
    "\n",
    "label2id = {k: i for i, k in enumerate(labels)}\n",
    "id2label = {i: k for i, k in enumerate(labels)}\n",
    "num_labels = len(labels)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc9b3d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:57.185317Z",
     "iopub.status.busy": "2022-11-06T10:09:57.184428Z",
     "iopub.status.idle": "2022-11-06T10:09:57.870110Z",
     "shell.execute_reply": "2022-11-06T10:09:57.868492Z"
    },
    "executionInfo": {
     "elapsed": 2145,
     "status": "ok",
     "timestamp": 1666258920989,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "Rohq6E8Lp1x1",
    "outputId": "88391cfb-80b0-436a-f862-034b00cef374",
    "papermill": {
     "duration": 0.705515,
     "end_time": "2022-11-06T10:09:57.874477",
     "exception": false,
     "start_time": "2022-11-06T10:09:57.168962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### paths and names\n",
    "\n",
    "PROJECT_NAME = 'aspect_sentiment_classification_multi'\n",
    "RUN_ID = 'uncleaned_v18_maxlen_256_asc_b'\n",
    "\n",
    "DATA_V = 'uncleaned_v18'\n",
    "DATA_T = 'pc_binary' # ce or pc or pc_binary\n",
    "AUGMENTATION = False\n",
    "AUG_NAME = 'balanced'\n",
    "\n",
    "model_checkpoint = 'klue_roberta_base_mlm_fine_tuned'\n",
    "\n",
    "notebook_name = 'train_asc.ipynb'\n",
    "\n",
    "### fixed\n",
    "\n",
    "model_name = re.sub(r'[/-]', r'_', model_checkpoint).lower()\n",
    "run_name = f'{model_name}_{RUN_ID}'\n",
    "\n",
    "ROOT_PATH = './'\n",
    "SAVE_PATH = os.path.join(ROOT_PATH, 'training_results', RUN_ID, 'asc')\n",
    "NOTEBOOK_PATH = os.path.join(ROOT_PATH, notebook_name)\n",
    "\n",
    "augornot = f'_{AUG_NAME}' if AUGMENTATION is True else ''\n",
    "TRAIN_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_train{augornot}.csv')\n",
    "EVAL_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_dev.csv')\n",
    "\n",
    "!mkdir -p {SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb377b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:57.934098Z",
     "iopub.status.busy": "2022-11-06T10:09:57.933392Z",
     "iopub.status.idle": "2022-11-06T10:09:57.945571Z",
     "shell.execute_reply": "2022-11-06T10:09:57.944410Z"
    },
    "papermill": {
     "duration": 0.042996,
     "end_time": "2022-11-06T10:09:57.947804",
     "exception": false,
     "start_time": "2022-11-06T10:09:57.904808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint: klue_roberta_base_mlm_fine_tuned\n",
      "DATA_V: uncleaned_v18\n",
      "./training_results/uncleaned_v18_maxlen_256_asc_b/asc exists.\n",
      "./train_asc.ipynb exists.\n",
      "./dataset/uncleaned_v18/pc_binary_train.csv exists.\n",
      "./dataset/uncleaned_v18/pc_binary_dev.csv exists.\n"
     ]
    }
   ],
   "source": [
    "print(f'model_checkpoint: {model_checkpoint}')\n",
    "print(f'DATA_V: {DATA_V}')\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    print(f'{SAVE_PATH} exists.')\n",
    "else:\n",
    "    print(f'{SAVE_PATH} does not exist.')\n",
    "if os.path.exists(NOTEBOOK_PATH):\n",
    "    print(f'{NOTEBOOK_PATH} exists.')\n",
    "else:\n",
    "    print(f'{NOTEBOOK_PATH} does not exist.')\n",
    "if os.path.exists(TRAIN_DATA_PATH):\n",
    "    print(f'{TRAIN_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{TRAIN_DATA_PATH} does not exist.')\n",
    "if os.path.exists(EVAL_DATA_PATH):\n",
    "    print(f'{EVAL_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{EVAL_DATA_PATH} does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88755207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:57.991759Z",
     "iopub.status.busy": "2022-11-06T10:09:57.990748Z",
     "iopub.status.idle": "2022-11-06T10:09:57.997022Z",
     "shell.execute_reply": "2022-11-06T10:09:57.996350Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666258920989,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "HnBF0kLyk4Z4",
    "papermill": {
     "duration": 0.029565,
     "end_time": "2022-11-06T10:09:57.998748",
     "exception": false,
     "start_time": "2022-11-06T10:09:57.969183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      "learning_rate: 1.2e-05\n",
      "num_train_epochs: 10\n"
     ]
    }
   ],
   "source": [
    "### rest of training args\n",
    "\n",
    "report_to=\"wandb\"\n",
    "\n",
    "fp16 = False\n",
    "\n",
    "num_train_epochs = 10\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "optim = 'adamw_hf' # 'adamw_torch'\n",
    "\n",
    "learning_rate = 3e-6 / 8 * batch_size * NGPU # 5e-5\n",
    "weight_decay = 0.01 # 0\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0\n",
    "\n",
    "save_total_limit = 2\n",
    "\n",
    "load_best_model_at_end = True\n",
    "metric_for_best_model ='f1_macro'\n",
    "\n",
    "save_strategy = \"epoch\"\n",
    "evaluation_strategy = \"epoch\"\n",
    "\n",
    "logging_strategy = \"steps\"\n",
    "logging_first_step = True \n",
    "logging_steps = 100\n",
    "\n",
    "print(f'batch_size: {batch_size}')\n",
    "print(f'learning_rate: {learning_rate}')\n",
    "print(f'num_train_epochs: {num_train_epochs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d55727",
   "metadata": {
    "id": "yXVsV8jQpreV",
    "papermill": {
     "duration": 0.017089,
     "end_time": "2022-11-06T10:09:58.033859",
     "exception": false,
     "start_time": "2022-11-06T10:09:58.016770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# WandB Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea44e666",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:09:58.067661Z",
     "iopub.status.busy": "2022-11-06T10:09:58.066849Z",
     "iopub.status.idle": "2022-11-06T10:09:59.893788Z",
     "shell.execute_reply": "2022-11-06T10:09:59.892434Z"
    },
    "executionInfo": {
     "elapsed": 4727,
     "status": "ok",
     "timestamp": 1666258925707,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "P0IR11QyPy26",
    "outputId": "1d7538ee-93e1-419d-ee09-4011e6742d6f",
    "papermill": {
     "duration": 1.846547,
     "end_time": "2022-11-06T10:09:59.896205",
     "exception": false,
     "start_time": "2022-11-06T10:09:58.049658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=aspect_sentiment_classification_multi\n",
      "env: WANDB_NOTEBOOK_NAME=./train_asc.ipynb\n",
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_WATCH=all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env WANDB_PROJECT={PROJECT_NAME}\n",
    "%env WANDB_NOTEBOOK_NAME={NOTEBOOK_PATH}\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_WATCH=all\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1a1c4",
   "metadata": {
    "id": "XSAzFxnH1ozQ",
    "papermill": {
     "duration": 0.026283,
     "end_time": "2022-11-06T10:09:59.949290",
     "exception": false,
     "start_time": "2022-11-06T10:09:59.923007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model, Tokenizer, and Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73121d99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "bf7dac5b27584f288107f28e482be51d",
      "9355394179624ce3be82e1b294b1a2b5",
      "e3db079ea80048359f6097228cdc8086",
      "0c4bff269e8f4d9693aec278a0a8d52a",
      "c30f1c569f584efdb38e04fd4d5f838a",
      "e01a20c18d8249cea389638d8c005b8d",
      "6acc835b544d451894d35e3736e0d804",
      "c5ed91471a484c8da8249e731a16f343",
      "bc621d540c4f48c88ef6758cc902f652",
      "9890392cc707490d88aa6fe155917a09",
      "f62340167e2d447096a2965b4fc60826",
      "83be86e7a1bc4cb5ad983f549588cec5",
      "0642dca8ab984c91a4539585afef8390",
      "92f849d5359340cc89bce483f9d15bfe",
      "a6d4a8cf193d4d4486b72f41e7ec7fa5",
      "bab12b33f3b0477c9a9c9fb02aa288db",
      "ad20f3a0ca6c42c6afc1f506046ebf3b",
      "fe51a8730e28454d897439830382db46",
      "684011384bc34d2692f71dfe935b4723",
      "44649a89dc5d4156892db45e1fdee5c1",
      "5b3593cbcc844e928f086f80d9108ba1",
      "a7c890f084ac432b9facfa6a397f6295",
      "d93d55f032ac46068d03caeb1330b7bc",
      "a143eeb39a3a4f34be3eea3253d8b3f2",
      "c2924cb5fd6642d5aa134b63aaa01dca",
      "e615f2d044e143d387a202fcaab64972",
      "4d894cca56034a818c9132a012504061",
      "a8e8e78b21d6416f858f4f7352059bc0",
      "7c3552d804164201a11b0d9a7a6d9b10",
      "efd3eea3194c47d28ce4981dceb04f54",
      "658511cf252648a0ae4dd509bbe12fe6",
      "5cb0cdb0332f49caa2c9e728078da80a",
      "1d07530c6d494b4bb5d9579e0da3c820",
      "c9b0e46751fb474ab454ba3eddd8dbd6",
      "e188d96fbcc54a35838b1356cf7a8797",
      "90465c6d97ef4e83b86160ce1e66ca8b",
      "bb83f39eb9b74852b14cc8317cacf616",
      "86c9f350fe5f491e966c968f09428b2f",
      "ba30ea7b361c4105966ff21c1d8a8695",
      "f514807a72e64160b487098810593b20",
      "110c5f6649ab4b3382cce9d0bfcca25b",
      "2e99b266d32549aa80f6234d807ff8bb",
      "45efd1e29eb445d0bbdb4d0e90dec407",
      "dff996c84db24f52bef3d54528588226"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:00.007430Z",
     "iopub.status.busy": "2022-11-06T10:10:00.006796Z",
     "iopub.status.idle": "2022-11-06T10:10:02.513708Z",
     "shell.execute_reply": "2022-11-06T10:10:02.512408Z"
    },
    "executionInfo": {
     "elapsed": 25161,
     "status": "ok",
     "timestamp": 1666258950864,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "v7hpRDtF7ChY",
    "outputId": "32ce331a-b87f-47f7-a3e7-b1af49c11478",
    "papermill": {
     "duration": 2.53756,
     "end_time": "2022-11-06T10:10:02.515894",
     "exception": false,
     "start_time": "2022-11-06T10:09:59.978334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue_roberta_base_mlm_fine_tuned were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue_roberta_base_mlm_fine_tuned and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, label2id=label2id, id2label=id2label, num_labels=num_labels\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='max_length', max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de2a164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:02.546862Z",
     "iopub.status.busy": "2022-11-06T10:10:02.546375Z",
     "iopub.status.idle": "2022-11-06T10:10:02.553382Z",
     "shell.execute_reply": "2022-11-06T10:10:02.552374Z"
    },
    "papermill": {
     "duration": 0.024992,
     "end_time": "2022-11-06T10:10:02.555117",
     "exception": false,
     "start_time": "2022-11-06T10:10:02.530125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = f'./dataset/{DATA_V}/raw_train.csv'\n",
    "# dev_path = f'./dataset/{DATA_V}/raw_dev.csv'\n",
    "# test_path = f'./dataset/{DATA_V}/raw_test.csv'\n",
    "# train = pd.read_csv(train_path)\n",
    "# dev = pd.read_csv(dev_path)\n",
    "# test = pd.read_csv(test_path)\n",
    "\n",
    "# print(len(tokenizer))\n",
    "# tokenizer_train_data = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form]).to_frame().drop_duplicates()\n",
    "# tokenizer_train_data = tokenizer_train_data.sentence_form.to_list()\n",
    "# new_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# new_tokenizer = tokenizer.train_new_from_iterator(tokenizer_train_data, vocab_size=1)\n",
    "# new_tokens = set(list(new_tokenizer.vocab.keys())) - set(tokenizer.vocab.keys())\n",
    "# tokenizer.add_tokens(list(new_tokens))\n",
    "# print(len(new_tokenizer))\n",
    "# print(len(tokenizer))\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# print(len(new_tokens))\n",
    "# print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09465722",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:02.584820Z",
     "iopub.status.busy": "2022-11-06T10:10:02.584184Z",
     "iopub.status.idle": "2022-11-06T10:10:02.593445Z",
     "shell.execute_reply": "2022-11-06T10:10:02.592367Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258957461,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "fPhUW964vTzH",
    "outputId": "eebfdfdb-9e05-4509-fac0-450ca0a24c31",
    "papermill": {
     "duration": 0.026962,
     "end_time": "2022-11-06T10:10:02.595568",
     "exception": false,
     "start_time": "2022-11-06T10:10:02.568606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'True': 0, 'False': 1}, {0: 'True', 1: 'False'}, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id, model.config.id2label, model.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f3053",
   "metadata": {
    "id": "V-EVcOAQ18dS",
    "papermill": {
     "duration": 0.013855,
     "end_time": "2022-11-06T10:10:02.623055",
     "exception": false,
     "start_time": "2022-11-06T10:10:02.609200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3106cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9a01945a9afe49a18a98c35b4cb99c8a",
      "f4a78200b20640f4928944c489daf7a7",
      "0032f06143bf468e90701a0ee56c9df1",
      "2a92b6399a3b4cfea7afcbe89ea6c1c8",
      "275c1bc29ce0431c919d30b0c4de4beb",
      "767206f5d9e04d099a2706442df3e2ca",
      "81ea513d9bbb4dffb926f175947642e9",
      "dc3f367d749440b1acd2f8cefe848c4e",
      "4cc2f55692264694a43389cc5385db8a",
      "b094395b8da34ff8a9c33fcded16377f",
      "1de70d714b014ec4bc1fa226ba66b64f",
      "76629b189eb648d3bc7ba0711e57bc66",
      "8d44dca2d0a24fb38dabcf4bd388323f",
      "89c0ae7377644daa8688ec9ede9f035a",
      "ae3f51735615420bbc92ad5dfb590263",
      "9714e67513334f8e868607422f7da2b9",
      "9237d2a901984102a5deb1c2528f1e10",
      "e9ef7c82807847eb8ff43b3f0303b7d5",
      "41e5cd9c231a46b5bfd8262b2b745cc6",
      "6dcdbf9f62004f9fb3141b1ca5dfddf0",
      "82ebe2dd5a624c418fdfe9dbc021d18d",
      "6ef978f43b214c58abfdf1155f475684"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:02.654788Z",
     "iopub.status.busy": "2022-11-06T10:10:02.654167Z",
     "iopub.status.idle": "2022-11-06T10:10:05.965836Z",
     "shell.execute_reply": "2022-11-06T10:10:05.964414Z"
    },
    "executionInfo": {
     "elapsed": 1037,
     "status": "ok",
     "timestamp": 1666258958492,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "qtEXOy22Gz8l",
    "outputId": "ec55c208-3acd-457e-f052-32644f1ffe7a",
    "papermill": {
     "duration": 3.331527,
     "end_time": "2022-11-06T10:10:05.968778",
     "exception": false,
     "start_time": "2022-11-06T10:10:02.637251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a621939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:06.009743Z",
     "iopub.status.busy": "2022-11-06T10:10:06.008380Z",
     "iopub.status.idle": "2022-11-06T10:10:06.021441Z",
     "shell.execute_reply": "2022-11-06T10:10:06.020408Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666258958492,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "1d61JHiLEadB",
    "papermill": {
     "duration": 0.03791,
     "end_time": "2022-11-06T10:10:06.023613",
     "exception": false,
     "start_time": "2022-11-06T10:10:05.985703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "#     accuracy = accuracy_metric.compute(references=labels, predictions=predictions)['accuracy']\n",
    "#     f1_positive, f1_negative, f1_neutral = tuple(f1_metric.compute(references=labels, predictions=predictions, average=None, labels=[0,1,2])['f1'])\n",
    "#     f1_macro = f1_metric.compute(references=labels, predictions=predictions, average='macro')['f1']\n",
    "#     f1_micro = f1_metric.compute(references=labels, predictions=predictions, average='micro')['f1']\n",
    "    \n",
    "#     return {'accuracy': accuracy, \n",
    "#             'f1_positive': f1_positive, 'f1_negative': f1_negative, 'f1_neutral': f1_neutral, \n",
    "#             'f1_macro': f1_macro, 'f1_micro': f1_micro}\n",
    "    \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(references=labels, predictions=predictions)['accuracy']\n",
    "    f1_true, f1_false = tuple(f1_metric.compute(references=labels, predictions=predictions, average=None, labels=[0,1])['f1'])\n",
    "    f1_macro = f1_metric.compute(references=labels, predictions=predictions, average='macro')['f1']\n",
    "    f1_micro = f1_metric.compute(references=labels, predictions=predictions, average='micro')['f1']\n",
    "    \n",
    "    return {'accuracy': accuracy, 'f1_true': f1_true, 'f1_false': f1_false, 'f1_macro': f1_macro, 'f1_micro': f1_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708afc90",
   "metadata": {
    "id": "EBp5WFGR2JRb",
    "papermill": {
     "duration": 0.021532,
     "end_time": "2022-11-06T10:10:06.061404",
     "exception": false,
     "start_time": "2022-11-06T10:10:06.039872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2f9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:06.101039Z",
     "iopub.status.busy": "2022-11-06T10:10:06.100244Z",
     "iopub.status.idle": "2022-11-06T10:10:06.109270Z",
     "shell.execute_reply": "2022-11-06T10:10:06.108380Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666258958493,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "ryHwmgr7B3Ze",
    "papermill": {
     "duration": 0.034263,
     "end_time": "2022-11-06T10:10:06.111259",
     "exception": false,
     "start_time": "2022-11-06T10:10:06.076996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"form\"], examples[\"pair\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867d20c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e91015e3fd4e4c48930293c31958c06b",
      "03a85f47681c41cdab9d75beee0fb78a",
      "04fe7e54680749478e8daec82decd3ee",
      "f76847602c9e4f8ba5141ccf966a8918",
      "c3f6df857dac4350a4c43b98e5b61e43",
      "5c02b9951c1946279cb36c6c8a4a50f4",
      "fbe16032b1b54aab84d7f1c3caf83201",
      "7d10259a18d54648a6c670a6722e82b5",
      "505a1235079e40cda60009ba1bcf31fe",
      "d4b8a3d633a346e1ad913a3f39ff7332",
      "df47dce258854a2cbfde89bd1b4333a3",
      "6d5bfc1c2ad541e38ef71c3b70faa6aa",
      "b46847cc57cb4d1686abedd7729f2276",
      "eefa541e2bce44f48d5d57921a5105a9",
      "6a576fba1fb14f2fab2cae599e01c9cb",
      "4652216b070746baa42a73d1dd6cec47",
      "d31b16ab5eeb4d3c8d842ec0a739524b",
      "0ad2f8531b5d4ab28f8cd8f9003f7f56",
      "7c9acc1b41de46debb3a27a4af31f6c1",
      "c7cce1948cf14099b8b760cf64db0733",
      "d70edc08493c42bba3d66945ad4da9ac",
      "f472a293ade641c9bff11ee3905e34ee"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:06.153976Z",
     "iopub.status.busy": "2022-11-06T10:10:06.153193Z",
     "iopub.status.idle": "2022-11-06T10:10:07.745594Z",
     "shell.execute_reply": "2022-11-06T10:10:07.744381Z"
    },
    "executionInfo": {
     "elapsed": 15291,
     "status": "ok",
     "timestamp": 1666258973779,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "lM9mxmKb2Nah",
    "outputId": "c048ff0a-1067-4143-88fb-a765c79f3cbc",
    "papermill": {
     "duration": 1.615482,
     "end_time": "2022-11-06T10:10:07.747774",
     "exception": false,
     "start_time": "2022-11-06T10:10:06.132292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f04b80ee86842a288786018b69dea89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e8c482b3a34e80917d142b24e78e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(TRAIN_DATA_PATH)\n",
    "eval_dataset = pd.read_csv(EVAL_DATA_PATH)\n",
    "train_dataset = datasets.Dataset.from_pandas(train_dataset).shuffle(seed=42)\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_dataset).shuffle(seed=42)\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21eb244c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:07.795160Z",
     "iopub.status.busy": "2022-11-06T10:10:07.794110Z",
     "iopub.status.idle": "2022-11-06T10:10:07.809516Z",
     "shell.execute_reply": "2022-11-06T10:10:07.808378Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1666258973781,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "YUaaH_gi7UFe",
    "outputId": "a481e242-25ea-461f-b54e-3c6372ae7421",
    "papermill": {
     "duration": 0.04787,
     "end_time": "2022-11-06T10:10:07.811886",
     "exception": false,
     "start_time": "2022-11-06T10:10:07.764016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9588, 9006)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4d58cbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:07.869441Z",
     "iopub.status.busy": "2022-11-06T10:10:07.868750Z",
     "iopub.status.idle": "2022-11-06T10:10:08.229491Z",
     "shell.execute_reply": "2022-11-06T10:10:08.228391Z"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "AW4V6ZVKdMRP",
    "outputId": "9a4ad945-bfaa-49d1-93db-3a62b359a6a2",
    "papermill": {
     "duration": 0.39316,
     "end_time": "2022-11-06T10:10:08.232396",
     "exception": false,
     "start_time": "2022-11-06T10:10:07.839236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 바람세기는 4단으로 되어있고 어디서든 거치할수있는 거치대도 있지만 휴대할때는 굳이 안가지고 다녀요 ~ [SEP] 패키지 / 구성품 # 편의성 # positive [SEP] 0\n",
      "[CLS] 다들 좋다기에 # 동인비초기본2종세트 부터 사용해봤는데 특유의 영양감과 촉촉하게 잘 스며드는 느낌까지 나무랄게 없는 ~ ♡ [SEP] 제품 전체 # 인지도 # neutral [SEP] 1\n"
     ]
    }
   ],
   "source": [
    "k = random.randrange(len(train_dataset))\n",
    "print(tokenizer.decode(train_dataset['input_ids'][k]), train_dataset['labels'][k])\n",
    "k = random.randrange(len(eval_dataset))\n",
    "print(tokenizer.decode(eval_dataset['input_ids'][k]), eval_dataset['labels'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8487ca9",
   "metadata": {
    "id": "admrPVvW1_Q_",
    "papermill": {
     "duration": 0.026259,
     "end_time": "2022-11-06T10:10:08.285190",
     "exception": false,
     "start_time": "2022-11-06T10:10:08.258931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17d3b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:08.330545Z",
     "iopub.status.busy": "2022-11-06T10:10:08.329021Z",
     "iopub.status.idle": "2022-11-06T10:10:08.353717Z",
     "shell.execute_reply": "2022-11-06T10:10:08.352412Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "B0b4moolsNWK",
    "papermill": {
     "duration": 0.051531,
     "end_time": "2022-11-06T10:10:08.357122",
     "exception": false,
     "start_time": "2022-11-06T10:10:08.305591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=run_name,\n",
    "    run_name=run_name,\n",
    "    report_to=report_to,\n",
    "\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "\n",
    "    optim=optim,\n",
    "\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    adam_epsilon=adam_epsilon,\n",
    "\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "\n",
    "    save_total_limit=save_total_limit,\n",
    "\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    \n",
    "    save_strategy=save_strategy,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_first_step=logging_first_step, \n",
    "    logging_steps=logging_steps,\n",
    "    \n",
    "    fp16=fp16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9be9bbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:08.415744Z",
     "iopub.status.busy": "2022-11-06T10:10:08.414907Z",
     "iopub.status.idle": "2022-11-06T10:10:08.421374Z",
     "shell.execute_reply": "2022-11-06T10:10:08.420377Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666258973782,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "w1aRCCDR9kVb",
    "papermill": {
     "duration": 0.040722,
     "end_time": "2022-11-06T10:10:08.423582",
     "exception": false,
     "start_time": "2022-11-06T10:10:08.382860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3d0f560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:08.453116Z",
     "iopub.status.busy": "2022-11-06T10:10:08.452009Z",
     "iopub.status.idle": "2022-11-06T10:10:15.061445Z",
     "shell.execute_reply": "2022-11-06T10:10:15.060458Z"
    },
    "executionInfo": {
     "elapsed": 4423,
     "status": "ok",
     "timestamp": 1666258978191,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "pwe87xkaMEK6",
    "papermill": {
     "duration": 6.62805,
     "end_time": "2022-11-06T10:10:15.065273",
     "exception": false,
     "start_time": "2022-11-06T10:10:08.437223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a384f3",
   "metadata": {
    "id": "9KNsbWs72BoC",
    "papermill": {
     "duration": 0.027866,
     "end_time": "2022-11-06T10:10:15.122433",
     "exception": false,
     "start_time": "2022-11-06T10:10:15.094567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "979b28ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "execution": {
     "iopub.execute_input": "2022-11-06T10:10:15.167508Z",
     "iopub.status.busy": "2022-11-06T10:10:15.167084Z",
     "iopub.status.idle": "2022-11-06T11:04:29.157682Z",
     "shell.execute_reply": "2022-11-06T11:04:29.156382Z"
    },
    "id": "tyN8PA8tMFsU",
    "outputId": "43105a1e-799b-4e6f-f03b-713148df5ce7",
    "papermill": {
     "duration": 3254.039548,
     "end_time": "2022-11-06T11:04:29.184059",
     "exception": false,
     "start_time": "2022-11-06T10:10:15.144511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Number of trainable parameters = 111021314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/jongmin/Jeonghyeon/codes/absa/wandb/run-20221106_191015-7ckof7qu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/7ckof7qu\" target=\"_blank\">klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b</a></strong> to <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 53:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 True</th>\n",
       "      <th>F1 False</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.067980</td>\n",
       "      <td>0.979680</td>\n",
       "      <td>0.968946</td>\n",
       "      <td>0.984900</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.979680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.984677</td>\n",
       "      <td>0.977000</td>\n",
       "      <td>0.988511</td>\n",
       "      <td>0.982756</td>\n",
       "      <td>0.984677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.970578</td>\n",
       "      <td>0.985617</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.980680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.090918</td>\n",
       "      <td>0.979458</td>\n",
       "      <td>0.969058</td>\n",
       "      <td>0.984626</td>\n",
       "      <td>0.976842</td>\n",
       "      <td>0.979458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.096176</td>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.975984</td>\n",
       "      <td>0.988016</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.984011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.123946</td>\n",
       "      <td>0.977571</td>\n",
       "      <td>0.966266</td>\n",
       "      <td>0.983200</td>\n",
       "      <td>0.974733</td>\n",
       "      <td>0.977571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.148928</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.962013</td>\n",
       "      <td>0.981016</td>\n",
       "      <td>0.971514</td>\n",
       "      <td>0.974684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.128061</td>\n",
       "      <td>0.980569</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.985425</td>\n",
       "      <td>0.978141</td>\n",
       "      <td>0.980569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.146828</td>\n",
       "      <td>0.978459</td>\n",
       "      <td>0.967623</td>\n",
       "      <td>0.983860</td>\n",
       "      <td>0.975742</td>\n",
       "      <td>0.978459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.152038</td>\n",
       "      <td>0.977904</td>\n",
       "      <td>0.966761</td>\n",
       "      <td>0.983451</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.977904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-900] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1200] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-1800] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2100] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, pair, form. If id, pair, form are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-3000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-3000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-3000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-2700] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b/checkpoint-600 (score: 0.9827557442557442).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/tmpmeb6v7tj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpmeb6v7tj/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /tmp/tmpmeb6v7tj/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /tmp/tmpmeb6v7tj/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /tmp/tmpmeb6v7tj/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅█▅▄█▃▁▅▄▃</td></tr><tr><td>eval/f1_false</td><td>▅█▅▄█▃▁▅▄▃</td></tr><tr><td>eval/f1_macro</td><td>▄█▅▄█▃▁▅▄▃</td></tr><tr><td>eval/f1_micro</td><td>▅█▅▄█▃▁▅▄▃</td></tr><tr><td>eval/f1_true</td><td>▄█▅▄█▃▁▅▄▃</td></tr><tr><td>eval/loss</td><td>▁▁▂▃▃▆█▆██</td></tr><tr><td>eval/runtime</td><td>▁▃▄▁▆▁▆█▁▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆▅█▃█▃▁█▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅█▃█▃▁█▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9779</td></tr><tr><td>eval/f1_false</td><td>0.98345</td></tr><tr><td>eval/f1_macro</td><td>0.97511</td></tr><tr><td>eval/f1_micro</td><td>0.9779</td></tr><tr><td>eval/f1_true</td><td>0.96676</td></tr><tr><td>eval/loss</td><td>0.15204</td></tr><tr><td>eval/runtime</td><td>89.2002</td></tr><tr><td>eval/samples_per_second</td><td>100.964</td></tr><tr><td>eval/steps_per_second</td><td>3.161</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>3000</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.003</td></tr><tr><td>train/total_flos</td><td>1.26135439939584e+16</td></tr><tr><td>train/train_loss</td><td>0.04381</td></tr><tr><td>train/train_runtime</td><td>3219.3925</td></tr><tr><td>train/train_samples_per_second</td><td>29.782</td></tr><tr><td>train/train_steps_per_second</td><td>0.932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">klue_roberta_base_mlm_fine_tuned_uncleaned_v18_maxlen_256_asc_b</strong>: <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/7ckof7qu\" target=\"_blank\">https://wandb.ai/dotsnangles/aspect_sentiment_classification_multi/runs/7ckof7qu</a><br/>Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221106_191015-7ckof7qu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27aa9bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-06T11:04:29.271569Z",
     "iopub.status.busy": "2022-11-06T11:04:29.270446Z",
     "iopub.status.idle": "2022-11-06T11:04:31.461955Z",
     "shell.execute_reply": "2022-11-06T11:04:31.460413Z"
    },
    "id": "njKzTZtir0SC",
    "papermill": {
     "duration": 2.242664,
     "end_time": "2022-11-06T11:04:31.466168",
     "exception": false,
     "start_time": "2022-11-06T11:04:29.223504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "keep = [\n",
    "    'added_tokens.json',\n",
    "    'config.json',\n",
    "    'pytorch_model.bin',\n",
    "    'special_tokens_map.json',\n",
    "    'tokenizer.json',\n",
    "    'tokenizer_config.json',\n",
    "    'vocab.txt'\n",
    "]\n",
    "\n",
    "ckpts = os.listdir(run_name)\n",
    "for ckpt in ckpts:\n",
    "    ckpt = os.path.join(run_name, ckpt)\n",
    "    for item in os.listdir(ckpt):\n",
    "        if item not in keep:\n",
    "            os.remove(os.path.join(ckpt, item))\n",
    "\n",
    "!mv wandb {run_name} {SAVE_PATH}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('jeonghyeon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3285.687421,
   "end_time": "2022-11-06T11:04:36.167427",
   "environment_variables": {},
   "exception": null,
   "input_path": "./train_asc.ipynb",
   "output_path": "./papermill/train_asc.ipynb",
   "parameters": {},
   "start_time": "2022-11-06T10:09:50.480006",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02748da449e844f7a2a385ce672f5ae9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0792be384d114b7d99bca95f43a5a5ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d4e21e47e31546179a8775155dc6933c",
        "IPY_MODEL_7a17258258764e2cae408eff7c49e724"
       ],
       "layout": "IPY_MODEL_f8ccf7b21fd44b109b20e35ac80e0b74",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0b58a03cc8ff49f4b0e1a8c51d7d5c32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0f04b80ee86842a288786018b69dea89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bfaae63e11944c8c8d582926b929dfce",
        "IPY_MODEL_486016c7b6cd436ea1fca202f3f24304",
        "IPY_MODEL_e76ea2235a9e412eaec69f7211543a8b"
       ],
       "layout": "IPY_MODEL_f8ea3fcc30ef42e2ae36ac7e6bedaee1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "139aa5d9294f4d7c87edb1ce2ed64c06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22aceaa225274141939d489a89fa1b17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c0409ecb3734c399f8ae37eb00db09d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "486016c7b6cd436ea1fca202f3f24304": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f8b67386ae294532b37cf85ab0e1ef5b",
       "max": 10.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_22aceaa225274141939d489a89fa1b17",
       "tabbable": null,
       "tooltip": null,
       "value": 9.0
      }
     },
     "4e93b1999b994581967a7d0c905cb002": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "565110b022bc4f4990b79ee2ba0454d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b9ecfeb902f4803a8e2a5594e4c4375": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "78974d629811486a9a71f36d7a6940f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7a17258258764e2cae408eff7c49e724": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_98781a412cfd482abf95dbdeb60df5e8",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cda7edd37405449eaa69035ce7c2bd1c",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "8c36caf4d49f4f5eb78c0ee85bdc7180": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "9199f6f5e8644a93a95b3f7549e07cee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eeb19f687f1f4f1e85864b815d4b39da",
        "IPY_MODEL_d25e744317024728a66793ccfcc4d23f"
       ],
       "layout": "IPY_MODEL_139aa5d9294f4d7c87edb1ce2ed64c06",
       "tabbable": null,
       "tooltip": null
      }
     },
     "91e8c482b3a34e80917d142b24e78e90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b70b1a0f0dea419ea4cf268928f6b800",
        "IPY_MODEL_da4dfcb1cef348a3a0c431fa5c8b7b30",
        "IPY_MODEL_d4e152a3796a416b8a1d9603548c3838"
       ],
       "layout": "IPY_MODEL_c108b7210ed44d56951f5b7f967a9c22",
       "tabbable": null,
       "tooltip": null
      }
     },
     "98781a412cfd482abf95dbdeb60df5e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cc29e328dbb42ceb9d8f5cf276a43a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a885a474e7f342559e7f0aa1c7870315": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0981fffe41a43c5b8f17a5960fe507f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b70b1a0f0dea419ea4cf268928f6b800": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b0981fffe41a43c5b8f17a5960fe507f",
       "placeholder": "​",
       "style": "IPY_MODEL_4e93b1999b994581967a7d0c905cb002",
       "tabbable": null,
       "tooltip": null,
       "value": " 90%"
      }
     },
     "b775f410a5f0496ba9623e1637a8b7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfaae63e11944c8c8d582926b929dfce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b775f410a5f0496ba9623e1637a8b7f6",
       "placeholder": "​",
       "style": "IPY_MODEL_f8aea7512718458aa713bfe3125cfb1b",
       "tabbable": null,
       "tooltip": null,
       "value": " 90%"
      }
     },
     "c108b7210ed44d56951f5b7f967a9c22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cda7edd37405449eaa69035ce7c2bd1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d25e744317024728a66793ccfcc4d23f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da0881ac1652404db451b681177e0dbb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b58a03cc8ff49f4b0e1a8c51d7d5c32",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "d4e152a3796a416b8a1d9603548c3838": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f16b90a976994abf8308a211f801b7f8",
       "placeholder": "​",
       "style": "IPY_MODEL_9cc29e328dbb42ceb9d8f5cf276a43a2",
       "tabbable": null,
       "tooltip": null,
       "value": " 9/10 [00:00&lt;00:00, 13.76ba/s]"
      }
     },
     "d4e21e47e31546179a8775155dc6933c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_565110b022bc4f4990b79ee2ba0454d0",
       "placeholder": "​",
       "style": "IPY_MODEL_8c36caf4d49f4f5eb78c0ee85bdc7180",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "da0881ac1652404db451b681177e0dbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da4dfcb1cef348a3a0c431fa5c8b7b30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78974d629811486a9a71f36d7a6940f6",
       "max": 10.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f0a8a936d89c4f5aa7041dd607690f6c",
       "tabbable": null,
       "tooltip": null,
       "value": 9.0
      }
     },
     "e76ea2235a9e412eaec69f7211543a8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02748da449e844f7a2a385ce672f5ae9",
       "placeholder": "​",
       "style": "IPY_MODEL_3c0409ecb3734c399f8ae37eb00db09d",
       "tabbable": null,
       "tooltip": null,
       "value": " 9/10 [00:00&lt;00:00, 16.11ba/s]"
      }
     },
     "eeb19f687f1f4f1e85864b815d4b39da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a885a474e7f342559e7f0aa1c7870315",
       "placeholder": "​",
       "style": "IPY_MODEL_5b9ecfeb902f4803a8e2a5594e4c4375",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "f0a8a936d89c4f5aa7041dd607690f6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f16b90a976994abf8308a211f801b7f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8aea7512718458aa713bfe3125cfb1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8b67386ae294532b37cf85ab0e1ef5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8ccf7b21fd44b109b20e35ac80e0b74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8ea3fcc30ef42e2ae36ac7e6bedaee1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}