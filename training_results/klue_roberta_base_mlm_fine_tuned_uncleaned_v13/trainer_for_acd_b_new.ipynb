{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5eebe67",
   "metadata": {
    "id": "p8Lb8VDc8Rak",
    "papermill": {
     "duration": 0.01852,
     "end_time": "2022-11-05T17:47:55.907804",
     "exception": false,
     "start_time": "2022-11-05T17:47:55.889284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b46f6d",
   "metadata": {
    "id": "9pZhmy9xKmZX",
    "papermill": {
     "duration": 0.013742,
     "end_time": "2022-11-05T17:47:56.012526",
     "exception": false,
     "start_time": "2022-11-05T17:47:55.998784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modules and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9765c83c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:47:56.042538Z",
     "iopub.status.busy": "2022-11-05T17:47:56.041562Z",
     "iopub.status.idle": "2022-11-05T17:47:59.181723Z",
     "shell.execute_reply": "2022-11-05T17:47:59.180404Z"
    },
    "executionInfo": {
     "elapsed": 7927,
     "status": "ok",
     "timestamp": 1666002823379,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "_v8VXBZdKuUD",
    "papermill": {
     "duration": 3.158625,
     "end_time": "2022-11-05T17:47:59.184713",
     "exception": false,
     "start_time": "2022-11-05T17:47:56.026088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding, \n",
    "    TrainingArguments, Trainer,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a6e26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:47:59.225931Z",
     "iopub.status.busy": "2022-11-05T17:47:59.225061Z",
     "iopub.status.idle": "2022-11-05T17:47:59.269603Z",
     "shell.execute_reply": "2022-11-05T17:47:59.268440Z"
    },
    "papermill": {
     "duration": 0.064004,
     "end_time": "2022-11-05T17:47:59.271907",
     "exception": false,
     "start_time": "2022-11-05T17:47:59.207903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.7.1\n",
      "torch.cuda.is_available(): True\n",
      "NGPU: 4\n"
     ]
    }
   ],
   "source": [
    "print(f'torch.__version__: {torch.__version__}')\n",
    "print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n",
    "NGPU = torch.cuda.device_count()\n",
    "print(f'NGPU: {NGPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed26599f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:47:59.301224Z",
     "iopub.status.busy": "2022-11-05T17:47:59.300741Z",
     "iopub.status.idle": "2022-11-05T17:47:59.309145Z",
     "shell.execute_reply": "2022-11-05T17:47:59.308346Z"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1666002823380,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "7t7eYrTJkyCV",
    "outputId": "752f7fad-c402-455f-e051-508453a58275",
    "papermill": {
     "duration": 0.02584,
     "end_time": "2022-11-05T17:47:59.310995",
     "exception": false,
     "start_time": "2022-11-05T17:47:59.285155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True': 0, 'False': 1}\n",
      "{0: 'True', 1: 'False'}\n"
     ]
    }
   ],
   "source": [
    "### labels\n",
    "\n",
    "ce_labels = ['True', 'False']\n",
    "pc_labels = ['positive', 'negative', 'neutral']\n",
    "pc_binary_labels = ['True', 'False']\n",
    "\n",
    "labels = ce_labels\n",
    "\n",
    "label2id = {k: i for i, k in enumerate(labels)}\n",
    "id2label = {i: k for i, k in enumerate(labels)}\n",
    "num_labels = len(labels)\n",
    "\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae8eef3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:47:59.340150Z",
     "iopub.status.busy": "2022-11-05T17:47:59.339793Z",
     "iopub.status.idle": "2022-11-05T17:47:59.989627Z",
     "shell.execute_reply": "2022-11-05T17:47:59.988468Z"
    },
    "executionInfo": {
     "elapsed": 2740,
     "status": "ok",
     "timestamp": 1666002826099,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "Rohq6E8Lp1x1",
    "outputId": "7acf0b7d-a979-4a20-b9f0-bbd449ae0c06",
    "papermill": {
     "duration": 0.669035,
     "end_time": "2022-11-05T17:47:59.993730",
     "exception": false,
     "start_time": "2022-11-05T17:47:59.324695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### paths and names\n",
    "\n",
    "PROJECT_NAME = 'aspect_category_detection'\n",
    "RUN_ID = 'uncleaned_v13'\n",
    "\n",
    "DATA_V = 'uncleaned_v13'\n",
    "DATA_T = 'ce' # ce or pc or pc_binary\n",
    "AUGMENTATION = False\n",
    "AUG_NAME = 'balanced'\n",
    "\n",
    "model_checkpoint = 'klue_roberta_base_mlm_fine_tuned'\n",
    "\n",
    "notebook_name = 'trainer_for_acd_b_new.ipynb'\n",
    "\n",
    "### fixed\n",
    "\n",
    "model_name = re.sub(r'[/-]', r'_', model_checkpoint).lower()\n",
    "run_name = f'{model_name}_{RUN_ID}'\n",
    "\n",
    "ROOT_PATH = './'\n",
    "SAVE_PATH = os.path.join(ROOT_PATH, 'training_results', run_name, 'acd')\n",
    "NOTEBOOK_PATH = os.path.join(ROOT_PATH, notebook_name)\n",
    "\n",
    "augornot = f'_{AUG_NAME}' if AUGMENTATION is True else ''\n",
    "TRAIN_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_train{augornot}.csv')\n",
    "EVAL_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_dev.csv')\n",
    "\n",
    "!mkdir -p {SAVE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641b93c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:00.052843Z",
     "iopub.status.busy": "2022-11-05T17:48:00.052187Z",
     "iopub.status.idle": "2022-11-05T17:48:00.060989Z",
     "shell.execute_reply": "2022-11-05T17:48:00.060350Z"
    },
    "papermill": {
     "duration": 0.041428,
     "end_time": "2022-11-05T17:48:00.064009",
     "exception": false,
     "start_time": "2022-11-05T17:48:00.022581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint: klue_roberta_base_mlm_fine_tuned\n",
      "DATA_V: uncleaned_v13\n",
      "./training_results/klue_roberta_base_mlm_fine_tuned_uncleaned_v13/acd exists.\n",
      "./trainer_for_acd_b_new.ipynb exists.\n",
      "./dataset/uncleaned_v13/ce_train.csv exists.\n",
      "./dataset/uncleaned_v13/ce_dev.csv exists.\n"
     ]
    }
   ],
   "source": [
    "print(f'model_checkpoint: {model_checkpoint}')\n",
    "print(f'DATA_V: {DATA_V}')\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    print(f'{SAVE_PATH} exists.')\n",
    "else:\n",
    "    print(f'{SAVE_PATH} does not exist.')\n",
    "if os.path.exists(NOTEBOOK_PATH):\n",
    "    print(f'{NOTEBOOK_PATH} exists.')\n",
    "else:\n",
    "    print(f'{NOTEBOOK_PATH} does not exist.')\n",
    "if os.path.exists(TRAIN_DATA_PATH):\n",
    "    print(f'{TRAIN_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{TRAIN_DATA_PATH} does not exist.')\n",
    "if os.path.exists(EVAL_DATA_PATH):\n",
    "    print(f'{EVAL_DATA_PATH} exists.')\n",
    "else:\n",
    "    print(f'{EVAL_DATA_PATH} does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada3816a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:00.120036Z",
     "iopub.status.busy": "2022-11-05T17:48:00.118475Z",
     "iopub.status.idle": "2022-11-05T17:48:00.129380Z",
     "shell.execute_reply": "2022-11-05T17:48:00.128370Z"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1666002826100,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "HnBF0kLyk4Z4",
    "papermill": {
     "duration": 0.040349,
     "end_time": "2022-11-05T17:48:00.131416",
     "exception": false,
     "start_time": "2022-11-05T17:48:00.091067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      "learning_rate: 1.2e-05\n",
      "num_train_epochs: 10\n"
     ]
    }
   ],
   "source": [
    "### rest of training args\n",
    "\n",
    "report_to=\"wandb\"\n",
    "\n",
    "fp16 = False\n",
    "\n",
    "num_train_epochs = 10\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "optim = 'adamw_hf' # 'adamw_torch'\n",
    "\n",
    "learning_rate = 3e-6 / 8 * batch_size * NGPU # 5e-5\n",
    "weight_decay = 0.01 # 0\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "lr_scheduler_type = 'linear'\n",
    "warmup_ratio = 0\n",
    "\n",
    "save_total_limit = 2\n",
    "\n",
    "load_best_model_at_end = True\n",
    "metric_for_best_model ='f1_macro'\n",
    "\n",
    "save_strategy = \"epoch\"\n",
    "evaluation_strategy = \"epoch\"\n",
    "\n",
    "logging_strategy = \"steps\"\n",
    "logging_first_step = True \n",
    "logging_steps = 100\n",
    "\n",
    "print(f'batch_size: {batch_size}')\n",
    "print(f'learning_rate: {learning_rate}')\n",
    "print(f'num_train_epochs: {num_train_epochs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d3f48",
   "metadata": {
    "id": "yXVsV8jQpreV",
    "papermill": {
     "duration": 0.013683,
     "end_time": "2022-11-05T17:48:00.158807",
     "exception": false,
     "start_time": "2022-11-05T17:48:00.145124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# WandB Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea51c91c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:00.189823Z",
     "iopub.status.busy": "2022-11-05T17:48:00.188277Z",
     "iopub.status.idle": "2022-11-05T17:48:01.817773Z",
     "shell.execute_reply": "2022-11-05T17:48:01.816474Z"
    },
    "executionInfo": {
     "elapsed": 5223,
     "status": "ok",
     "timestamp": 1666002831299,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "P0IR11QyPy26",
    "outputId": "1fbef064-51fe-4272-cb98-dcdc79bcb78d",
    "papermill": {
     "duration": 1.647643,
     "end_time": "2022-11-05T17:48:01.820046",
     "exception": false,
     "start_time": "2022-11-05T17:48:00.172403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=aspect_category_detection\n",
      "env: WANDB_NOTEBOOK_NAME=./trainer_for_acd_b_new.ipynb\n",
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_WATCH=all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env WANDB_PROJECT={PROJECT_NAME}\n",
    "%env WANDB_NOTEBOOK_NAME={NOTEBOOK_PATH}\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_WATCH=all\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78790e",
   "metadata": {
    "id": "XSAzFxnH1ozQ",
    "papermill": {
     "duration": 0.020806,
     "end_time": "2022-11-05T17:48:01.863681",
     "exception": false,
     "start_time": "2022-11-05T17:48:01.842875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model, Tokenizer, and Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53094179",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256,
     "referenced_widgets": [
      "a617546d074546e1b5aecfd9455ed7c1",
      "72bf2247806d45388a7e1a0aa11d0959",
      "26c761752f7545eebd3f4031565bd21b",
      "edf47685cc1d42f4b89e5e12098e2b38",
      "fdf9b64435a14fa3a3595cbfceaa74fe",
      "c7fe824174f84db0b4cfcba3ab2d4865",
      "9372cce179da4990b10545216ddfff57",
      "5934d7aa96754d1c8f68e482e4ead238",
      "c24b01a4136347378bc40e292b4a9ae1",
      "f126b3d7919746eda30642d56666403d",
      "65d1b052cf30437595549494881dbfff",
      "3dad4c6750e34ae5a045f4d0b93f4842",
      "80e6eeca23244072bfaba7188bf166e3",
      "34cff3cdd86f497bb030e9047652091e",
      "ca89d634c4594eb7ac596999b528a608",
      "1b695bdc091843efb477445ffa98daed",
      "f421ec005ae340f285bb64edba73d38a",
      "0247963a6fb6431593c3525f80e556a8",
      "3cdcc7db38cc4be0b6d8968fda36033e",
      "70961bf6efb244bbbbd6aa0f55a9d9b5",
      "22c00b59825045c78a680eeab20c2850",
      "220328c5c2b947d997375647045b0188",
      "f176e7c6260c4d9ca52d0e2f7be37835",
      "beddebd7683c4152ba665807ec63e3f1",
      "5f5a745dba1f4f6f9ad72680e44c1f9d",
      "7f0563c80b144498a1cb781c0eda51ca",
      "04d34de8dee54d16b492cde56978c682",
      "873055642db74cdf96bbc78c2254eb08",
      "006f8165820f493daf38f10e7ed02caa",
      "2d4ba99325754feb8987027cd582568a",
      "ede7f3ad3c0d4395b2d5c6650cbb4871",
      "a118595725754a5088c1953b1654ed9d",
      "6b3cd7406576456fa820093599bd4ca7",
      "588821b286b34625a9dbd1008fb553a4",
      "fff8b7627a41445e9bcaaa3c2c280d4d",
      "98b7e9b6cdb648388cdff7ab2626054d",
      "21c14493175b41278c9608f48aefaf63",
      "49347ce9a69544b79514e3bad1065196",
      "568587eeda734aa1974d3ab04284ac23",
      "e9de070546d54e74b5571640c4601977",
      "b634013c76804be5868bea6de3b21876",
      "51a2b42366f647bc873f83e793247d0f",
      "1adb644a97e04715a675cef21c9d4349",
      "64e2c8736f4e4b3d83c8a646c0850542"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:01.903666Z",
     "iopub.status.busy": "2022-11-05T17:48:01.902230Z",
     "iopub.status.idle": "2022-11-05T17:48:03.717398Z",
     "shell.execute_reply": "2022-11-05T17:48:03.716380Z"
    },
    "executionInfo": {
     "elapsed": 25262,
     "status": "ok",
     "timestamp": 1666002856543,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "v7hpRDtF7ChY",
    "outputId": "9e26624f-a607-468c-d346-bdff6569a989",
    "papermill": {
     "duration": 1.840173,
     "end_time": "2022-11-05T17:48:03.722385",
     "exception": false,
     "start_time": "2022-11-05T17:48:01.882212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue_roberta_base_mlm_fine_tuned were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue_roberta_base_mlm_fine_tuned and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, label2id=label2id, id2label=id2label, num_labels=num_labels\n",
    ")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d5b8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:03.756549Z",
     "iopub.status.busy": "2022-11-05T17:48:03.755986Z",
     "iopub.status.idle": "2022-11-05T17:48:03.761326Z",
     "shell.execute_reply": "2022-11-05T17:48:03.760367Z"
    },
    "papermill": {
     "duration": 0.024584,
     "end_time": "2022-11-05T17:48:03.763379",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.738795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.config.hidden_dropout_prob = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b17737f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:03.794930Z",
     "iopub.status.busy": "2022-11-05T17:48:03.794508Z",
     "iopub.status.idle": "2022-11-05T17:48:03.801015Z",
     "shell.execute_reply": "2022-11-05T17:48:03.800333Z"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1666002860165,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "jRpAE71Baeiv",
    "papermill": {
     "duration": 0.023975,
     "end_time": "2022-11-05T17:48:03.802432",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.778457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = f'./dataset/{DATA_V}/raw_train.csv'\n",
    "# dev_path = f'./dataset/{DATA_V}/raw_dev.csv'\n",
    "# test_path = f'./dataset/{DATA_V}/raw_test.csv'\n",
    "# train = pd.read_csv(train_path)\n",
    "# dev = pd.read_csv(dev_path)\n",
    "# test = pd.read_csv(test_path)\n",
    "\n",
    "# print(len(tokenizer))\n",
    "# tokenizer_train_data = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form]).to_frame().drop_duplicates()\n",
    "# tokenizer_train_data = tokenizer_train_data.sentence_form.to_list()\n",
    "# new_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# new_tokenizer = tokenizer.train_new_from_iterator(tokenizer_train_data, vocab_size=1)\n",
    "# new_tokens = set(list(new_tokenizer.vocab.keys())) - set(tokenizer.vocab.keys())\n",
    "# tokenizer.add_tokens(list(new_tokens))\n",
    "# print(len(new_tokenizer))\n",
    "# print(len(tokenizer))\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2da5bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:03.829766Z",
     "iopub.status.busy": "2022-11-05T17:48:03.829466Z",
     "iopub.status.idle": "2022-11-05T17:48:03.833002Z",
     "shell.execute_reply": "2022-11-05T17:48:03.832333Z"
    },
    "papermill": {
     "duration": 0.018951,
     "end_time": "2022-11-05T17:48:03.834501",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.815550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(new_tokens))\n",
    "# print(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64135b05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:03.863787Z",
     "iopub.status.busy": "2022-11-05T17:48:03.863325Z",
     "iopub.status.idle": "2022-11-05T17:48:03.868978Z",
     "shell.execute_reply": "2022-11-05T17:48:03.868330Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666002862318,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "fPhUW964vTzH",
    "outputId": "f7259eb0-6a7d-4527-bd65-ab97d3391bf1",
    "papermill": {
     "duration": 0.022196,
     "end_time": "2022-11-05T17:48:03.870454",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.848258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'True': 0, 'False': 1}, {0: 'True', 1: 'False'}, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.label2id, model.config.id2label, model.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f16cd",
   "metadata": {
    "id": "V-EVcOAQ18dS",
    "papermill": {
     "duration": 0.013185,
     "end_time": "2022-11-05T17:48:03.896732",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.883547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5616600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "2acbe67064e642e68645ef60458fdfdc",
      "eb4a00ce79f84c2bb6150a24503c1eb6",
      "511d2db235684e2e8621ea2faaebcb1d",
      "c90289bd74b34fafb2bac06f3b22fc7f",
      "f0a629bf3847497ab655c1cda0c9c5af",
      "108c8184c356401c83d1a9679bcb5848",
      "a2ebdd246c7e48b7a019a795526e25fa",
      "2f04c700f3eb41bca2b1dbf0004e47fd",
      "573cb79e515b4a34a99bcd4860bcc2b0",
      "ee834bb939ee462d9a9f34ebf02aac59",
      "4af8016f4e5349e1ab0775f17f2db82f",
      "fa1aee690e874736adc1e4c381327507",
      "7b1808532a3c4903ab98aa58af8e1248",
      "62959d0b97384b48af1ccc453409e5ee",
      "cd84bc40872c43e997130f05d7d170a0",
      "91eb60b340064785ad8cc6a305c3ff55",
      "4b08a69907db4c11a663e3ce1d8d86ae",
      "145aa8c1774e47e6b41cb05b3410f524",
      "3ea409649a9f4e24900c36fe55849691",
      "023e50a08de74d0dbb516866989a50cd",
      "43a1fdd397714aa78df15d8023e4fc8d",
      "a3af79f2f66745b085ed3439060d1b51"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:03.925994Z",
     "iopub.status.busy": "2022-11-05T17:48:03.925264Z",
     "iopub.status.idle": "2022-11-05T17:48:07.217870Z",
     "shell.execute_reply": "2022-11-05T17:48:07.216440Z"
    },
    "executionInfo": {
     "elapsed": 5329,
     "status": "ok",
     "timestamp": 1666002867640,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "qtEXOy22Gz8l",
    "outputId": "14e8d37b-0df4-472e-8039-246a78344968",
    "papermill": {
     "duration": 3.311187,
     "end_time": "2022-11-05T17:48:07.221229",
     "exception": false,
     "start_time": "2022-11-05T17:48:03.910042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5344378f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:07.261481Z",
     "iopub.status.busy": "2022-11-05T17:48:07.260925Z",
     "iopub.status.idle": "2022-11-05T17:48:07.269332Z",
     "shell.execute_reply": "2022-11-05T17:48:07.268369Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666002867641,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "1d61JHiLEadB",
    "papermill": {
     "duration": 0.028744,
     "end_time": "2022-11-05T17:48:07.271300",
     "exception": false,
     "start_time": "2022-11-05T17:48:07.242556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(references=labels, predictions=predictions)['accuracy']\n",
    "    f1_true, f1_false = tuple(f1_metric.compute(references=labels, predictions=predictions, average=None, labels=[0,1])['f1'])\n",
    "    f1_macro = f1_metric.compute(references=labels, predictions=predictions, average='macro')['f1']\n",
    "    f1_micro = f1_metric.compute(references=labels, predictions=predictions, average='micro')['f1']\n",
    "    \n",
    "    return {'accuracy': accuracy, 'f1_true': f1_true, 'f1_false': f1_false, 'f1_macro': f1_macro, 'f1_micro': f1_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac6eb5",
   "metadata": {
    "id": "EBp5WFGR2JRb",
    "papermill": {
     "duration": 0.014169,
     "end_time": "2022-11-05T17:48:07.299440",
     "exception": false,
     "start_time": "2022-11-05T17:48:07.285271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec6118e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:07.330319Z",
     "iopub.status.busy": "2022-11-05T17:48:07.329408Z",
     "iopub.status.idle": "2022-11-05T17:48:07.337240Z",
     "shell.execute_reply": "2022-11-05T17:48:07.336375Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666002867641,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "ryHwmgr7B3Ze",
    "papermill": {
     "duration": 0.025586,
     "end_time": "2022-11-05T17:48:07.339066",
     "exception": false,
     "start_time": "2022-11-05T17:48:07.313480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"form\"], examples[\"pair\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0de104a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "84347e32e7c347dc944f17495ce5d0d1",
      "a2bbca70b92a4cadb7490f9557090cb8",
      "bcb47f2fcce3498bad5649df3765875c",
      "58f58af09b4c40c5842a85ef74691b43",
      "c24715f2177f4671b7d59194e70adf05",
      "78b1cc22cf7d4dc0b336aad1de510d65",
      "d2451ff40bc542d7a4e4a5c078d52a80",
      "1571b488fd5f43abbe7403a9eb6c5dc0",
      "a86755357a82421aadf92b445e936d21",
      "889b946a743142329787ca7652e8351b",
      "795293e6d69648069d41e689c4288e3c",
      "1d3d62930fb54eb1b42416c2d29b60c9",
      "34718e57ddbd45fd9b39df78c39ac684",
      "354c39a508c24098945ecc3e0370c802",
      "fadede78260f47dcbb5dd57b06f63e03",
      "c9105a4d4c8146518865674f0c01eeba",
      "2e61589dbff743109b00222189d0852d",
      "c45b08001d0842ef96b9e0d5bd238a47",
      "e9f1f74a460c479583ac50966ce6dc00",
      "b30b5031b69246178354057c0adb28d2",
      "c4c70934fa6949d393e6619ba7918f9f",
      "99ff889a390148d6806eb682f1c0aea8"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:07.369395Z",
     "iopub.status.busy": "2022-11-05T17:48:07.368787Z",
     "iopub.status.idle": "2022-11-05T17:48:17.393404Z",
     "shell.execute_reply": "2022-11-05T17:48:17.392368Z"
    },
    "executionInfo": {
     "elapsed": 50966,
     "status": "ok",
     "timestamp": 1666002918598,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "lM9mxmKb2Nah",
    "outputId": "97146b6f-80f1-4c8b-d6ec-efd8f524f65c",
    "papermill": {
     "duration": 10.042964,
     "end_time": "2022-11-05T17:48:17.396217",
     "exception": false,
     "start_time": "2022-11-05T17:48:07.353253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3033dfd4482648bbbeb57b21022269e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa15667a025148bc958c690ad1f8167c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(TRAIN_DATA_PATH)\n",
    "eval_dataset = pd.read_csv(EVAL_DATA_PATH)\n",
    "train_dataset = datasets.Dataset.from_pandas(train_dataset).shuffle(seed=42)\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_dataset).shuffle(seed=42)\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2bb1a7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:17.455675Z",
     "iopub.status.busy": "2022-11-05T17:48:17.455134Z",
     "iopub.status.idle": "2022-11-05T17:48:17.465315Z",
     "shell.execute_reply": "2022-11-05T17:48:17.464392Z"
    },
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1666002919300,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "YUaaH_gi7UFe",
    "outputId": "400c3962-ef13-4f6c-ce89-680522f3b3c8",
    "papermill": {
     "duration": 0.039955,
     "end_time": "2022-11-05T17:48:17.467366",
     "exception": false,
     "start_time": "2022-11-05T17:48:17.427411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 69825)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa5bf10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:17.508936Z",
     "iopub.status.busy": "2022-11-05T17:48:17.508014Z",
     "iopub.status.idle": "2022-11-05T17:48:19.825712Z",
     "shell.execute_reply": "2022-11-05T17:48:19.824378Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666002919301,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "AW4V6ZVKdMRP",
    "outputId": "ebd2c436-824c-4b5e-8359-129c4e32b6a1",
    "papermill": {
     "duration": 2.338604,
     "end_time": "2022-11-05T17:48:19.828062",
     "exception": false,
     "start_time": "2022-11-05T17:48:17.489458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 완전 감동 ㅠ. ㅠ [SEP] 본품 # 디자인 [SEP] 1\n",
      "[CLS] # 텐셀마스크 라 그런지 얼굴에 밀착이 진짜 잘되구요 ~ [SEP] 브랜드 # 가격 [SEP] 1\n"
     ]
    }
   ],
   "source": [
    "k = random.randrange(len(train_dataset))\n",
    "print(tokenizer.decode(train_dataset['input_ids'][k]), train_dataset['labels'][k])\n",
    "k = random.randrange(len(eval_dataset))\n",
    "print(tokenizer.decode(eval_dataset['input_ids'][k]), eval_dataset['labels'][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c6529",
   "metadata": {
    "id": "admrPVvW1_Q_",
    "papermill": {
     "duration": 0.014755,
     "end_time": "2022-11-05T17:48:19.858339",
     "exception": false,
     "start_time": "2022-11-05T17:48:19.843584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9821a47e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:19.889848Z",
     "iopub.status.busy": "2022-11-05T17:48:19.889196Z",
     "iopub.status.idle": "2022-11-05T17:48:19.905460Z",
     "shell.execute_reply": "2022-11-05T17:48:19.904391Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666002919301,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "B0b4moolsNWK",
    "papermill": {
     "duration": 0.034572,
     "end_time": "2022-11-05T17:48:19.907434",
     "exception": false,
     "start_time": "2022-11-05T17:48:19.872862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=run_name,\n",
    "    run_name=run_name,\n",
    "    report_to=report_to,\n",
    "\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "\n",
    "    optim=optim,\n",
    "\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    adam_epsilon=adam_epsilon,\n",
    "\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "\n",
    "    save_total_limit=save_total_limit,\n",
    "\n",
    "    load_best_model_at_end=load_best_model_at_end,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    "    \n",
    "    save_strategy=save_strategy,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_first_step=logging_first_step, \n",
    "    logging_steps=logging_steps,\n",
    "    \n",
    "    fp16=fp16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d100dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:19.939598Z",
     "iopub.status.busy": "2022-11-05T17:48:19.938460Z",
     "iopub.status.idle": "2022-11-05T17:48:19.945810Z",
     "shell.execute_reply": "2022-11-05T17:48:19.944411Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666002919302,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "w1aRCCDR9kVb",
    "papermill": {
     "duration": 0.025999,
     "end_time": "2022-11-05T17:48:19.947721",
     "exception": false,
     "start_time": "2022-11-05T17:48:19.921722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec70656b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:19.978775Z",
     "iopub.status.busy": "2022-11-05T17:48:19.977614Z",
     "iopub.status.idle": "2022-11-05T17:48:25.589713Z",
     "shell.execute_reply": "2022-11-05T17:48:25.588408Z"
    },
    "executionInfo": {
     "elapsed": 4075,
     "status": "ok",
     "timestamp": 1666002923371,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "pwe87xkaMEK6",
    "papermill": {
     "duration": 5.630994,
     "end_time": "2022-11-05T17:48:25.592874",
     "exception": false,
     "start_time": "2022-11-05T17:48:19.961880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    # callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce09b1",
   "metadata": {
    "id": "9KNsbWs72BoC",
    "papermill": {
     "duration": 0.0207,
     "end_time": "2022-11-05T17:48:25.636685",
     "exception": false,
     "start_time": "2022-11-05T17:48:25.615985",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1649e8c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2022-11-05T17:48:25.676464Z",
     "iopub.status.busy": "2022-11-05T17:48:25.675888Z",
     "iopub.status.idle": "2022-11-05T22:36:23.157583Z",
     "shell.execute_reply": "2022-11-05T22:36:23.156354Z"
    },
    "executionInfo": {
     "elapsed": 13721386,
     "status": "ok",
     "timestamp": 1666016644733,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "tyN8PA8tMFsU",
    "outputId": "2f105feb-e18e-43d4-d0ed-49832d7ffc24",
    "papermill": {
     "duration": 17277.51717,
     "end_time": "2022-11-05T22:36:23.173094",
     "exception": false,
     "start_time": "2022-11-05T17:48:25.655924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 75000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 23440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Number of trainable parameters = 111021314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/jongmin/Jeonghyeon/codes/absa/wandb/run-20221106_024825-350a5etu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/aspect_category_detection/runs/350a5etu\" target=\"_blank\">klue_roberta_base_mlm_fine_tuned_uncleaned_v13</a></strong> to <a href=\"https://wandb.ai/dotsnangles/aspect_category_detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23440' max='23440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23440/23440 4:47:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 True</th>\n",
       "      <th>F1 False</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.091617</td>\n",
       "      <td>0.971515</td>\n",
       "      <td>0.621647</td>\n",
       "      <td>0.985200</td>\n",
       "      <td>0.803424</td>\n",
       "      <td>0.971515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.077270</td>\n",
       "      <td>0.975281</td>\n",
       "      <td>0.676537</td>\n",
       "      <td>0.987150</td>\n",
       "      <td>0.831843</td>\n",
       "      <td>0.975281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>0.976169</td>\n",
       "      <td>0.687100</td>\n",
       "      <td>0.987613</td>\n",
       "      <td>0.837357</td>\n",
       "      <td>0.976169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.102645</td>\n",
       "      <td>0.975696</td>\n",
       "      <td>0.702750</td>\n",
       "      <td>0.987330</td>\n",
       "      <td>0.845040</td>\n",
       "      <td>0.975696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.104834</td>\n",
       "      <td>0.974164</td>\n",
       "      <td>0.698126</td>\n",
       "      <td>0.986504</td>\n",
       "      <td>0.842315</td>\n",
       "      <td>0.974164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.130790</td>\n",
       "      <td>0.974393</td>\n",
       "      <td>0.692784</td>\n",
       "      <td>0.986640</td>\n",
       "      <td>0.839712</td>\n",
       "      <td>0.974393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.146680</td>\n",
       "      <td>0.975567</td>\n",
       "      <td>0.709171</td>\n",
       "      <td>0.987248</td>\n",
       "      <td>0.848210</td>\n",
       "      <td>0.975567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.162796</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>0.703684</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.845444</td>\n",
       "      <td>0.975467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.172943</td>\n",
       "      <td>0.975009</td>\n",
       "      <td>0.692728</td>\n",
       "      <td>0.986975</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>0.975009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.179610</td>\n",
       "      <td>0.975811</td>\n",
       "      <td>0.701326</td>\n",
       "      <td>0.987395</td>\n",
       "      <td>0.844361</td>\n",
       "      <td>0.975811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-2344] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-4688] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-7032] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-11720] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-9376] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-14064] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-18752] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: id, form, pair. If id, form, pair are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 69825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-23440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-23440/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-23440/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-23440/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-23440/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-21096] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from klue_roberta_base_mlm_fine_tuned_uncleaned_v13/checkpoint-16408 (score: 0.8482097990891027).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tmp/tmp7q40ake2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmp7q40ake2/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /tmp/tmp7q40ake2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /tmp/tmp7q40ake2/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /tmp/tmp7q40ake2/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█▇▅▅▇▇▆▇</td></tr><tr><td>eval/f1_false</td><td>▁▇█▇▅▅▇▇▆▇</td></tr><tr><td>eval/f1_macro</td><td>▁▅▆█▇▇██▇▇</td></tr><tr><td>eval/f1_micro</td><td>▁▇█▇▅▅▇▇▆▇</td></tr><tr><td>eval/f1_true</td><td>▁▅▆▇▇▇██▇▇</td></tr><tr><td>eval/loss</td><td>▂▁▂▃▃▅▆▇██</td></tr><tr><td>eval/runtime</td><td>▁▆▂▁▄▅▄█▅█</td></tr><tr><td>eval/samples_per_second</td><td>█▃▇█▅▄▅▁▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▃▇█▅▄▅▁▃▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97581</td></tr><tr><td>eval/f1_false</td><td>0.9874</td></tr><tr><td>eval/f1_macro</td><td>0.84436</td></tr><tr><td>eval/f1_micro</td><td>0.97581</td></tr><tr><td>eval/f1_true</td><td>0.70133</td></tr><tr><td>eval/loss</td><td>0.17961</td></tr><tr><td>eval/runtime</td><td>517.7557</td></tr><tr><td>eval/samples_per_second</td><td>134.861</td></tr><tr><td>eval/steps_per_second</td><td>4.216</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>23440</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0057</td></tr><tr><td>train/total_flos</td><td>2.253732833563296e+16</td></tr><tr><td>train/train_loss</td><td>0.04013</td></tr><tr><td>train/train_runtime</td><td>17247.1161</td></tr><tr><td>train/train_samples_per_second</td><td>43.486</td></tr><tr><td>train/train_steps_per_second</td><td>1.359</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">klue_roberta_base_mlm_fine_tuned_uncleaned_v13</strong>: <a href=\"https://wandb.ai/dotsnangles/aspect_category_detection/runs/350a5etu\" target=\"_blank\">https://wandb.ai/dotsnangles/aspect_category_detection/runs/350a5etu</a><br/>Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221106_024825-350a5etu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eab6fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T22:36:23.216175Z",
     "iopub.status.busy": "2022-11-05T22:36:23.214653Z",
     "iopub.status.idle": "2022-11-05T22:36:26.005536Z",
     "shell.execute_reply": "2022-11-05T22:36:26.004434Z"
    },
    "executionInfo": {
     "elapsed": 7718,
     "status": "ok",
     "timestamp": 1666016652428,
     "user": {
      "displayName": "Jeonghyeon Park",
      "userId": "12513544746873038725"
     },
     "user_tz": -540
    },
    "id": "njKzTZtir0SC",
    "papermill": {
     "duration": 2.816445,
     "end_time": "2022-11-05T22:36:26.008721",
     "exception": false,
     "start_time": "2022-11-05T22:36:23.192276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "keep = [\n",
    "    'added_tokens.json',\n",
    "    'config.json',\n",
    "    'pytorch_model.bin',\n",
    "    'special_tokens_map.json',\n",
    "    'tokenizer.json',\n",
    "    'tokenizer_config.json',\n",
    "    'vocab.txt'\n",
    "]\n",
    "\n",
    "ckpts = os.listdir(run_name)\n",
    "for ckpt in ckpts:\n",
    "    ckpt = os.path.join(run_name, ckpt)\n",
    "    for item in os.listdir(ckpt):\n",
    "        if item not in keep:\n",
    "            os.remove(os.path.join(ckpt, item))\n",
    "\n",
    "!mv wandb {run_name} {SAVE_PATH}/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3.10.6 ('jeonghyeon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17316.339424,
   "end_time": "2022-11-05T22:36:30.583989",
   "environment_variables": {},
   "exception": null,
   "input_path": "./trainer_for_acd_b_new.ipynb",
   "output_path": "./papermill/trainer_for_acd_b_new.ipynb",
   "parameters": {},
   "start_time": "2022-11-05T17:47:54.244565",
   "version": "2.4.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "061d7091da8b4c24bb2d3822c7e6e200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0c29ca9185d6411492d861a2c56d0d0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d7d1751828945a39f3734516d1ef770": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0e67470e4e104768aaed5e2434678c8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1403c46f38bc4d6980bcf901a35965ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16f746878bf04a9a9c5940f4c4e0786a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "178396522bde48da9bd11dcc6e820b87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "267fcfa89850466e98edd39ecbe91be8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3033dfd4482648bbbeb57b21022269e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad809e56039249babcbc5db67678db0e",
        "IPY_MODEL_9d9c5822cf9f427b89545633c81aeccc",
        "IPY_MODEL_dc1797cfcedf4dd3bd52f8cccd678950"
       ],
       "layout": "IPY_MODEL_a573a93311434554bd539b6cda72c606",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3c72ea9b117f4fd18e69afa20f657ad9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bb30b56b9cbf4e04b57e459b82785550",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ff454aed0e1430da9f274b0f4ffbb59",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "3cca0541411744c3af5486ddab47ab25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d06898fbc224ff5ad7d7da715edf0c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58f6447cc41c44acb98702bab570da5e",
       "placeholder": "​",
       "style": "IPY_MODEL_b7aaed88037c4bb3a38a739926a83183",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "414064c13f8a4b598f89af04131bea3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "LabelView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1403c46f38bc4d6980bcf901a35965ff",
       "placeholder": "​",
       "style": "IPY_MODEL_720bd38f0b9c477eaf7c33710da89173",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "58f6447cc41c44acb98702bab570da5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cd3e76da3e9476dbd2417a00e63f092": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fa42436ef9234f1f9c729080e8c63606",
       "max": 70.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_061d7091da8b4c24bb2d3822c7e6e200",
       "tabbable": null,
       "tooltip": null,
       "value": 69.0
      }
     },
     "6131b5e579354cb7b2469404e6239477": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d84b2dfede64355b94e42f22a40f693": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c44787a52dab4be19a54df1d65519d25",
       "placeholder": "​",
       "style": "IPY_MODEL_8299c827e3a14c28abfc5462a610886c",
       "tabbable": null,
       "tooltip": null,
       "value": " 99%"
      }
     },
     "6ff454aed0e1430da9f274b0f4ffbb59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "720bd38f0b9c477eaf7c33710da89173": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "791012edfe934ee2b2c2be0c278c1bbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8299c827e3a14c28abfc5462a610886c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9a4ac4e73c7b4f509db5efa45753a3d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d06898fbc224ff5ad7d7da715edf0c9",
        "IPY_MODEL_3c72ea9b117f4fd18e69afa20f657ad9"
       ],
       "layout": "IPY_MODEL_791012edfe934ee2b2c2be0c278c1bbd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9d35b87d4ab14a94828dafb852514323": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_414064c13f8a4b598f89af04131bea3a",
        "IPY_MODEL_c54ca09ff85c463585ae9e01470564fb"
       ],
       "layout": "IPY_MODEL_0e67470e4e104768aaed5e2434678c8d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9d9c5822cf9f427b89545633c81aeccc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_acee21d84d294cd491aacc6c9e02cb89",
       "max": 75.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3cca0541411744c3af5486ddab47ab25",
       "tabbable": null,
       "tooltip": null,
       "value": 74.0
      }
     },
     "a573a93311434554bd539b6cda72c606": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa15667a025148bc958c690ad1f8167c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d84b2dfede64355b94e42f22a40f693",
        "IPY_MODEL_5cd3e76da3e9476dbd2417a00e63f092",
        "IPY_MODEL_e7da0eeb71da426a9cb1fd34754dfd39"
       ],
       "layout": "IPY_MODEL_d9a9f5385a6c41fe939748a894c00a3e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "acee21d84d294cd491aacc6c9e02cb89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad809e56039249babcbc5db67678db0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c29ca9185d6411492d861a2c56d0d0b",
       "placeholder": "​",
       "style": "IPY_MODEL_0d7d1751828945a39f3734516d1ef770",
       "tabbable": null,
       "tooltip": null,
       "value": " 99%"
      }
     },
     "b7aaed88037c4bb3a38a739926a83183": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "LabelStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "bb30b56b9cbf4e04b57e459b82785550": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c42b8963ce834783b5526bf21d7af851": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c44787a52dab4be19a54df1d65519d25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c54ca09ff85c463585ae9e01470564fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_178396522bde48da9bd11dcc6e820b87",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_16f746878bf04a9a9c5940f4c4e0786a",
       "tabbable": null,
       "tooltip": null,
       "value": 0.0
      }
     },
     "d3e5f7662e574d85a5d5074df045456e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d9a9f5385a6c41fe939748a894c00a3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc1797cfcedf4dd3bd52f8cccd678950": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6131b5e579354cb7b2469404e6239477",
       "placeholder": "​",
       "style": "IPY_MODEL_d3e5f7662e574d85a5d5074df045456e",
       "tabbable": null,
       "tooltip": null,
       "value": " 74/75 [00:05&lt;00:00, 15.14ba/s]"
      }
     },
     "e7da0eeb71da426a9cb1fd34754dfd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c42b8963ce834783b5526bf21d7af851",
       "placeholder": "​",
       "style": "IPY_MODEL_267fcfa89850466e98edd39ecbe91be8",
       "tabbable": null,
       "tooltip": null,
       "value": " 69/70 [00:04&lt;00:00, 15.66ba/s]"
      }
     },
     "fa42436ef9234f1f9c729080e8c63606": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}