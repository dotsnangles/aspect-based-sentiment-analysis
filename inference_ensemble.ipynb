{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"  # Set the GPUs to use\n","import torch\n","print('Current cuda device:', torch.cuda.current_device())\n","print('Count of using GPUs:', torch.cuda.device_count())"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":879,"status":"ok","timestamp":1666094093089,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"_v8VXBZdKuUD"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification,\n",")\n","\n","import torch, copy, os\n","from module.score import evaluation_f1\n","from module.load_json import *\n","from module.maps import *\n","from module.args import print_torch_info\n","from module.inference import *\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print_torch_info()"]},{"cell_type":"markdown","metadata":{},"source":["# Paths and Modes"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1666094093090,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"T1iAj-3Vmqt0"},"outputs":[],"source":["EVAL_MODE = False\n","\n","RESULT_ID = 'uncleaned_v22_run_1_ensemble_v3'\n","\n","ACD_1_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_klue_roberta_base_mlm_fine_tuned_uncleaned_v22_run_1/checkpoint-37500'\n","ACD_2_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_monologg_koelectra_base_v3_discriminator_uncleaned_v22_run_1/checkpoint-37500'\n","ACD_3_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_snunlp_kr_electra_discriminator_uncleaned_v22_run_1/checkpoint-37500'\n","\n","ASC_1_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_klue_roberta_base_mlm_fine_tuned_uncleaned_v22_run_1/checkpoint-1608'\n","ASC_2_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_monologg_koelectra_base_v3_discriminator_uncleaned_v22_run_1/checkpoint-1608'\n","ASC_3_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_snunlp_kr_electra_discriminator_uncleaned_v22_run_1/checkpoint-1608'\n","\n","TEST_DATA_PATH = 'dataset/nikluge-sa-2022-test.jsonl'\n","EVAL_DATA_PATH = 'dataset/nikluge-sa-2022-dev.jsonl'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if EVAL_MODE == True:\n","    TEST_DATA_PATH = EVAL_DATA_PATH\n","test_data = jsonlload(TEST_DATA_PATH)\n","print('>>>>> >>>>> >>>>> ', TEST_DATA_PATH, ' <<<<< <<<<< <<<<<', '\\n', sep='')"]},{"cell_type":"markdown","metadata":{"id":"XSAzFxnH1ozQ"},"source":["# Load Models and Tokenizers"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3554,"status":"ok","timestamp":1666094096632,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"BlFBKYKDPNuN"},"outputs":[],"source":["acd_model_1 = AutoModelForSequenceClassification.from_pretrained(ACD_1_CHECKPOINT)\n","acd_model_2 = AutoModelForSequenceClassification.from_pretrained(ACD_2_CHECKPOINT)\n","acd_model_3 = AutoModelForSequenceClassification.from_pretrained(ACD_3_CHECKPOINT)\n","acd_tokenizer_1 = AutoTokenizer.from_pretrained(ACD_1_CHECKPOINT)\n","acd_tokenizer_2 = AutoTokenizer.from_pretrained(ACD_2_CHECKPOINT)\n","acd_tokenizer_3 = AutoTokenizer.from_pretrained(ACD_3_CHECKPOINT)\n","\n","asc_model_1 = AutoModelForSequenceClassification.from_pretrained(ASC_1_CHECKPOINT)\n","asc_model_2 = AutoModelForSequenceClassification.from_pretrained(ASC_2_CHECKPOINT)\n","asc_model_3 = AutoModelForSequenceClassification.from_pretrained(ASC_3_CHECKPOINT)\n","asc_tokenizer_1 = AutoTokenizer.from_pretrained(ASC_1_CHECKPOINT)\n","asc_tokenizer_2 = AutoTokenizer.from_pretrained(ASC_2_CHECKPOINT)\n","asc_tokenizer_3 = AutoTokenizer.from_pretrained(ASC_3_CHECKPOINT)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # v1\n","\n","# def acd_ensemble(form, acd_pair):\n","#     acd_model_1.to(device)\n","#     acd_model_2.to(device)\n","#     acd_model_3.to(device)\n","#     acd_model_1.eval()\n","#     acd_model_2.eval()\n","#     acd_model_3.eval()\n","\n","#     acd_encoded_1 = acd_tokenizer_1(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","#     acd_encoded_1 = {k:v.to(device) for k,v in acd_encoded_1.items()}\n","\n","#     acd_encoded_2 = acd_tokenizer_2(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","#     acd_encoded_2 = {k:v.to(device) for k,v in acd_encoded_2.items()}\n","\n","#     acd_encoded_3 = acd_tokenizer_3(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","#     acd_encoded_3 = {k:v.to(device) for k,v in acd_encoded_3.items()}\n","\n","#     with torch.no_grad():\n","#         acd_outputs_1 = acd_model_1(**acd_encoded_1)['logits']\n","#         acd_outputs_2 = acd_model_2(**acd_encoded_2)['logits']\n","#         acd_outputs_3 = acd_model_3(**acd_encoded_3)['logits']\n","\n","#     acd_outputs = acd_outputs_1 + acd_outputs_2 + acd_outputs_3\n","#     acd_predictions = acd_outputs.argmax(-1)[0]\n","    \n","#     return acd_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# v2\n","\n","def acd_ensemble(form, acd_pair):\n","    acd_model_1.to(device)\n","    acd_model_2.to(device)\n","    acd_model_3.to(device)\n","    acd_model_1.eval()\n","    acd_model_2.eval()\n","    acd_model_3.eval()\n","\n","    acd_encoded_1 = acd_tokenizer_1(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","    acd_encoded_1 = {k:v.to(device) for k,v in acd_encoded_1.items()}\n","\n","    acd_encoded_2 = acd_tokenizer_2(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","    acd_encoded_2 = {k:v.to(device) for k,v in acd_encoded_2.items()}\n","\n","    acd_encoded_3 = acd_tokenizer_3(form, acd_pair, truncation=True, return_tensors=\"pt\")\n","    acd_encoded_3 = {k:v.to(device) for k,v in acd_encoded_3.items()}\n","\n","    with torch.no_grad():\n","        acd_outputs_1 = acd_model_1(**acd_encoded_1)['logits']\n","        acd_outputs_2 = acd_model_2(**acd_encoded_2)['logits']\n","        acd_outputs_3 = acd_model_3(**acd_encoded_3)['logits']\n","\n","    acd_outputs = acd_outputs_1 + acd_outputs_2 + acd_outputs_3\n","    \n","    acd_predictions_1 = acd_outputs_1.argmax(-1).squeeze()\n","    acd_predictions_2 = acd_outputs_2.argmax(-1).squeeze()\n","    acd_predictions_3 = acd_outputs_3.argmax(-1).squeeze()\n","    \n","    if 0 in [acd_predictions_1, acd_predictions_2, acd_predictions_3]:\n","        return 0\n","    \n","    return 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def asc_ensemble(form, asc_pair):\n","    asc_model_1.to(device)\n","    asc_model_2.to(device)\n","    asc_model_3.to(device)\n","    asc_model_1.eval()\n","    asc_model_2.eval()\n","    asc_model_3.eval()\n","\n","    asc_encoded_1 = asc_tokenizer_1(form, asc_pair, truncation=True, return_tensors=\"pt\")\n","    asc_encoded_1 = {k:v.to(device) for k,v in asc_encoded_1.items()}\n","\n","    asc_encoded_2 = asc_tokenizer_2(form, asc_pair, truncation=True, return_tensors=\"pt\")\n","    asc_encoded_2 = {k:v.to(device) for k,v in asc_encoded_2.items()}\n","\n","    asc_encoded_3 = asc_tokenizer_3(form, asc_pair, truncation=True, return_tensors=\"pt\")\n","    asc_encoded_3 = {k:v.to(device) for k,v in asc_encoded_3.items()}\n","\n","    with torch.no_grad():\n","        asc_outputs_1 = asc_model_1(**asc_encoded_1)['logits']\n","        asc_outputs_2 = asc_model_2(**asc_encoded_2)['logits']\n","        asc_outputs_3 = asc_model_3(**asc_encoded_3)['logits']\n","\n","    asc_outputs = asc_outputs_1 + asc_outputs_2 + asc_outputs_3\n","    \n","    return asc_outputs"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for entity_property_pair in entity_property_pairs:\n","    num_of_ep_pairs = len(entity_property_pair)\n","    RESULT_SAVE_NAME = f'{RESULT_ID}_num_of_ep_pairs_{num_of_ep_pairs}.json'\n","    \n","    pred_data = inference_m_ensemble(acd_ensemble, asc_ensemble, copy.deepcopy(test_data), entity_property_pair)\n","    \n","    if EVAL_MODE == False:\n","        save_path = './'\n","\n","        jsondump(pred_data, os.path.join(save_path, RESULT_SAVE_NAME))\n","        pred_data = jsonload(os.path.join(save_path, RESULT_SAVE_NAME))\n","    \n","    print(RESULT_SAVE_NAME)    \n","    print(len(test_data), len(pred_data))\n","    \n","    if EVAL_MODE == True:\n","        print('INFERENCE DATA: ', TEST_DATA_PATH)\n","\n","        print('EVAL_MODE :', EVAL_MODE)\n","\n","        result = evaluation_f1(test_data, pred_data)\n","        print(list(result.items())[0])\n","        print(list(result.items())[1])\n","    break"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1lKTzwHyfXqUlglH4FYVH3lca6fPTxdYY","timestamp":1665143444868},{"file_id":"1SYzd80ssw5Xa_9cqyxAgVHC8lconiyjO","timestamp":1664892294191},{"file_id":"1ol6PhPqw6eJZDA7lphJRBh83aKzP4lLr","timestamp":1664726608470},{"file_id":"1SFw-WNKMa9Ds61AP8W7feAFKz7BAHJ8P","timestamp":1664724312859},{"file_id":"1FZZECpNm4M1SB3O2esRpEC02q2TeHjn7","timestamp":1664720478054}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
