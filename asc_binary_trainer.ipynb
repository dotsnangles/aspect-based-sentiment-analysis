{"cells":[{"cell_type":"markdown","metadata":{"id":"p8Lb8VDc8Rak"},"source":["# Description"]},{"cell_type":"markdown","metadata":{"id":"9pZhmy9xKmZX"},"source":["# Modules and Global Variables"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6502,"status":"ok","timestamp":1666258918849,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"_v8VXBZdKuUD"},"outputs":[],"source":["from transformers import (\n","    AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, \n","    DefaultDataCollator, DataCollatorWithPadding, \n","    TrainingArguments, Trainer,\n",")\n","\n","from transformers.optimization import (\n","    AdamW, get_linear_schedule_with_warmup,\n","    Adafactor, AdafactorSchedule,\n",")\n","\n","import torch\n","import wandb\n","\n","import datasets\n","import evaluate\n","\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","import re\n","import random\n","\n","import demoji"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.12.1\n","torch.cuda.is_available(): True\n","NGPU: 4\n"]}],"source":["print(f'torch.__version__: {torch.__version__}')\n","print(f'torch.cuda.is_available(): {torch.cuda.is_available()}')\n","NGPU = torch.cuda.device_count()\n","print(f'NGPU: {NGPU}')\n","# NGPU = torch.cuda.device_count()\n","# if NGPU > 1:\n","#     model = torch.nn.DataParallel(model, device_ids=list(range(NGPU)))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666258918850,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"7t7eYrTJkyCV","outputId":"4a36004a-6875-4404-dc79-01c48573a154"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'True': 0, 'False': 1}\n","{0: 'True', 1: 'False'}\n"]}],"source":["### labels\n","\n","ce_labels = ['True', 'False']\n","pc_labels = ['positive', 'negative', 'neutral']\n","pc_binary_labels = ['True', 'False']\n","\n","labels = pc_binary_labels\n","\n","label2id = {k: i for i, k in enumerate(labels)}\n","id2label = {i: k for i, k in enumerate(labels)}\n","num_labels = len(labels)\n","\n","print(label2id)\n","print(id2label)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2145,"status":"ok","timestamp":1666258920989,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"Rohq6E8Lp1x1","outputId":"88391cfb-80b0-436a-f862-034b00cef374"},"outputs":[],"source":["### paths and names\n","\n","PROJECT_NAME = 'aspect_sentiment_classification_binary'\n","RUN_ID = 'uncleaned_v1'\n","\n","DATA_V = 'uncleaned_v1'\n","DATA_T = 'pc_binary' # ce or pc\n","AUGMENTATION = False\n","AUG_NAME = 'aug'\n","\n","model_checkpoint = 'snunlp/KR-ELECTRA-discriminator'\n","\n","notebook_name = 'asc_binary_trainer.ipynb'\n","\n","### fixed\n","\n","model_name = re.sub(r'[/-]', r'_', model_checkpoint).lower()\n","run_name = f'{model_name}_{RUN_ID}'\n","\n","ROOT_PATH = './'\n","SAVE_PATH = os.path.join(ROOT_PATH, 'training_results', run_name, 'asc')\n","NOTEBOOK_PATH = os.path.join('./', notebook_name)\n","\n","augornot = f'_{AUG_NAME}' if AUGMENTATION is True else ''\n","TRAIN_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_train{augornot}.csv')\n","EVAL_DATA_PATH = os.path.join(ROOT_PATH, 'dataset', DATA_V, f'{DATA_T}_dev.csv')\n","\n","!mkdir -p {SAVE_PATH}"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./training_results/snunlp_kr_electra_discriminator_uncleaned_v1/asc exists.\n","./asc_binary_trainer.ipynb exists.\n","./dataset/uncleaned_v1/pc_binary_train.csv exists.\n","./dataset/uncleaned_v1/pc_binary_dev.csv exists.\n"]}],"source":["if os.path.exists(SAVE_PATH):\n","    print(f'{SAVE_PATH} exists.')\n","else:\n","    print(f'{SAVE_PATH} does not exist.')\n","if os.path.exists(NOTEBOOK_PATH):\n","    print(f'{NOTEBOOK_PATH} exists.')\n","else:\n","    print(f'{NOTEBOOK_PATH} does not exist.')\n","if os.path.exists(TRAIN_DATA_PATH):\n","    print(f'{TRAIN_DATA_PATH} exists.')\n","else:\n","    print(f'{TRAIN_DATA_PATH} does not exist.')\n","if os.path.exists(EVAL_DATA_PATH):\n","    print(f'{EVAL_DATA_PATH} exists.')\n","else:\n","    print(f'{EVAL_DATA_PATH} does not exist.')"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666258920989,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"HnBF0kLyk4Z4"},"outputs":[],"source":["### rest of training args\n","\n","report_to=\"wandb\"\n","\n","fp16 = False\n","\n","num_train_epochs = 10\n","batch_size = 3\n","gradient_accumulation_steps = 1\n","\n","optim = 'adamw_torch' # 'adamw_hf'\n","\n","learning_rate = 3e-6 # 5e-5\n","weight_decay = 0.01 # 0\n","adam_epsilon = 1e-8\n","\n","lr_scheduler_type = 'cosine'\n","warmup_ratio = 0\n","\n","save_total_limit = 2\n","\n","load_best_model_at_end = True\n","metric_for_best_model ='f1_macro'\n","\n","save_strategy = \"epoch\"\n","evaluation_strategy = \"epoch\"\n","\n","logging_strategy = \"steps\"\n","logging_first_step = True \n","logging_steps = 500"]},{"cell_type":"markdown","metadata":{"id":"yXVsV8jQpreV"},"source":["# WandB Configuration"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":4727,"status":"ok","timestamp":1666258925707,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"P0IR11QyPy26","outputId":"1d7538ee-93e1-419d-ee09-4011e6742d6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: WANDB_PROJECT=aspect_sentiment_classification_binary\n","env: WANDB_NOTEBOOK_NAME=./asc_binary_trainer.ipynb\n","env: WANDB_LOG_MODEL=true\n","env: WANDB_WATCH=all\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdotsnangles\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["%env WANDB_PROJECT={PROJECT_NAME}\n","%env WANDB_NOTEBOOK_NAME={NOTEBOOK_PATH}\n","%env WANDB_LOG_MODEL=true\n","%env WANDB_WATCH=all\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"XSAzFxnH1ozQ"},"source":["# Load Model, Tokenizer, and Collator"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256,"referenced_widgets":["bf7dac5b27584f288107f28e482be51d","9355394179624ce3be82e1b294b1a2b5","e3db079ea80048359f6097228cdc8086","0c4bff269e8f4d9693aec278a0a8d52a","c30f1c569f584efdb38e04fd4d5f838a","e01a20c18d8249cea389638d8c005b8d","6acc835b544d451894d35e3736e0d804","c5ed91471a484c8da8249e731a16f343","bc621d540c4f48c88ef6758cc902f652","9890392cc707490d88aa6fe155917a09","f62340167e2d447096a2965b4fc60826","83be86e7a1bc4cb5ad983f549588cec5","0642dca8ab984c91a4539585afef8390","92f849d5359340cc89bce483f9d15bfe","a6d4a8cf193d4d4486b72f41e7ec7fa5","bab12b33f3b0477c9a9c9fb02aa288db","ad20f3a0ca6c42c6afc1f506046ebf3b","fe51a8730e28454d897439830382db46","684011384bc34d2692f71dfe935b4723","44649a89dc5d4156892db45e1fdee5c1","5b3593cbcc844e928f086f80d9108ba1","a7c890f084ac432b9facfa6a397f6295","d93d55f032ac46068d03caeb1330b7bc","a143eeb39a3a4f34be3eea3253d8b3f2","c2924cb5fd6642d5aa134b63aaa01dca","e615f2d044e143d387a202fcaab64972","4d894cca56034a818c9132a012504061","a8e8e78b21d6416f858f4f7352059bc0","7c3552d804164201a11b0d9a7a6d9b10","efd3eea3194c47d28ce4981dceb04f54","658511cf252648a0ae4dd509bbe12fe6","5cb0cdb0332f49caa2c9e728078da80a","1d07530c6d494b4bb5d9579e0da3c820","c9b0e46751fb474ab454ba3eddd8dbd6","e188d96fbcc54a35838b1356cf7a8797","90465c6d97ef4e83b86160ce1e66ca8b","bb83f39eb9b74852b14cc8317cacf616","86c9f350fe5f491e966c968f09428b2f","ba30ea7b361c4105966ff21c1d8a8695","f514807a72e64160b487098810593b20","110c5f6649ab4b3382cce9d0bfcca25b","2e99b266d32549aa80f6234d807ff8bb","45efd1e29eb445d0bbdb4d0e90dec407","dff996c84db24f52bef3d54528588226"]},"executionInfo":{"elapsed":25161,"status":"ok","timestamp":1666258950864,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"v7hpRDtF7ChY","outputId":"32ce331a-b87f-47f7-a3e7-b1af49c11478"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at snunlp/KR-ELECTRA-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at snunlp/KR-ELECTRA-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_checkpoint, label2id=label2id, id2label=id2label, num_labels=num_labels\n",")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2786,"status":"ok","timestamp":1666258953645,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"9yKjNjuraamB"},"outputs":[],"source":["train_path = './dataset/uncleaned_v1/raw_train.csv'\n","dev_path = './dataset/uncleaned_v1/raw_dev.csv'\n","test_path = './dataset/uncleaned_v1/raw_test.csv'\n","train = pd.read_csv(train_path)\n","dev = pd.read_csv(dev_path)\n","test = pd.read_csv(test_path)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2252,"status":"ok","timestamp":1666258955885,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"jRpAE71Baeiv"},"outputs":[],"source":["### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","]\n","\n","\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","emojis = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form], ignore_index=True, verify_integrity=True).to_frame()\n","emojis = list(set(demoji.findall(' '.join(emojis.sentence_form.to_list())).keys()))\n","\n","tokensToAdd = more_tokens + emojis\n","ep_labels = pd.Series(entity_property_pair, name='sentence_form', copy=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1666258955886,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"rYqvBLopai9d","outputId":"1c5c4599-9617-48d2-d6f8-a768ef3d130e"},"outputs":[{"name":"stdout","output_type":"stream","text":["7920\n","7915\n"]}],"source":["data = pd.concat([train.sentence_form, dev.sentence_form, test.sentence_form], ignore_index=True, verify_integrity=True).to_frame()\n","print(len(data))\n","data = data.drop_duplicates()\n","print(len(data.drop_duplicates()))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1584,"status":"ok","timestamp":1666258957461,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"JZ_A1Zq1aRAj","outputId":"08b8d3c7-5440-493b-c222-94ae126523f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["30000\n","\n","\n","\n","3060\n","30117\n"]},{"data":{"text/plain":["Embedding(30117, 768)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","print(len(tokenizer))\n","\n","tokenizerTrainData = data.sentence_form.to_list()\n","newTokenizer = tokenizer.train_new_from_iterator(tokenizerTrainData, vocab_size=1)\n","\n","new_tokens = set(list(newTokenizer.vocab.keys())) - set(tokenizer.vocab.keys())\n","tokenizer.add_tokens(list(new_tokens) + tokensToAdd)\n","print(len(newTokenizer))\n","print(len(tokenizer))\n","\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(76,\n"," {'##ɢ',\n","  '##ɪ',\n","  '##ɴ',\n","  '##ʀ',\n","  '##ˇ',\n","  '##ᴍ',\n","  '##ᴘ',\n","  '##ᴛ',\n","  '##ᴜ',\n","  '##ᴠ',\n","  '##ᴡ',\n","  '##ᵕ',\n","  '##◍',\n","  '##❔',\n","  '##➕',\n","  '##㉦',\n","  '##ꈍ',\n","  '##뜌',\n","  '##읒',\n","  '##죱',\n","  '##쨕',\n","  '##쫜',\n","  '##👠',\n","  '##💄',\n","  '##💆',\n","  '##💇',\n","  '##🕷',\n","  '##🕸',\n","  '##🚗',\n","  '##🤡',\n","  '##🥤',\n","  'ɢ',\n","  'ɪ',\n","  'ɴ',\n","  'ʀ',\n","  'ʜ',\n","  'ˇ',\n","  'ғ',\n","  'ᴍ',\n","  'ᴘ',\n","  'ᴛ',\n","  'ᴜ',\n","  'ᴠ',\n","  'ᴡ',\n","  'ᵕ',\n","  '⏰',\n","  '◍',\n","  '❔',\n","  '➕',\n","  '㉦',\n","  'ꈍ',\n","  '뜌',\n","  '뿤',\n","  '쓩',\n","  '읒',\n","  '죱',\n","  '쨕',\n","  '쫜',\n","  '챳',\n","  '🍷',\n","  '🍼',\n","  '🐄',\n","  '👠',\n","  '💄',\n","  '💆',\n","  '💇',\n","  '💡',\n","  '💬',\n","  '🕷',\n","  '🕸',\n","  '🕺',\n","  '😯',\n","  '😺',\n","  '🚗',\n","  '🤡',\n","  '🥤'})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["len(new_tokens), new_tokens"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666258957461,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"fPhUW964vTzH","outputId":"eebfdfdb-9e05-4509-fac0-450ca0a24c31"},"outputs":[{"data":{"text/plain":["({'True': 0, 'False': 1}, {0: 'True', 1: 'False'}, 2)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model.config.label2id, model.config.id2label, model.num_labels"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666258957462,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"EbnV6ZS_xp3Z","outputId":"127c6ce6-2bb3-4b42-cd0a-3ccdcb581e6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] 본품 # 가격 # positive [SEP]\n","[CLS] 본품 # 가격 # negative [SEP]\n","[CLS] 본품 # 가격 # neutral [SEP]\n","[CLS] 본품 # 다양성 # positive [SEP]\n","[CLS] 본품 # 다양성 # negative [SEP]\n","[CLS] 본품 # 다양성 # neutral [SEP]\n","[CLS] 본품 # 디자인 # positive [SEP]\n","[CLS] 본품 # 디자인 # negative [SEP]\n","[CLS] 본품 # 디자인 # neutral [SEP]\n","[CLS] 본품 # 인지도 # positive [SEP]\n","[CLS] 본품 # 인지도 # negative [SEP]\n","[CLS] 본품 # 인지도 # neutral [SEP]\n","[CLS] 본품 # 일반 # positive [SEP]\n","[CLS] 본품 # 일반 # negative [SEP]\n","[CLS] 본품 # 일반 # neutral [SEP]\n","[CLS] 본품 # 편의성 # positive [SEP]\n","[CLS] 본품 # 편의성 # negative [SEP]\n","[CLS] 본품 # 편의성 # neutral [SEP]\n","[CLS] 본품 # 품질 # positive [SEP]\n","[CLS] 본품 # 품질 # negative [SEP]\n","[CLS] 본품 # 품질 # neutral [SEP]\n","[CLS] 브랜드 # 가격 # positive [SEP]\n","[CLS] 브랜드 # 가격 # negative [SEP]\n","[CLS] 브랜드 # 가격 # neutral [SEP]\n","[CLS] 브랜드 # 디자인 # positive [SEP]\n","[CLS] 브랜드 # 디자인 # negative [SEP]\n","[CLS] 브랜드 # 디자인 # neutral [SEP]\n","[CLS] 브랜드 # 인지도 # positive [SEP]\n","[CLS] 브랜드 # 인지도 # negative [SEP]\n","[CLS] 브랜드 # 인지도 # neutral [SEP]\n","[CLS] 브랜드 # 일반 # positive [SEP]\n","[CLS] 브랜드 # 일반 # negative [SEP]\n","[CLS] 브랜드 # 일반 # neutral [SEP]\n","[CLS] 브랜드 # 품질 # positive [SEP]\n","[CLS] 브랜드 # 품질 # negative [SEP]\n","[CLS] 브랜드 # 품질 # neutral [SEP]\n","[CLS] 제품 전체 # 가격 # positive [SEP]\n","[CLS] 제품 전체 # 가격 # negative [SEP]\n","[CLS] 제품 전체 # 가격 # neutral [SEP]\n","[CLS] 제품 전체 # 다양성 # positive [SEP]\n","[CLS] 제품 전체 # 다양성 # negative [SEP]\n","[CLS] 제품 전체 # 다양성 # neutral [SEP]\n","[CLS] 제품 전체 # 디자인 # positive [SEP]\n","[CLS] 제품 전체 # 디자인 # negative [SEP]\n","[CLS] 제품 전체 # 디자인 # neutral [SEP]\n","[CLS] 제품 전체 # 인지도 # positive [SEP]\n","[CLS] 제품 전체 # 인지도 # negative [SEP]\n","[CLS] 제품 전체 # 인지도 # neutral [SEP]\n","[CLS] 제품 전체 # 일반 # positive [SEP]\n","[CLS] 제품 전체 # 일반 # negative [SEP]\n","[CLS] 제품 전체 # 일반 # neutral [SEP]\n","[CLS] 제품 전체 # 편의성 # positive [SEP]\n","[CLS] 제품 전체 # 편의성 # negative [SEP]\n","[CLS] 제품 전체 # 편의성 # neutral [SEP]\n","[CLS] 제품 전체 # 품질 # positive [SEP]\n","[CLS] 제품 전체 # 품질 # negative [SEP]\n","[CLS] 제품 전체 # 품질 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 가격 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 가격 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 가격 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 다양성 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 다양성 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 다양성 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 디자인 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 디자인 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 디자인 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 일반 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 일반 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 일반 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 편의성 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 편의성 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 편의성 # neutral [SEP]\n","[CLS] 패키지 / 구성품 # 품질 # positive [SEP]\n","[CLS] 패키지 / 구성품 # 품질 # negative [SEP]\n","[CLS] 패키지 / 구성품 # 품질 # neutral [SEP]\n","[2, 25777, 7, 8388, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 8388, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 8388, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 8645, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 8645, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 8645, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 8593, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 8593, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 8593, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 18053, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 18053, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 18053, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 8680, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 8680, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 8680, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 10389, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 10389, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 10389, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 25777, 7, 9183, 7, 84, 13635, 10263, 18249, 3]\n","[2, 25777, 7, 9183, 7, 82, 17986, 9781, 18249, 3]\n","[2, 25777, 7, 9183, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 9091, 7, 8388, 7, 84, 13635, 10263, 18249, 3]\n","[2, 9091, 7, 8388, 7, 82, 17986, 9781, 18249, 3]\n","[2, 9091, 7, 8388, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 9091, 7, 8593, 7, 84, 13635, 10263, 18249, 3]\n","[2, 9091, 7, 8593, 7, 82, 17986, 9781, 18249, 3]\n","[2, 9091, 7, 8593, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 9091, 7, 18053, 7, 84, 13635, 10263, 18249, 3]\n","[2, 9091, 7, 18053, 7, 82, 17986, 9781, 18249, 3]\n","[2, 9091, 7, 18053, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 9091, 7, 8680, 7, 84, 13635, 10263, 18249, 3]\n","[2, 9091, 7, 8680, 7, 82, 17986, 9781, 18249, 3]\n","[2, 9091, 7, 8680, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 9091, 7, 9183, 7, 84, 13635, 10263, 18249, 3]\n","[2, 9091, 7, 9183, 7, 82, 17986, 9781, 18249, 3]\n","[2, 9091, 7, 9183, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 8388, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 8388, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 8388, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 8645, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 8645, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 8645, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 8593, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 8593, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 8593, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 18053, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 18053, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 18053, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 8680, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 8680, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 8680, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 10389, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 10389, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 10389, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 8392, 8737, 7, 9183, 7, 84, 13635, 10263, 18249, 3]\n","[2, 8392, 8737, 7, 9183, 7, 82, 17986, 9781, 18249, 3]\n","[2, 8392, 8737, 7, 9183, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8388, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8388, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8388, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8645, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8645, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8645, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8593, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8593, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8593, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8680, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8680, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 8680, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 10389, 5117, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 10389, 5117, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 10389, 5117, 7, 82, 5006, 12874, 14138, 5007, 3]\n","[2, 13633, 19, 8755, 5044, 7, 9183, 7, 84, 13635, 10263, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 9183, 7, 82, 17986, 9781, 18249, 3]\n","[2, 13633, 19, 8755, 5044, 7, 9183, 7, 82, 5006, 12874, 14138, 5007, 3]\n"]}],"source":["# entity_property_pair = [\n","#     '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","#     '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","#     '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","#     '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","# ]\n","\n","# polarity_id_to_name = ['positive', 'negative', 'neutral']\n","\n","# tokenizer_tester = []\n","# for pair in entity_property_pair:\n","#     for polarity in polarity_id_to_name:\n","#         tokenizer_tester.append('#'.join([pair, polarity]))\n","\n","# for e in tokenizer_tester:\n","#     print(tokenizer.decode(tokenizer.encode(e)))\n","\n","# for e in tokenizer_tester:\n","#     print(tokenizer.encode(e))"]},{"cell_type":"markdown","metadata":{"id":"V-EVcOAQ18dS"},"source":["# Define Metric"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["9a01945a9afe49a18a98c35b4cb99c8a","f4a78200b20640f4928944c489daf7a7","0032f06143bf468e90701a0ee56c9df1","2a92b6399a3b4cfea7afcbe89ea6c1c8","275c1bc29ce0431c919d30b0c4de4beb","767206f5d9e04d099a2706442df3e2ca","81ea513d9bbb4dffb926f175947642e9","dc3f367d749440b1acd2f8cefe848c4e","4cc2f55692264694a43389cc5385db8a","b094395b8da34ff8a9c33fcded16377f","1de70d714b014ec4bc1fa226ba66b64f","76629b189eb648d3bc7ba0711e57bc66","8d44dca2d0a24fb38dabcf4bd388323f","89c0ae7377644daa8688ec9ede9f035a","ae3f51735615420bbc92ad5dfb590263","9714e67513334f8e868607422f7da2b9","9237d2a901984102a5deb1c2528f1e10","e9ef7c82807847eb8ff43b3f0303b7d5","41e5cd9c231a46b5bfd8262b2b745cc6","6dcdbf9f62004f9fb3141b1ca5dfddf0","82ebe2dd5a624c418fdfe9dbc021d18d","6ef978f43b214c58abfdf1155f475684"]},"executionInfo":{"elapsed":1037,"status":"ok","timestamp":1666258958492,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"qtEXOy22Gz8l","outputId":"ec55c208-3acd-457e-f052-32644f1ffe7a"},"outputs":[],"source":["accuracy_metric = evaluate.load('accuracy')\n","f1_metric = evaluate.load('f1')"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1666258958492,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"1d61JHiLEadB"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    \n","    accuracy = accuracy_metric.compute(references=labels, predictions=predictions)['accuracy']\n","    f1_true, f1_false = tuple(f1_metric.compute(references=labels, predictions=predictions, average=None, labels=[0,1])['f1'])\n","    f1_macro = f1_metric.compute(references=labels, predictions=predictions, average='macro')['f1']\n","    f1_micro = f1_metric.compute(references=labels, predictions=predictions, average='micro')['f1']\n","    \n","    return {'accuracy': accuracy, 'f1_true': f1_true, 'f1_false': f1_false, 'f1_macro': f1_macro, 'f1_micro': f1_micro}"]},{"cell_type":"markdown","metadata":{"id":"EBp5WFGR2JRb"},"source":["# Load Data"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1666258958493,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"ryHwmgr7B3Ze"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples[\"sentence_form\"], examples[\"entity_property\"], truncation=True)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["e91015e3fd4e4c48930293c31958c06b","03a85f47681c41cdab9d75beee0fb78a","04fe7e54680749478e8daec82decd3ee","f76847602c9e4f8ba5141ccf966a8918","c3f6df857dac4350a4c43b98e5b61e43","5c02b9951c1946279cb36c6c8a4a50f4","fbe16032b1b54aab84d7f1c3caf83201","7d10259a18d54648a6c670a6722e82b5","505a1235079e40cda60009ba1bcf31fe","d4b8a3d633a346e1ad913a3f39ff7332","df47dce258854a2cbfde89bd1b4333a3","6d5bfc1c2ad541e38ef71c3b70faa6aa","b46847cc57cb4d1686abedd7729f2276","eefa541e2bce44f48d5d57921a5105a9","6a576fba1fb14f2fab2cae599e01c9cb","4652216b070746baa42a73d1dd6cec47","d31b16ab5eeb4d3c8d842ec0a739524b","0ad2f8531b5d4ab28f8cd8f9003f7f56","7c9acc1b41de46debb3a27a4af31f6c1","c7cce1948cf14099b8b760cf64db0733","d70edc08493c42bba3d66945ad4da9ac","f472a293ade641c9bff11ee3905e34ee"]},"executionInfo":{"elapsed":15291,"status":"ok","timestamp":1666258973779,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"lM9mxmKb2Nah","outputId":"c048ff0a-1067-4143-88fb-a765c79f3cbc"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 9588/9588 [00:02<00:00, 3430.81ex/s]\n","100%|██████████| 9006/9006 [00:02<00:00, 3487.48ex/s]\n"]}],"source":["train_dataset = pd.read_csv(TRAIN_DATA_PATH)\n","eval_dataset = pd.read_csv(EVAL_DATA_PATH)\n","# train_dataset = pd.concat([train_dataset, eval_dataset])\n","train_dataset = datasets.Dataset.from_pandas(train_dataset) #.shuffle(seed=42)\n","eval_dataset = datasets.Dataset.from_pandas(eval_dataset) #.shuffle(seed=42)\n","train_dataset = train_dataset.map(preprocess_function, batched=False)\n","eval_dataset = eval_dataset.map(preprocess_function, batched=False)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1666258973781,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"YUaaH_gi7UFe","outputId":"a481e242-25ea-461f-b54e-3c6372ae7421"},"outputs":[{"data":{"text/plain":["(9588, 9006)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset), len(eval_dataset)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1666258973782,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"AW4V6ZVKdMRP","outputId":"9a4ad945-bfaa-49d1-93db-3a62b359a6a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] < < 물광피부 만들어주네요 > > [SEP] 상품평 문장의 범주 유형이 < < 본품 # 품질 > > 일 때 감성 유형은 < < neutral > > 이다. [SEP] 1\n","[CLS] < < 흔한 블랙 # 자켓 이 아닌 겨울엔 이너처럼 입고 좋은곳이나 # 하객룩으로도 딱 좋을 느낌 > > [SEP] 상품평 문장의 범주 유형이 < < 제품 전체 # 일반 > > 일 때 감성 유형은 < < negative > > 이다. [SEP] 1\n"]}],"source":["k = random.randrange(len(train_dataset))\n","print(tokenizer.decode(train_dataset['input_ids'][k]), train_dataset['labels'][k])\n","k = random.randrange(len(eval_dataset))\n","print(tokenizer.decode(eval_dataset['input_ids'][k]), eval_dataset['labels'][k])"]},{"cell_type":"markdown","metadata":{"id":"admrPVvW1_Q_"},"source":["# Load Trainer"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666258973782,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"B0b4moolsNWK"},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir=run_name,\n","    run_name=run_name,\n","    report_to=report_to,\n","\n","    num_train_epochs=num_train_epochs,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","\n","    optim=optim,\n","\n","    learning_rate=learning_rate,\n","    weight_decay=weight_decay,\n","    adam_epsilon=adam_epsilon,\n","\n","    lr_scheduler_type=lr_scheduler_type,\n","    warmup_ratio=warmup_ratio,\n","\n","    save_total_limit=save_total_limit,\n","\n","    load_best_model_at_end=load_best_model_at_end,\n","    metric_for_best_model=metric_for_best_model,\n","    \n","    save_strategy=save_strategy,\n","    evaluation_strategy=evaluation_strategy,\n","\n","    logging_strategy=logging_strategy,\n","    logging_first_step=logging_first_step, \n","    logging_steps=logging_steps,\n","    \n","    fp16=fp16,\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1666258973782,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"w1aRCCDR9kVb"},"outputs":[],"source":["# es = EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":4423,"status":"ok","timestamp":1666258978191,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"pwe87xkaMEK6"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    data_collator=data_collator,\n","    # callbacks=[es],\n",")"]},{"cell_type":"markdown","metadata":{"id":"9KNsbWs72BoC"},"source":["# Run Trainer"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"id":"tyN8PA8tMFsU","outputId":"43105a1e-799b-4e6f-f03b-713148df5ce7"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 9588\n","  Num Epochs = 30\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2250\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/ubuntu/jongmin/Jeonghyeon/codes/absa/asc_binary/wandb/run-20221021_020436-qubkrl6j</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_binary/runs/qubkrl6j\" target=\"_blank\">snunlp_kr_electra_discriminator_cleaned_v1</a></strong> to <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_binary\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2250/2250 47:12, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 True</th>\n","      <th>F1 False</th>\n","      <th>F1 Macro</th>\n","      <th>F1 Micro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.689800</td>\n","      <td>0.080120</td>\n","      <td>0.981790</td>\n","      <td>0.972685</td>\n","      <td>0.986342</td>\n","      <td>0.979514</td>\n","      <td>0.981790</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.689800</td>\n","      <td>0.064090</td>\n","      <td>0.983455</td>\n","      <td>0.974886</td>\n","      <td>0.987665</td>\n","      <td>0.981275</td>\n","      <td>0.983455</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.689800</td>\n","      <td>0.064678</td>\n","      <td>0.981790</td>\n","      <td>0.972232</td>\n","      <td>0.986453</td>\n","      <td>0.979342</td>\n","      <td>0.981790</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.689800</td>\n","      <td>0.068252</td>\n","      <td>0.982345</td>\n","      <td>0.973282</td>\n","      <td>0.986817</td>\n","      <td>0.980049</td>\n","      <td>0.982345</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.689800</td>\n","      <td>0.075387</td>\n","      <td>0.981013</td>\n","      <td>0.971590</td>\n","      <td>0.985742</td>\n","      <td>0.978666</td>\n","      <td>0.981013</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.689800</td>\n","      <td>0.086813</td>\n","      <td>0.981790</td>\n","      <td>0.972639</td>\n","      <td>0.986354</td>\n","      <td>0.979497</td>\n","      <td>0.981790</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.078500</td>\n","      <td>0.089193</td>\n","      <td>0.980791</td>\n","      <td>0.971171</td>\n","      <td>0.985597</td>\n","      <td>0.978384</td>\n","      <td>0.980791</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.078500</td>\n","      <td>0.089659</td>\n","      <td>0.971686</td>\n","      <td>0.957507</td>\n","      <td>0.978769</td>\n","      <td>0.968138</td>\n","      <td>0.971686</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.078500</td>\n","      <td>0.106145</td>\n","      <td>0.980902</td>\n","      <td>0.971266</td>\n","      <td>0.985698</td>\n","      <td>0.978482</td>\n","      <td>0.980902</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.078500</td>\n","      <td>0.103083</td>\n","      <td>0.981457</td>\n","      <td>0.972236</td>\n","      <td>0.986080</td>\n","      <td>0.979158</td>\n","      <td>0.981457</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.078500</td>\n","      <td>0.118511</td>\n","      <td>0.981457</td>\n","      <td>0.972143</td>\n","      <td>0.986103</td>\n","      <td>0.979123</td>\n","      <td>0.981457</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.078500</td>\n","      <td>0.120776</td>\n","      <td>0.980902</td>\n","      <td>0.971324</td>\n","      <td>0.985683</td>\n","      <td>0.978504</td>\n","      <td>0.980902</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.078500</td>\n","      <td>0.103901</td>\n","      <td>0.981679</td>\n","      <td>0.972486</td>\n","      <td>0.986267</td>\n","      <td>0.979377</td>\n","      <td>0.981679</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.012600</td>\n","      <td>0.135780</td>\n","      <td>0.982789</td>\n","      <td>0.974205</td>\n","      <td>0.987087</td>\n","      <td>0.980646</td>\n","      <td>0.982789</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.012600</td>\n","      <td>0.145036</td>\n","      <td>0.975239</td>\n","      <td>0.962765</td>\n","      <td>0.981452</td>\n","      <td>0.972109</td>\n","      <td>0.975239</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.012600</td>\n","      <td>0.124927</td>\n","      <td>0.982123</td>\n","      <td>0.973099</td>\n","      <td>0.986613</td>\n","      <td>0.979856</td>\n","      <td>0.982123</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.012600</td>\n","      <td>0.127784</td>\n","      <td>0.982234</td>\n","      <td>0.973280</td>\n","      <td>0.986693</td>\n","      <td>0.979987</td>\n","      <td>0.982234</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.012600</td>\n","      <td>0.129047</td>\n","      <td>0.980902</td>\n","      <td>0.971314</td>\n","      <td>0.985686</td>\n","      <td>0.978500</td>\n","      <td>0.980902</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.012600</td>\n","      <td>0.130665</td>\n","      <td>0.982345</td>\n","      <td>0.973496</td>\n","      <td>0.986764</td>\n","      <td>0.980130</td>\n","      <td>0.982345</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.001500</td>\n","      <td>0.132028</td>\n","      <td>0.982345</td>\n","      <td>0.973487</td>\n","      <td>0.986767</td>\n","      <td>0.980127</td>\n","      <td>0.982345</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.001500</td>\n","      <td>0.133371</td>\n","      <td>0.982567</td>\n","      <td>0.973812</td>\n","      <td>0.986935</td>\n","      <td>0.980373</td>\n","      <td>0.982567</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.001500</td>\n","      <td>0.134377</td>\n","      <td>0.982456</td>\n","      <td>0.973658</td>\n","      <td>0.986849</td>\n","      <td>0.980253</td>\n","      <td>0.982456</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.001500</td>\n","      <td>0.135694</td>\n","      <td>0.982456</td>\n","      <td>0.973640</td>\n","      <td>0.986853</td>\n","      <td>0.980247</td>\n","      <td>0.982456</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.001500</td>\n","      <td>0.135793</td>\n","      <td>0.982567</td>\n","      <td>0.973820</td>\n","      <td>0.986933</td>\n","      <td>0.980377</td>\n","      <td>0.982567</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.001500</td>\n","      <td>0.136183</td>\n","      <td>0.982567</td>\n","      <td>0.973812</td>\n","      <td>0.986935</td>\n","      <td>0.980373</td>\n","      <td>0.982567</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.001500</td>\n","      <td>0.136573</td>\n","      <td>0.982678</td>\n","      <td>0.973983</td>\n","      <td>0.987017</td>\n","      <td>0.980500</td>\n","      <td>0.982678</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.000800</td>\n","      <td>0.136967</td>\n","      <td>0.982456</td>\n","      <td>0.973649</td>\n","      <td>0.986851</td>\n","      <td>0.980250</td>\n","      <td>0.982456</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.000800</td>\n","      <td>0.137083</td>\n","      <td>0.982456</td>\n","      <td>0.973649</td>\n","      <td>0.986851</td>\n","      <td>0.980250</td>\n","      <td>0.982456</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.000800</td>\n","      <td>0.137140</td>\n","      <td>0.982567</td>\n","      <td>0.973820</td>\n","      <td>0.986933</td>\n","      <td>0.980377</td>\n","      <td>0.982567</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.000800</td>\n","      <td>0.137146</td>\n","      <td>0.982567</td>\n","      <td>0.973820</td>\n","      <td>0.986933</td>\n","      <td>0.980377</td>\n","      <td>0.982567</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75/special_tokens_map.json\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150/special_tokens_map.json\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-75] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-225] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-300] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-375] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-450] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-525] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-600] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-675] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-750] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-825] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","wandb: Network error (ReadTimeout), entering retry loop.\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-900] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-975] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1050] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1125] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1200] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1275] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1350] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1425] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1500] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1575] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1650] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1725] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1800] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1875] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-1950] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2025] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2100] due to args.save_total_limit\n","/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","The following columns in the evaluation set don't have a corresponding argument in `ElectraForSequenceClassification.forward` and have been ignored: sentence_form, id, entity_property. If sentence_form, id, entity_property are not expected by `ElectraForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9006\n","  Batch size = 128\n","Saving model checkpoint to snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2250\n","Configuration saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2250/config.json\n","Model weights saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2250/pytorch_model.bin\n","tokenizer config file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2250/tokenizer_config.json\n","Special tokens file saved in snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2250/special_tokens_map.json\n","Deleting older checkpoint [snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-2175] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from snunlp_kr_electra_discriminator_cleaned_v1/checkpoint-150 (score: 0.9812753856650805).\n","Saving model checkpoint to /tmp/tmp8xcqm2sl\n","Configuration saved in /tmp/tmp8xcqm2sl/config.json\n","Model weights saved in /tmp/tmp8xcqm2sl/pytorch_model.bin\n","tokenizer config file saved in /tmp/tmp8xcqm2sl/tokenizer_config.json\n","Special tokens file saved in /tmp/tmp8xcqm2sl/special_tokens_map.json\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇█▇▇▇▇▆▁▆▇▇▆▇█▃▇▇▆▇▇▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>eval/f1_false</td><td>▇█▇▇▆▇▆▁▆▇▇▆▇█▃▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>eval/f1_macro</td><td>▇█▇▇▇▇▆▁▇▇▇▇▇█▃▇▇▇▇▇█▇▇███▇▇██</td></tr><tr><td>eval/f1_micro</td><td>▇█▇▇▇▇▆▁▆▇▇▆▇█▃▇▇▆▇▇▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>eval/f1_true</td><td>▇█▇▇▇▇▇▁▇▇▇▇▇█▃▇▇▇▇▇██▇███████</td></tr><tr><td>eval/loss</td><td>▂▁▁▁▂▃▃▃▅▄▆▆▄▇█▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>eval/runtime</td><td>▃▃▇▁▂▃▄█▄▃▆▄▆▄▃▄▃█▃▄▅▃▂▃▄▃▅▃▄▅</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▂█▇▆▄▁▄▆▃▅▃▅▆▅▆▁▆▅▄▆▇▆▅▆▄▆▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▂█▇▆▄▁▄▆▃▅▃▅▆▅▆▁▆▅▄▆▇▆▅▆▄▆▅▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>█▇▅▃▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98257</td></tr><tr><td>eval/f1_false</td><td>0.98693</td></tr><tr><td>eval/f1_macro</td><td>0.98038</td></tr><tr><td>eval/f1_micro</td><td>0.98257</td></tr><tr><td>eval/f1_true</td><td>0.97382</td></tr><tr><td>eval/loss</td><td>0.13715</td></tr><tr><td>eval/runtime</td><td>29.3049</td></tr><tr><td>eval/samples_per_second</td><td>307.32</td></tr><tr><td>eval/steps_per_second</td><td>2.423</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>2250</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0008</td></tr><tr><td>train/total_flos</td><td>1.043591356649184e+16</td></tr><tr><td>train/train_loss</td><td>0.02107</td></tr><tr><td>train/train_runtime</td><td>2837.2329</td></tr><tr><td>train/train_samples_per_second</td><td>101.38</td></tr><tr><td>train/train_steps_per_second</td><td>0.793</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">snunlp_kr_electra_discriminator_cleaned_v1</strong>: <a href=\"https://wandb.ai/dotsnangles/aspect_sentiment_classification_binary/runs/qubkrl6j\" target=\"_blank\">https://wandb.ai/dotsnangles/aspect_sentiment_classification_binary/runs/qubkrl6j</a><br/>Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20221021_020436-qubkrl6j/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()\n","wandb.finish()"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"njKzTZtir0SC"},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["keep = [\n","    'added_tokens.json',\n","    'config.json',\n","    'pytorch_model.bin',\n","    'special_tokens_map.json',\n","    'tokenizer.json',\n","    'tokenizer_config.json',\n","    'vocab.txt'\n","]\n","\n","ckpts = os.listdir(run_name)\n","for ckpt in ckpts:\n","    ckpt = os.path.join(run_name, ckpt)\n","    for item in os.listdir(ckpt):\n","        if item not in keep:\n","            os.remove(os.path.join(ckpt, item))\n","\n","!mv wandb {run_name} {SAVE_PATH}/"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0032f06143bf468e90701a0ee56c9df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc3f367d749440b1acd2f8cefe848c4e","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cc2f55692264694a43389cc5385db8a","value":4203}},"03a85f47681c41cdab9d75beee0fb78a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c02b9951c1946279cb36c6c8a4a50f4","placeholder":"​","style":"IPY_MODEL_fbe16032b1b54aab84d7f1c3caf83201","value":"100%"}},"04fe7e54680749478e8daec82decd3ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d10259a18d54648a6c670a6722e82b5","max":27321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_505a1235079e40cda60009ba1bcf31fe","value":27321}},"0642dca8ab984c91a4539585afef8390":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad20f3a0ca6c42c6afc1f506046ebf3b","placeholder":"​","style":"IPY_MODEL_fe51a8730e28454d897439830382db46","value":"Downloading: 100%"}},"0ad2f8531b5d4ab28f8cd8f9003f7f56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c4bff269e8f4d9693aec278a0a8d52a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9890392cc707490d88aa6fe155917a09","placeholder":"​","style":"IPY_MODEL_f62340167e2d447096a2965b4fc60826","value":" 56.0/56.0 [00:00&lt;00:00, 1.44kB/s]"}},"110c5f6649ab4b3382cce9d0bfcca25b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d07530c6d494b4bb5d9579e0da3c820":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1de70d714b014ec4bc1fa226ba66b64f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"275c1bc29ce0431c919d30b0c4de4beb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a92b6399a3b4cfea7afcbe89ea6c1c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b094395b8da34ff8a9c33fcded16377f","placeholder":"​","style":"IPY_MODEL_1de70d714b014ec4bc1fa226ba66b64f","value":" 4.20k/4.20k [00:00&lt;00:00, 114kB/s]"}},"2e99b266d32549aa80f6234d807ff8bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"41e5cd9c231a46b5bfd8262b2b745cc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44649a89dc5d4156892db45e1fdee5c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45efd1e29eb445d0bbdb4d0e90dec407":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4652216b070746baa42a73d1dd6cec47":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cc2f55692264694a43389cc5385db8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d894cca56034a818c9132a012504061":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505a1235079e40cda60009ba1bcf31fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b3593cbcc844e928f086f80d9108ba1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c02b9951c1946279cb36c6c8a4a50f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb0cdb0332f49caa2c9e728078da80a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"658511cf252648a0ae4dd509bbe12fe6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"684011384bc34d2692f71dfe935b4723":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a576fba1fb14f2fab2cae599e01c9cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d70edc08493c42bba3d66945ad4da9ac","placeholder":"​","style":"IPY_MODEL_f472a293ade641c9bff11ee3905e34ee","value":" 9006/9006 [00:03&lt;00:00, 2723.19ex/s]"}},"6acc835b544d451894d35e3736e0d804":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d5bfc1c2ad541e38ef71c3b70faa6aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b46847cc57cb4d1686abedd7729f2276","IPY_MODEL_eefa541e2bce44f48d5d57921a5105a9","IPY_MODEL_6a576fba1fb14f2fab2cae599e01c9cb"],"layout":"IPY_MODEL_4652216b070746baa42a73d1dd6cec47"}},"6dcdbf9f62004f9fb3141b1ca5dfddf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ef978f43b214c58abfdf1155f475684":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76629b189eb648d3bc7ba0711e57bc66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d44dca2d0a24fb38dabcf4bd388323f","IPY_MODEL_89c0ae7377644daa8688ec9ede9f035a","IPY_MODEL_ae3f51735615420bbc92ad5dfb590263"],"layout":"IPY_MODEL_9714e67513334f8e868607422f7da2b9"}},"767206f5d9e04d099a2706442df3e2ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3552d804164201a11b0d9a7a6d9b10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c9acc1b41de46debb3a27a4af31f6c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d10259a18d54648a6c670a6722e82b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ea513d9bbb4dffb926f175947642e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82ebe2dd5a624c418fdfe9dbc021d18d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83be86e7a1bc4cb5ad983f549588cec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0642dca8ab984c91a4539585afef8390","IPY_MODEL_92f849d5359340cc89bce483f9d15bfe","IPY_MODEL_a6d4a8cf193d4d4486b72f41e7ec7fa5"],"layout":"IPY_MODEL_bab12b33f3b0477c9a9c9fb02aa288db"}},"86c9f350fe5f491e966c968f09428b2f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c0ae7377644daa8688ec9ede9f035a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41e5cd9c231a46b5bfd8262b2b745cc6","max":6771,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dcdbf9f62004f9fb3141b1ca5dfddf0","value":6771}},"8d44dca2d0a24fb38dabcf4bd388323f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9237d2a901984102a5deb1c2528f1e10","placeholder":"​","style":"IPY_MODEL_e9ef7c82807847eb8ff43b3f0303b7d5","value":"Downloading builder script: 100%"}},"90465c6d97ef4e83b86160ce1e66ca8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_110c5f6649ab4b3382cce9d0bfcca25b","max":436416329,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e99b266d32549aa80f6234d807ff8bb","value":436416329}},"9237d2a901984102a5deb1c2528f1e10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92f849d5359340cc89bce483f9d15bfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_684011384bc34d2692f71dfe935b4723","max":468,"min":0,"orientation":"horizontal","style":"IPY_MODEL_44649a89dc5d4156892db45e1fdee5c1","value":468}},"9355394179624ce3be82e1b294b1a2b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e01a20c18d8249cea389638d8c005b8d","placeholder":"​","style":"IPY_MODEL_6acc835b544d451894d35e3736e0d804","value":"Downloading: 100%"}},"9714e67513334f8e868607422f7da2b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9890392cc707490d88aa6fe155917a09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a01945a9afe49a18a98c35b4cb99c8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4a78200b20640f4928944c489daf7a7","IPY_MODEL_0032f06143bf468e90701a0ee56c9df1","IPY_MODEL_2a92b6399a3b4cfea7afcbe89ea6c1c8"],"layout":"IPY_MODEL_275c1bc29ce0431c919d30b0c4de4beb"}},"a143eeb39a3a4f34be3eea3253d8b3f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8e8e78b21d6416f858f4f7352059bc0","placeholder":"​","style":"IPY_MODEL_7c3552d804164201a11b0d9a7a6d9b10","value":"Downloading: 100%"}},"a6d4a8cf193d4d4486b72f41e7ec7fa5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b3593cbcc844e928f086f80d9108ba1","placeholder":"​","style":"IPY_MODEL_a7c890f084ac432b9facfa6a397f6295","value":" 468/468 [00:00&lt;00:00, 5.00kB/s]"}},"a7c890f084ac432b9facfa6a397f6295":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8e8e78b21d6416f858f4f7352059bc0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad20f3a0ca6c42c6afc1f506046ebf3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae3f51735615420bbc92ad5dfb590263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82ebe2dd5a624c418fdfe9dbc021d18d","placeholder":"​","style":"IPY_MODEL_6ef978f43b214c58abfdf1155f475684","value":" 6.77k/6.77k [00:00&lt;00:00, 231kB/s]"}},"b094395b8da34ff8a9c33fcded16377f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b46847cc57cb4d1686abedd7729f2276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d31b16ab5eeb4d3c8d842ec0a739524b","placeholder":"​","style":"IPY_MODEL_0ad2f8531b5d4ab28f8cd8f9003f7f56","value":"100%"}},"ba30ea7b361c4105966ff21c1d8a8695":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bab12b33f3b0477c9a9c9fb02aa288db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb83f39eb9b74852b14cc8317cacf616":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45efd1e29eb445d0bbdb4d0e90dec407","placeholder":"​","style":"IPY_MODEL_dff996c84db24f52bef3d54528588226","value":" 436M/436M [00:17&lt;00:00, 38.8MB/s]"}},"bc621d540c4f48c88ef6758cc902f652":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf7dac5b27584f288107f28e482be51d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9355394179624ce3be82e1b294b1a2b5","IPY_MODEL_e3db079ea80048359f6097228cdc8086","IPY_MODEL_0c4bff269e8f4d9693aec278a0a8d52a"],"layout":"IPY_MODEL_c30f1c569f584efdb38e04fd4d5f838a"}},"c2924cb5fd6642d5aa134b63aaa01dca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efd3eea3194c47d28ce4981dceb04f54","max":213726,"min":0,"orientation":"horizontal","style":"IPY_MODEL_658511cf252648a0ae4dd509bbe12fe6","value":213726}},"c30f1c569f584efdb38e04fd4d5f838a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3f6df857dac4350a4c43b98e5b61e43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5ed91471a484c8da8249e731a16f343":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7cce1948cf14099b8b760cf64db0733":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9b0e46751fb474ab454ba3eddd8dbd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e188d96fbcc54a35838b1356cf7a8797","IPY_MODEL_90465c6d97ef4e83b86160ce1e66ca8b","IPY_MODEL_bb83f39eb9b74852b14cc8317cacf616"],"layout":"IPY_MODEL_86c9f350fe5f491e966c968f09428b2f"}},"d31b16ab5eeb4d3c8d842ec0a739524b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4b8a3d633a346e1ad913a3f39ff7332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d70edc08493c42bba3d66945ad4da9ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93d55f032ac46068d03caeb1330b7bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a143eeb39a3a4f34be3eea3253d8b3f2","IPY_MODEL_c2924cb5fd6642d5aa134b63aaa01dca","IPY_MODEL_e615f2d044e143d387a202fcaab64972"],"layout":"IPY_MODEL_4d894cca56034a818c9132a012504061"}},"dc3f367d749440b1acd2f8cefe848c4e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df47dce258854a2cbfde89bd1b4333a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dff996c84db24f52bef3d54528588226":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e01a20c18d8249cea389638d8c005b8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e188d96fbcc54a35838b1356cf7a8797":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba30ea7b361c4105966ff21c1d8a8695","placeholder":"​","style":"IPY_MODEL_f514807a72e64160b487098810593b20","value":"Downloading: 100%"}},"e3db079ea80048359f6097228cdc8086":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5ed91471a484c8da8249e731a16f343","max":56,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc621d540c4f48c88ef6758cc902f652","value":56}},"e615f2d044e143d387a202fcaab64972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb0cdb0332f49caa2c9e728078da80a","placeholder":"​","style":"IPY_MODEL_1d07530c6d494b4bb5d9579e0da3c820","value":" 214k/214k [00:00&lt;00:00, 481kB/s]"}},"e91015e3fd4e4c48930293c31958c06b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03a85f47681c41cdab9d75beee0fb78a","IPY_MODEL_04fe7e54680749478e8daec82decd3ee","IPY_MODEL_f76847602c9e4f8ba5141ccf966a8918"],"layout":"IPY_MODEL_c3f6df857dac4350a4c43b98e5b61e43"}},"e9ef7c82807847eb8ff43b3f0303b7d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eefa541e2bce44f48d5d57921a5105a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9acc1b41de46debb3a27a4af31f6c1","max":9006,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7cce1948cf14099b8b760cf64db0733","value":9006}},"efd3eea3194c47d28ce4981dceb04f54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f472a293ade641c9bff11ee3905e34ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4a78200b20640f4928944c489daf7a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_767206f5d9e04d099a2706442df3e2ca","placeholder":"​","style":"IPY_MODEL_81ea513d9bbb4dffb926f175947642e9","value":"Downloading builder script: 100%"}},"f514807a72e64160b487098810593b20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f62340167e2d447096a2965b4fc60826":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f76847602c9e4f8ba5141ccf966a8918":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4b8a3d633a346e1ad913a3f39ff7332","placeholder":"​","style":"IPY_MODEL_df47dce258854a2cbfde89bd1b4333a3","value":" 27321/27321 [00:10&lt;00:00, 2639.04ex/s]"}},"fbe16032b1b54aab84d7f1c3caf83201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe51a8730e28454d897439830382db46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
