{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1666249058207,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"MbTADoPibruA"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import (\n","    AutoConfig, ElectraTokenizerFast, ElectraForTokenClassification, \n","    DataCollatorForTokenClassification,\n","    TrainingArguments, Trainer,\n",")\n","\n","import re, math, random, json, os\n","from copy import deepcopy\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import Counter\n","\n","from module.preprocess import decorate_form, decorate_acd_pair, decorate_asc_pair, decorate_acd_pair_split, decorate_asc_pair_split\n","from module.utils import count_tags, make_token_classification_pair, remove_props, align_tokens_and_labels, get_filter, generate_token_classification_data, adjust_target\n","import demoji"]},{"cell_type":"markdown","metadata":{},"source":["# Declare Stuff to use"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ov3SPo0UK_2k"},"outputs":[],"source":["### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","\n","]\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/uncleaned_v12\n"]}],"source":["DATA_V = 'uncleaned_v12'\n","save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"markdown","metadata":{},"source":["# ACD and ASC Preprocess"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train = pd.read_json(f'{save_path}/tagger_train.json')\n","dev = pd.read_json(f'{save_path}/tagger_dev.json')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["train = train[['id', 'sentence_form', 'annotation']]\n","dev = dev[['id', 'sentence_form', 'annotation']]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def reformat(df):\n","    tabsa =[]\n","    for index, row in df.iterrows():\n","        utterance = row.sentence_form\n","        id = row.id\n","        form = utterance\n","        # form = decorate_form(utterance)\n","        \n","        trg_ep_sents = {}\n","        for annotation in row.annotation:\n","            ep_and_sent = [annotation[0], annotation[2]]\n","            target = annotation[1][0]\n","            if target not in trg_ep_sents.keys():\n","                trg_ep_sents[target] = []\n","                trg_ep_sents[target].append(ep_and_sent)\n","            else:\n","                trg_ep_sents[target].append(ep_and_sent)\n","\n","        for target in trg_ep_sents.keys():\n","            annotations = trg_ep_sents[target]\n","            for pair in entity_property_pair:\n","                for polarity in polarity_id_to_name:\n","                    isPairInOpinion = False\n","                    if pd.isna(utterance):\n","                        break\n","                    for annotation in annotations:\n","                        entity_property = annotation[0]\n","                        sentiment = annotation[1]\n","                        if entity_property == pair and sentiment == polarity:\n","                            tabsa_pair = '#'.join([target, entity_property, sentiment])\n","                            ep_append = [id, form, tabsa_pair, tf_name_to_id['True']]\n","                            tabsa.append(ep_append)\n","                            isPairInOpinion = True\n","                            break\n","                    if isPairInOpinion is False:\n","                        tabsa_pair = '#'.join([target, pair, polarity])\n","                        ep_append = [id, form, tabsa_pair, tf_name_to_id['False']]\n","                        tabsa.append(ep_append)\n","    return tabsa"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(374100, 92325)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tabsa_train = reformat(train)\n","tabsa_dev = reformat(dev)\n","\n","tabsa_train = pd.DataFrame(tabsa_train, columns=['id', 'form', 'pair', 'labels'])\n","tabsa_dev = pd.DataFrame(tabsa_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","len(tabsa_train), len(tabsa_dev)"]},{"cell_type":"markdown","metadata":{"id":"rjaoyM97e9PQ"},"source":["### Counting"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"GFroeNPQc-DZ","outputId":"bce5e0c2-0423-4db7-982a-23d5b68b8618"},"outputs":[{"name":"stdout","output_type":"stream","text":["before: 374100 92325\n","after: 374100 92325\n"]},{"data":{"text/plain":["(None, None)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["print('before: ', end=''), print(len(tabsa_train), len(tabsa_dev))\n","\n","tabsa_train = tabsa_train.drop_duplicates()\n","tabsa_dev = tabsa_dev.drop_duplicates()\n","\n","print('after: ', end=''), print(len(tabsa_train), len(tabsa_dev))"]},{"cell_type":"markdown","metadata":{},"source":["### Validate Here"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# for idx, row in train.iterrows():\n","#     if len(row.annotation) == 5:\n","#         print(row.id)\n","#         print()\n","#         print(row.sentence_form)\n","#         print()\n","#         for annotation in row.annotation:\n","#             print(annotation)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# df = tabsa_train\n","# for idx, row in df.iterrows():\n","#     if row.id == 'nikluge-sa-2022-train-00174':\n","#         print(row.id, '\\n',\n","#             row.form, '\\n',\n","#             row.pair, '\\n',\n","#             row.labels, '\\n',)"]},{"cell_type":"markdown","metadata":{},"source":["### Save"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/uncleaned_v12\n"]}],"source":["save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["!mkdir -p {save_path}\n","\n","tabsa_train.to_csv(f'{save_path}/tabsa_train.csv', index=False, encoding='utf-8')\n","tabsa_dev.to_csv(f'{save_path}/tabsa_dev.csv', index=False, encoding='utf-8')"]},{"cell_type":"markdown","metadata":{},"source":["### Additional Length Test If Needed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ep_train, ep_dev, p_binary_train, p_binary_dev"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_checkpoint = 'dataset/uncleaned_v11/tokenizer'\n","tokenizer = ElectraTokenizerFast.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tabsa_train, tabsa_dev\n","len_counter = []\n","for df in [tabsa_train, tabsa_dev]:\n","    for idx, row in df.iterrows():\n","        len_counter.append(len(tokenizer(row[\"form\"], row[\"pair\"], truncation=True).input_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max(len_counter)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
