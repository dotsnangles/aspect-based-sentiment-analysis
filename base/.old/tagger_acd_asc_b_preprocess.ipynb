{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1666249058207,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"MbTADoPibruA"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/anaconda3/envs/jeonghyeon/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from transformers import (\n","    AutoConfig, ElectraTokenizerFast, ElectraForTokenClassification, \n","    DataCollatorForTokenClassification,\n","    TrainingArguments, Trainer,\n",")\n","\n","# from torch.nn import CrossEntropyLoss\n","# loss = CrossEntropyLoss()\n","# loss.ignore_index\n","\n","# import nlpaug.augmenter.char as nac\n","# import nlpaug.augmenter.word as naw\n","# import nlpaug.augmenter.sentence as nas\n","# import nlpaug.flow as nafc\n","# from nlpaug.util import Action\n","\n","# from googletrans import Translator\n","# import translators as ts\n","\n","import re, math, random, json, os\n","from copy import deepcopy\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import Counter\n","\n","from module.preprocess import decorate_form, decorate_acd_pair, decorate_asc_pair, decorate_acd_pair_split, decorate_asc_pair_split\n","from module.utils import count_tags, make_token_classification_pair, remove_props, align_tokens_and_labels, get_filter, generate_token_classification_data, adjust_target\n","import demoji\n","\n","# from cleantext import clean\n","# from pykospacing import Spacing\n","# from hanspell import spell_checker"]},{"cell_type":"markdown","metadata":{},"source":["# Declare Stuff to use"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ov3SPo0UK_2k"},"outputs":[],"source":["### new\n","entity_property_pair = [\n","    '본품#가격', '본품#다양성', '본품#디자인', '본품#인지도', '본품#일반', '본품#편의성', '본품#품질',\n","    '브랜드#가격', '브랜드#디자인', '브랜드#인지도', '브랜드#일반', '브랜드#품질',\n","    '제품 전체#가격', '제품 전체#다양성', '제품 전체#디자인', '제품 전체#인지도', '제품 전체#일반', '제품 전체#편의성', '제품 전체#품질',\n","    '패키지/구성품#가격', '패키지/구성품#다양성', '패키지/구성품#디자인', '패키지/구성품#일반', '패키지/구성품#편의성', '패키지/구성품#품질'\n","\n","]\n","more_tokens = ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n","\n","tf_id_to_name = ['True', 'False']\n","tf_name_to_id = {tf_id_to_name[i]: i for i in range(len(tf_id_to_name))}\n","\n","polarity_id_to_name = ['positive', 'negative', 'neutral']\n","polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/uncleaned_v11\n"]}],"source":["DATA_V = 'uncleaned_v11'\n","save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"markdown","metadata":{},"source":["# ACD and ASC Preprocess"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train = pd.read_json(f'{save_path}/tagger_train.json')\n","dev = pd.read_json(f'{save_path}/tagger_dev.json')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["train = train[['id', 'sentence_form', 'annotation']]\n","dev = dev[['id', 'sentence_form', 'annotation']]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def reformat(df):\n","    ep =[]\n","    p = []\n","    for index, row in df.iterrows():\n","        utterance = row.sentence_form\n","        id = row.id\n","        form = utterance\n","        # form = decorate_form(utterance)\n","        \n","        trg_ep_sents = {}\n","        for annotation in row.annotation:\n","            ep_and_sent = [annotation[0], annotation[2]]\n","            target = annotation[1][0]\n","            if target not in trg_ep_sents.keys():\n","                trg_ep_sents[target] = []\n","                trg_ep_sents[target].append(ep_and_sent)\n","            else:\n","                trg_ep_sents[target].append(ep_and_sent)\n","        \n","        for target in trg_ep_sents.keys():\n","            annotations = trg_ep_sents[target]\n","            for pair in entity_property_pair:\n","                isPairInOpinion = False\n","                if pd.isna(utterance):\n","                    break\n","                for annotation in annotations:\n","                    entity_property = annotation[0]\n","                    sentiment = annotation[1]\n","\n","                    if entity_property == pair:\n","                        \n","                        acd_pair = '#'.join([target, entity_property])\n","                        \n","                        ep_append = [id, form, acd_pair, tf_name_to_id['True']]\n","                        ep.append(ep_append)\n","                        p.append([id, utterance, target, entity_property, sentiment])\n","                        isPairInOpinion = True\n","                        break\n","                if isPairInOpinion is False:\n","                    \n","                    acd_pair = '#'.join([target, pair])\n","                    \n","                    ep_append = [id, form, acd_pair, tf_name_to_id['False']]\n","                    ep.append(ep_append)\n","    return ep, p"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def reformat_p_binary(df):\n","    p_binary = []\n","    for i, row in df.iterrows():\n","        row.id, row.form, row.target, row.pair, row.sentiment\n","        \n","        form = row.form\n","        # form = decorate_form(row.form)\n","        \n","        for sentiment in polarity_id_to_name:\n","            if sentiment == row.sentiment:\n","\n","                asc_pair = '#'.join([row.target, row.pair, row.sentiment])\n","                # asc_pair = decorate_asc_pair(row.pair, row.sentiment)\n","                # asc_pair = decorate_asc_pair_split(row.pair, row.sentiment)\n","\n","                p_binary_append = [row.id, form, asc_pair, tf_name_to_id['True']]\n","                p_binary.append(p_binary_append)\n","            else:\n","\n","                asc_pair = '#'.join([row.target, row.pair, sentiment])\n","                # asc_pair = decorate_asc_pair(row.pair, sentiment)\n","                # asc_pair = decorate_asc_pair_split(row.pair, sentiment)\n","\n","                p_binary_append = [row.id, form, asc_pair, tf_name_to_id['False']]\n","                p_binary.append(p_binary_append)\n","    return p_binary"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(124700, 30775, 5073, 1253)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["ep_train, p_train = reformat(train)\n","ep_dev, p_dev = reformat(dev)\n","\n","ep_train = pd.DataFrame(ep_train, columns=['id', 'form', 'pair', 'labels'])\n","ep_dev = pd.DataFrame(ep_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","p_train = pd.DataFrame(p_train, columns=['id', 'form', 'target', 'pair', 'sentiment'])\n","p_dev = pd.DataFrame(p_dev, columns=['id', 'form', 'target', 'pair', 'sentiment'])\n","\n","len(ep_train), len(ep_dev), len(p_train), len(p_dev)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(124700, 30775, 15219, 3759)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["p_binary_train = reformat_p_binary(p_train)\n","p_binary_train = pd.DataFrame(p_binary_train, columns=['id', 'form', 'pair', 'labels'])\n","\n","p_binary_dev = reformat_p_binary(p_dev)\n","p_binary_dev = pd.DataFrame(p_binary_dev, columns=['id', 'form', 'pair', 'labels'])\n","\n","len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev)"]},{"cell_type":"markdown","metadata":{"id":"rjaoyM97e9PQ"},"source":["### Counting"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666184237228,"user":{"displayName":"Jeonghyeon Park","userId":"12513544746873038725"},"user_tz":-540},"id":"GFroeNPQc-DZ","outputId":"bce5e0c2-0423-4db7-982a-23d5b68b8618"},"outputs":[{"name":"stdout","output_type":"stream","text":["binary_multi: 124700 30775 5073 1253\n","binary_binary: 124700 30775 15219 3759\n","\n","after drop_duplicates\n","\n","binary_multi: 124700 30775 5073 1253\n","binary_binary: 124700 30775 15219 3759\n"]},{"data":{"text/plain":["(None, None)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))\n","print('binary_binary: ', end=''), print(len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev))\n","ep_train = ep_train.drop_duplicates()\n","ep_dev = ep_dev.drop_duplicates()\n","p_train = p_train.drop_duplicates()\n","p_dev = p_dev.drop_duplicates()\n","p_binary_train = p_binary_train.drop_duplicates()\n","p_binary_dev = p_binary_dev.drop_duplicates()\n","print('\\nafter drop_duplicates\\n')\n","print('binary_multi: ', end=''), print(len(ep_train), len(ep_dev), len(p_train), len(p_dev))\n","print('binary_binary: ', end=''), print(len(ep_train), len(ep_dev), len(p_binary_train), len(p_binary_dev))"]},{"cell_type":"markdown","metadata":{},"source":["### Validate Here"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nikluge-sa-2022-train-00174\n","\n","Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족..\n","\n","['브랜드#가격', ['토드비', 21, 24], 'positive']\n","['제품 전체#품질', ['토드비', 21, 24], 'positive']\n","['제품 전체#디자인', ['스타일도', 33, 37], 'positive']\n","['본품#일반', ['색상도', 38, 41], 'positive']\n","['제품 전체#품질', ['재질도', 46, 49], 'positive']\n"]}],"source":["for idx, row in train.iterrows():\n","    if len(row.annotation) == 5:\n","        print(row.id)\n","        print()\n","        print(row.sentence_form)\n","        print()\n","        for annotation in row.annotation:\n","            print(annotation)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#브랜드#가격#positive \n"," 0 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#브랜드#가격#negative \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#브랜드#가격#neutral \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#제품 전체#품질#positive \n"," 0 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#제품 전체#품질#negative \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 토드비#제품 전체#품질#neutral \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 스타일도#제품 전체#디자인#positive \n"," 0 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 스타일도#제품 전체#디자인#negative \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 스타일도#제품 전체#디자인#neutral \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 색상도#본품#일반#positive \n"," 0 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 색상도#본품#일반#negative \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 색상도#본품#일반#neutral \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 재질도#제품 전체#품질#positive \n"," 0 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 재질도#제품 전체#품질#negative \n"," 1 \n","\n","nikluge-sa-2022-train-00174 \n"," Target 가성비 좋고 실용성 좋은 토드비 착용하는데.. 스타일도 색상도 예쁘고 재질도 부드러워서.. 만족만족.. \n"," 재질도#제품 전체#품질#neutral \n"," 1 \n","\n"]}],"source":["df = p_binary_train\n","for idx, row in df.iterrows():\n","    if row.id == 'nikluge-sa-2022-train-00174':\n","        print(row.id, '\\n',\n","            row.form, '\\n',\n","            row.pair, '\\n',\n","            row.labels, '\\n',)"]},{"cell_type":"markdown","metadata":{},"source":["### Save"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/uncleaned_v11\n"]}],"source":["DATA_V = 'uncleaned_v11'\n","save_path = f'./dataset/{DATA_V}'\n","print(save_path)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["!mkdir -p {save_path}\n","\n","# train.to_csv(f'{save_path}/raw_train.csv', index=False)\n","# dev.to_csv(f'{save_path}/raw_dev.csv', index=False)\n","# test.to_csv(f'{save_path}/raw_test.csv', index=False)\n","\n","ep_train.to_csv(f'{save_path}/ce_train.csv', index=False)\n","ep_dev.to_csv(f'{save_path}/ce_dev.csv', index=False)\n","\n","p_binary_train.to_csv(f'{save_path}/pc_binary_train.csv', index=False)\n","p_binary_dev.to_csv(f'{save_path}/pc_binary_dev.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Additional Length Test If Needed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ep_train, ep_dev, p_binary_train, p_binary_dev"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_checkpoint = 'dataset/uncleaned_v11/tokenizer'\n","tokenizer = ElectraTokenizerFast.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ep_train, ep_dev, p_binary_train, p_binary_dev\n","len_counter = []\n","for df in [ep_train, ep_dev, p_binary_train, p_binary_dev]:\n","    for idx, row in df.iterrows():\n","        len_counter.append(len(tokenizer(row[\"form\"], row[\"pair\"], truncation=True).input_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max(len_counter)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 ('jeonghyeon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"}}},"nbformat":4,"nbformat_minor":0}
