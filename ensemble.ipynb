{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.7.1\n",
      "torch.cuda.is_available(): True\n",
      "NGPU: 4\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "import torch, copy, os\n",
    "from module.score import evaluation_f1\n",
    "from module.load_json import *\n",
    "from module.maps import *\n",
    "from module.args import print_torch_info\n",
    "from module.inference import *\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACD_1_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_klue_roberta_base_mlm_fine_tuned_uncleaned_v22_run_1/checkpoint-37500'\n",
    "ACD_2_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_monologg_koelectra_base_v3_discriminator_uncleaned_v22_run_1/checkpoint-37500'\n",
    "ACD_3_CHECKPOINT = 'training_results/uncleaned_v22_run_1/acd_snunlp_kr_electra_discriminator_uncleaned_v22_run_1/checkpoint-37500'\n",
    "\n",
    "ASC_1_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_klue_roberta_base_mlm_fine_tuned_uncleaned_v22_run_1/checkpoint-1608'\n",
    "ASC_2_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_monologg_koelectra_base_v3_discriminator_uncleaned_v22_run_1/checkpoint-1608'\n",
    "ASC_3_CHECKPOINT = 'training_results/uncleaned_v22_run_1/asc_snunlp_kr_electra_discriminator_uncleaned_v22_run_1/checkpoint-1608'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acd_model_1 = AutoModelForSequenceClassification.from_pretrained(ACD_1_CHECKPOINT)\n",
    "acd_model_2 = AutoModelForSequenceClassification.from_pretrained(ACD_2_CHECKPOINT)\n",
    "acd_model_3 = AutoModelForSequenceClassification.from_pretrained(ACD_3_CHECKPOINT)\n",
    "acd_tokenizer_1 = AutoTokenizer.from_pretrained(ACD_1_CHECKPOINT)\n",
    "acd_tokenizer_2 = AutoTokenizer.from_pretrained(ACD_2_CHECKPOINT)\n",
    "acd_tokenizer_3 = AutoTokenizer.from_pretrained(ACD_3_CHECKPOINT)\n",
    "\n",
    "asc_model_1 = AutoModelForSequenceClassification.from_pretrained(ASC_1_CHECKPOINT)\n",
    "asc_model_2 = AutoModelForSequenceClassification.from_pretrained(ASC_2_CHECKPOINT)\n",
    "asc_model_3 = AutoModelForSequenceClassification.from_pretrained(ASC_3_CHECKPOINT)\n",
    "asc_tokenizer_1 = AutoTokenizer.from_pretrained(ASC_1_CHECKPOINT)\n",
    "asc_tokenizer_2 = AutoTokenizer.from_pretrained(ASC_2_CHECKPOINT)\n",
    "asc_tokenizer_3 = AutoTokenizer.from_pretrained(ASC_3_CHECKPOINT)\n",
    "\n",
    "# asc_model = AutoModelForSequenceClassification.from_pretrained(ASC_CHECKPOINT)\n",
    "# asc_tokenizer = AutoTokenizer.from_pretrained(ASC_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = '야 이놈아 이 것 좀 보려무나!'\n",
    "acd_pair = '이놈#저놈'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # v1\n",
    "\n",
    "# def acd_ensemble(form, acd_pair):\n",
    "#     acd_model_1.to(device)\n",
    "#     acd_model_2.to(device)\n",
    "#     acd_model_3.to(device)\n",
    "#     acd_model_1.eval()\n",
    "#     acd_model_2.eval()\n",
    "#     acd_model_3.eval()\n",
    "\n",
    "#     acd_encoded_1 = acd_tokenizer_1(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "#     acd_encoded_1 = {k:v.to(device) for k,v in acd_encoded_1.items()}\n",
    "\n",
    "#     acd_encoded_2 = acd_tokenizer_2(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "#     acd_encoded_2 = {k:v.to(device) for k,v in acd_encoded_2.items()}\n",
    "\n",
    "#     acd_encoded_3 = acd_tokenizer_3(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "#     acd_encoded_3 = {k:v.to(device) for k,v in acd_encoded_3.items()}\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         acd_outputs_1 = acd_model_1(**acd_encoded_1)['logits']\n",
    "#         acd_outputs_2 = acd_model_2(**acd_encoded_2)['logits']\n",
    "#         acd_outputs_3 = acd_model_3(**acd_encoded_3)['logits']\n",
    "\n",
    "#     acd_outputs = acd_outputs_1 + acd_outputs_2 + acd_outputs_3\n",
    "#     acd_predictions = acd_outputs.argmax(-1)[0]\n",
    "    \n",
    "#     return acd_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "\n",
    "def acd_ensemble(form, acd_pair):\n",
    "    acd_model_1.to(device)\n",
    "    acd_model_2.to(device)\n",
    "    acd_model_3.to(device)\n",
    "    acd_model_1.eval()\n",
    "    acd_model_2.eval()\n",
    "    acd_model_3.eval()\n",
    "\n",
    "    acd_encoded_1 = acd_tokenizer_1(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "    acd_encoded_1 = {k:v.to(device) for k,v in acd_encoded_1.items()}\n",
    "\n",
    "    acd_encoded_2 = acd_tokenizer_2(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "    acd_encoded_2 = {k:v.to(device) for k,v in acd_encoded_2.items()}\n",
    "\n",
    "    acd_encoded_3 = acd_tokenizer_3(form, acd_pair, truncation=True, return_tensors=\"pt\")\n",
    "    acd_encoded_3 = {k:v.to(device) for k,v in acd_encoded_3.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        acd_outputs_1 = acd_model_1(**acd_encoded_1)['logits']\n",
    "        acd_outputs_2 = acd_model_2(**acd_encoded_2)['logits']\n",
    "        acd_outputs_3 = acd_model_3(**acd_encoded_3)['logits']\n",
    "\n",
    "    acd_outputs = acd_outputs_1 + acd_outputs_2 + acd_outputs_3\n",
    "    \n",
    "    acd_predictions_1 = acd_outputs_1.argmax(-1).squeeze()\n",
    "    acd_predictions_2 = acd_outputs_2.argmax(-1).squeeze()\n",
    "    acd_predictions_3 = acd_outputs_3.argmax(-1).squeeze()\n",
    "    print([acd_predictions_1, acd_predictions_2, acd_predictions_3])\n",
    "    if 0 in [acd_predictions_1, acd_predictions_2, acd_predictions_3]:\n",
    "        return 0\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = ''\n",
    "acd_pair = '헙헙#요요홉'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0, device='cuda:0'), tensor(1, device='cuda:0'), tensor(1, device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acd_ensemble(form, acd_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asc_ensemble(form, asc_pair):\n",
    "    asc_model_1.to(device)\n",
    "    asc_model_2.to(device)\n",
    "    asc_model_3.to(device)\n",
    "    asc_model_1.eval()\n",
    "    asc_model_2.eval()\n",
    "    asc_model_3.eval()\n",
    "\n",
    "    asc_encoded_1 = asc_tokenizer_1(form, asc_pair, truncation=True, return_tensors=\"pt\")\n",
    "    asc_encoded_1 = {k:v.to(device) for k,v in asc_encoded_1.items()}\n",
    "\n",
    "    asc_encoded_2 = asc_tokenizer_2(form, asc_pair, truncation=True, return_tensors=\"pt\")\n",
    "    asc_encoded_2 = {k:v.to(device) for k,v in asc_encoded_2.items()}\n",
    "\n",
    "    asc_encoded_3 = asc_tokenizer_3(form, asc_pair, truncation=True, return_tensors=\"pt\")\n",
    "    asc_encoded_3 = {k:v.to(device) for k,v in asc_encoded_3.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        asc_outputs_1 = asc_model_1(**asc_encoded_1)['logits']\n",
    "        asc_outputs_2 = asc_model_2(**asc_encoded_2)['logits']\n",
    "        asc_outputs_3 = asc_model_3(**asc_encoded_3)['logits']\n",
    "\n",
    "    asc_outputs = asc_outputs_1 + asc_outputs_2 + asc_outputs_3\n",
    "    \n",
    "    return asc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_m_ensemble(acd_ensemble, asc_ensemble, data, entity_property_pair):\n",
    "    print(entity_property_pair)\n",
    "    for sentence in tqdm(data):\n",
    "        form = sentence['sentence_form']\n",
    "        sentence['annotation'] = []\n",
    "        if type(form) != str:\n",
    "            print(\"form type is wrong: \", form)\n",
    "            continue\n",
    "        for pair in entity_property_pair:\n",
    "            acd_pair = pair\n",
    "\n",
    "            acd_predictions = acd_ensemble(form, acd_pair)\n",
    "            acd_result = tf_id_to_name[acd_predictions]\n",
    "\n",
    "            if acd_result == 'True':\n",
    "                asc_pair = pair\n",
    "\n",
    "                asc_outputs = asc_ensemble(form, asc_pair)\n",
    "                asc_predictions = asc_outputs.argmax(-1)\n",
    "                asc_result = polarity_id_to_name[asc_predictions[0]]\n",
    "\n",
    "                if pair == '패키지/구성품#가격':\n",
    "                    print(f'{pair} found.')\n",
    "                    pair = '패키지/ 구성품#가격'\n",
    "                    print(f'corrected as {pair}')\n",
    "\n",
    "                sentence['annotation'].append([pair, asc_result])\n",
    "\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('jeonghyeon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df12b971f0e4e081474c4ac44bd338416eac6f5401e1e938ba342788cee78ecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
